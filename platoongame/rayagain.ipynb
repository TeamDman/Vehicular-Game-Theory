{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/ray-project/ray/blob/master/rllib/examples/sb2rllib_rllib_example.py\n",
    "import ray\n",
    "from ray import tune, air\n",
    "import ray.rllib.algorithms.ppo as ppo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage stats collection is enabled by default for nightly wheels. To disable this, run the following command: `ray disable-usage-stats` before starting Ray. See https://docs.ray.io/en/master/cluster/usage-stats.html for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 18:04:07,658\tINFO worker.py:1536 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.15</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 3.0.0.dev0</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://127.0.0.1:8265\" target=\"_blank\">http://127.0.0.1:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='127.0.0.1:8265', python_version='3.8.15', ray_version='3.0.0.dev0', ray_commit='3e18487d7427a3ffcea9fecd5c79ca3e81fb92d0', address_info={'node_ip_address': '127.0.0.1', 'raylet_ip_address': '127.0.0.1', 'redis_address': None, 'object_store_address': 'tcp://127.0.0.1:28352', 'raylet_socket_name': 'tcp://127.0.0.1:34435', 'webui_url': '127.0.0.1:8265', 'session_dir': 'C:\\\\Users\\\\TeamD\\\\AppData\\\\Local\\\\Temp\\\\ray\\\\session_2023-01-10_18-04-05_116514_11636', 'metrics_export_port': 16597, 'gcs_address': '127.0.0.1:11191', 'address': '127.0.0.1:11191', 'dashboard_agent_listen_port': 52365, 'node_id': 'b7f0f3d3aaf97a7ad12b8c268cab199d5118f007f1875d932a550bac'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "ray.init(num_gpus=1, local_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platoon-v2 \n",
      "------------------\n",
      "reward_threshold 500\n",
      "max_episode_steps 20\n"
     ]
    }
   ],
   "source": [
    "# settings used for both stable baselines and rllib\n",
    "import gymnasium as gym\n",
    "import platoonenv\n",
    "# import check env\n",
    "\n",
    "env_name = \"Platoon-v2\"\n",
    "env = gym.make(env_name)\n",
    "\n",
    "print(env_name,\"\\n------------------\")\n",
    "print(\"reward_threshold\", env.spec.reward_threshold)\n",
    "print(\"max_episode_steps\", env.spec.max_episode_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 18:04:10,795\tWARNING env.py:166 -- Your env reset() method appears to take 'seed' or 'return_info' arguments. Note that these are not yet supported in RLlib. Seeding will take place using 'env.seed()' and the info dict will not be returned from reset.\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.utils import check_env\n",
    "\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=19380)\u001b[0m 2023-01-10 18:04:23,167\tWARNING env.py:166 -- Your env reset() method appears to take 'seed' or 'return_info' arguments. Note that these are not yet supported in RLlib. Seeding will take place using 'env.seed()' and the info dict will not be returned from reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19380)\u001b[0m 2023-01-10 18:04:23,224\tINFO policy.py:1196 -- Policy (worker=1) running on CPU.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19380)\u001b[0m 2023-01-10 18:04:23,224\tINFO torch_policy_v2.py:110 -- Found 1 visible cuda devices.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=14712)\u001b[0m 2023-01-10 18:04:23,271\tINFO policy.py:1196 -- Policy (worker=2) running on CPU.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=14712)\u001b[0m 2023-01-10 18:04:23,271\tINFO torch_policy_v2.py:110 -- Found 1 visible cuda devices.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=8636)\u001b[0m 2023-01-10 18:04:23,267\tINFO policy.py:1196 -- Policy (worker=5) running on CPU.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=8636)\u001b[0m 2023-01-10 18:04:23,267\tINFO torch_policy_v2.py:110 -- Found 1 visible cuda devices.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=9004)\u001b[0m 2023-01-10 18:04:23,254\tINFO policy.py:1196 -- Policy (worker=3) running on CPU.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=9004)\u001b[0m 2023-01-10 18:04:23,254\tINFO torch_policy_v2.py:110 -- Found 1 visible cuda devices.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=8240)\u001b[0m 2023-01-10 18:04:23,356\tINFO policy.py:1196 -- Policy (worker=10) running on CPU.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=8240)\u001b[0m 2023-01-10 18:04:23,357\tINFO torch_policy_v2.py:110 -- Found 1 visible cuda devices.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=9380)\u001b[0m 2023-01-10 18:04:23,366\tINFO policy.py:1196 -- Policy (worker=4) running on CPU.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=9380)\u001b[0m 2023-01-10 18:04:23,366\tINFO torch_policy_v2.py:110 -- Found 1 visible cuda devices.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=8892)\u001b[0m 2023-01-10 18:04:23,392\tINFO policy.py:1196 -- Policy (worker=9) running on CPU.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=8892)\u001b[0m 2023-01-10 18:04:23,393\tINFO torch_policy_v2.py:110 -- Found 1 visible cuda devices.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15824)\u001b[0m 2023-01-10 18:04:23,408\tINFO policy.py:1196 -- Policy (worker=6) running on CPU.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15824)\u001b[0m 2023-01-10 18:04:23,408\tINFO torch_policy_v2.py:110 -- Found 1 visible cuda devices.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3604)\u001b[0m 2023-01-10 18:04:23,428\tINFO policy.py:1196 -- Policy (worker=7) running on CPU.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3604)\u001b[0m 2023-01-10 18:04:23,428\tINFO torch_policy_v2.py:110 -- Found 1 visible cuda devices.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=14564)\u001b[0m 2023-01-10 18:04:23,475\tINFO policy.py:1196 -- Policy (worker=8) running on CPU.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=14564)\u001b[0m 2023-01-10 18:04:23,475\tINFO torch_policy_v2.py:110 -- Found 1 visible cuda devices.\n",
      "2023-01-10 18:04:23,533\tINFO policy.py:1196 -- Policy (worker=local) running on 1 GPUs.\n",
      "2023-01-10 18:04:23,534\tINFO torch_policy_v2.py:110 -- Found 1 visible cuda devices.\n",
      "2023-01-10 18:04:25,252\tINFO rollout_worker.py:2037 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['default_policy']>\n",
      "2023-01-10 18:04:25,252\tINFO rollout_worker.py:2038 -- Built preprocessor map: {'default_policy': <ray.rllib.models.preprocessors.NoPreprocessor object at 0x0000017C6107B850>}\n",
      "2023-01-10 18:04:25,253\tINFO rollout_worker.py:757 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {'default_policy': <ray.rllib.utils.filter.NoFilter object at 0x0000017C6107BFA0>})\n",
      "2023-01-10 18:04:25,267\tINFO trainable.py:172 -- Trainable.setup took 14.370 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.rllib.algorithms.dqn import DQNConfig\n",
    "\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    .environment(env=env_name)\n",
    "    .framework(\"torch\")\n",
    "    .rollouts(num_rollout_workers=10)\n",
    "    # .rollouts(num_rollout_workers=0) # curiosity doesn't support parallelism\n",
    "    .resources(num_gpus=1)\n",
    "    # .exploration( # https://docs.ray.io/en/latest/rllib/rllib-algorithms.html#curiosity-icm-intrinsic-curiosity-module\n",
    "    #     exploration_config={\n",
    "    #         \"type\": \"Curiosity\",  # <- Use the Curiosity module for exploring.\n",
    "    #         \"eta\": 1.0,  # Weight for intrinsic rewards before being added to extrinsic ones.\n",
    "    #         \"lr\": 0.001,  # Learning rate of the curiosity (ICM) module.\n",
    "    #         \"feature_dim\": 288,  # Dimensionality of the generated feature vectors.\n",
    "    #         # Setup of the feature net (used to encode observations into feature (latent) vectors).\n",
    "    #         \"feature_net_config\": {\n",
    "    #             \"fcnet_hiddens\": [],\n",
    "    #             \"fcnet_activation\": \"relu\",\n",
    "    #         },\n",
    "    #         \"inverse_net_hiddens\": [256],  # Hidden layers of the \"inverse\" model.\n",
    "    #         \"inverse_net_activation\": \"relu\",  # Activation of the \"inverse\" model.\n",
    "    #         \"forward_net_hiddens\": [256],  # Hidden layers of the \"forward\" model.\n",
    "    #         \"forward_net_activation\": \"relu\",  # Activation of the \"forward\" model.\n",
    "    #         \"beta\": 0.2,  # Weight for the \"forward\" loss (beta) over the \"inverse\" loss (1.0 - beta).\n",
    "    #         # Specify, which exploration sub-type to use (usually, the algo's \"default\"\n",
    "    #         # exploration, e.g. EpsilonGreedy for DQN, StochasticSampling for PG/SAC).\n",
    "    #         \"sub_exploration\": {\n",
    "    #             \"type\": \"StochasticSampling\",\n",
    "    #         }\n",
    "    #     }\n",
    "    # )\n",
    ")\n",
    "config.horizon = env.spec.max_episode_steps\n",
    "config.lr = 0.0001\n",
    "config.create_env_on_local_worker=True\n",
    "algo = config.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'extra_python_environs_for_driver': {},\n",
       " 'extra_python_environs_for_worker': {},\n",
       " 'num_gpus': 1,\n",
       " 'num_cpus_per_worker': 1,\n",
       " 'num_gpus_per_worker': 0,\n",
       " '_fake_gpus': False,\n",
       " 'custom_resources_per_worker': {},\n",
       " 'placement_strategy': 'PACK',\n",
       " 'eager_tracing': False,\n",
       " 'eager_max_retraces': 20,\n",
       " 'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "  'inter_op_parallelism_threads': 2,\n",
       "  'gpu_options': {'allow_growth': True},\n",
       "  'log_device_placement': False,\n",
       "  'device_count': {'CPU': 1},\n",
       "  'allow_soft_placement': True},\n",
       " 'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "  'inter_op_parallelism_threads': 8},\n",
       " 'env': 'Platoon-v2',\n",
       " 'env_config': {},\n",
       " 'observation_space': None,\n",
       " 'action_space': None,\n",
       " 'env_task_fn': None,\n",
       " 'render_env': False,\n",
       " 'clip_rewards': None,\n",
       " 'normalize_actions': True,\n",
       " 'clip_actions': False,\n",
       " 'disable_env_checking': False,\n",
       " 'is_atari': None,\n",
       " 'num_envs_per_worker': 1,\n",
       " 'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       " 'sample_async': False,\n",
       " 'enable_connectors': False,\n",
       " 'rollout_fragment_length': 'auto',\n",
       " 'batch_mode': 'truncate_episodes',\n",
       " 'remote_worker_envs': False,\n",
       " 'remote_env_batch_wait_ms': 0,\n",
       " 'validate_workers_after_construction': True,\n",
       " 'ignore_worker_failures': False,\n",
       " 'recreate_failed_workers': False,\n",
       " 'restart_failed_sub_environments': False,\n",
       " 'num_consecutive_worker_failures_tolerance': 100,\n",
       " 'preprocessor_pref': 'deepmind',\n",
       " 'observation_filter': 'NoFilter',\n",
       " 'synchronize_filters': True,\n",
       " 'compress_observations': False,\n",
       " 'enable_tf1_exec_eagerly': False,\n",
       " 'sampler_perf_stats_ema_coef': None,\n",
       " 'gamma': 0.99,\n",
       " 'lr': 0.0001,\n",
       " 'train_batch_size': 4000,\n",
       " 'model': {'_disable_preprocessor_api': False,\n",
       "  '_disable_action_flattening': False,\n",
       "  'fcnet_hiddens': [256, 256],\n",
       "  'fcnet_activation': 'tanh',\n",
       "  'conv_filters': None,\n",
       "  'conv_activation': 'relu',\n",
       "  'post_fcnet_hiddens': [],\n",
       "  'post_fcnet_activation': 'relu',\n",
       "  'free_log_std': False,\n",
       "  'no_final_linear': False,\n",
       "  'vf_share_layers': False,\n",
       "  'use_lstm': False,\n",
       "  'max_seq_len': 20,\n",
       "  'lstm_cell_size': 256,\n",
       "  'lstm_use_prev_action': False,\n",
       "  'lstm_use_prev_reward': False,\n",
       "  '_time_major': False,\n",
       "  'use_attention': False,\n",
       "  'attention_num_transformer_units': 1,\n",
       "  'attention_dim': 64,\n",
       "  'attention_num_heads': 1,\n",
       "  'attention_head_dim': 32,\n",
       "  'attention_memory_inference': 50,\n",
       "  'attention_memory_training': 50,\n",
       "  'attention_position_wise_mlp_dim': 32,\n",
       "  'attention_init_gru_gate_bias': 2.0,\n",
       "  'attention_use_n_prev_actions': 0,\n",
       "  'attention_use_n_prev_rewards': 0,\n",
       "  'framestack': True,\n",
       "  'dim': 84,\n",
       "  'grayscale': False,\n",
       "  'zero_mean': True,\n",
       "  'custom_model': None,\n",
       "  'custom_model_config': {},\n",
       "  'custom_action_dist': None,\n",
       "  'custom_preprocessor': None,\n",
       "  'lstm_use_prev_action_reward': -1,\n",
       "  '_use_default_native_models': -1},\n",
       " 'optimizer': {},\n",
       " 'max_requests_in_flight_per_sampler_worker': 2,\n",
       " 'explore': True,\n",
       " 'exploration_config': {'type': 'StochasticSampling'},\n",
       " 'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec at 0x17c60da87f0>},\n",
       " 'policy_states_are_swappable': False,\n",
       " 'input_config': {},\n",
       " 'actions_in_input_normalized': False,\n",
       " 'postprocess_inputs': False,\n",
       " 'shuffle_buffer_size': 0,\n",
       " 'output': None,\n",
       " 'output_config': {},\n",
       " 'output_compress_columns': ['obs', 'new_obs'],\n",
       " 'output_max_file_size': 67108864,\n",
       " 'offline_sampling': False,\n",
       " 'evaluation_interval': None,\n",
       " 'evaluation_duration': 10,\n",
       " 'evaluation_duration_unit': 'episodes',\n",
       " 'evaluation_sample_timeout_s': 180.0,\n",
       " 'evaluation_parallel_to_training': False,\n",
       " 'evaluation_config': None,\n",
       " 'off_policy_estimation_methods': {},\n",
       " 'ope_split_batch_by_episode': True,\n",
       " 'evaluation_num_workers': 0,\n",
       " 'always_attach_evaluation_results': False,\n",
       " 'enable_async_evaluation': False,\n",
       " 'in_evaluation': False,\n",
       " 'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
       " 'keep_per_episode_custom_metrics': False,\n",
       " 'metrics_episode_collection_timeout_s': 60.0,\n",
       " 'metrics_num_episodes_for_smoothing': 100,\n",
       " 'min_time_s_per_iteration': None,\n",
       " 'min_train_timesteps_per_iteration': 0,\n",
       " 'min_sample_timesteps_per_iteration': 0,\n",
       " 'export_native_model_files': False,\n",
       " 'checkpoint_trainable_policies_only': False,\n",
       " 'logger_creator': None,\n",
       " 'logger_config': None,\n",
       " 'log_level': -1,\n",
       " 'log_sys_usage': True,\n",
       " 'fake_sampler': False,\n",
       " 'seed': None,\n",
       " 'worker_cls': None,\n",
       " 'rl_module_class': None,\n",
       " '_enable_rl_module_api': False,\n",
       " '_tf_policy_handles_more_than_one_loss': False,\n",
       " '_disable_preprocessor_api': False,\n",
       " '_disable_action_flattening': False,\n",
       " '_disable_execution_plan_api': True,\n",
       " 'simple_optimizer': -1,\n",
       " 'replay_sequence_length': None,\n",
       " 'horizon': 20,\n",
       " 'soft_horizon': -1,\n",
       " 'no_done_at_end': -1,\n",
       " 'lr_schedule': None,\n",
       " 'use_critic': True,\n",
       " 'use_gae': True,\n",
       " 'kl_coeff': 0.2,\n",
       " 'sgd_minibatch_size': 128,\n",
       " 'num_sgd_iter': 30,\n",
       " 'shuffle_sequences': True,\n",
       " 'vf_loss_coeff': 1.0,\n",
       " 'entropy_coeff': 0.0,\n",
       " 'entropy_coeff_schedule': None,\n",
       " 'clip_param': 0.3,\n",
       " 'vf_clip_param': 10.0,\n",
       " 'grad_clip': None,\n",
       " 'kl_target': 0.01,\n",
       " 'vf_share_layers': -1,\n",
       " 'lambda': 1.0,\n",
       " 'input': 'sampler',\n",
       " 'multiagent': {'policies': {'default_policy': (None, None, None, None)},\n",
       "  'policy_mapping_fn': <function ray.rllib.algorithms.algorithm_config.AlgorithmConfig.__init__.<locals>.<lambda>(aid, episode, worker, **kwargs)>,\n",
       "  'policies_to_train': None,\n",
       "  'policy_map_capacity': 100,\n",
       "  'policy_map_cache': -1,\n",
       "  'count_steps_by': 'env_steps',\n",
       "  'observation_fn': None},\n",
       " 'callbacks': ray.rllib.algorithms.callbacks.DefaultCallbacks,\n",
       " 'create_env_on_driver': True,\n",
       " 'custom_eval_function': None,\n",
       " 'framework': 'torch',\n",
       " 'num_cpus_for_driver': 1,\n",
       " 'num_workers': 10}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 18:04:25,422\tINFO trainable.py:790 -- Restored on 127.0.0.1 from checkpoint: saved_models\\Platoon-v2-curious-2\\checkpoint_000077\n",
      "2023-01-10 18:04:25,423\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 77, '_timesteps_total': None, '_time_total': 805.8298804759979, '_episodes_total': 30760}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring from checkpoint: saved_models\\Platoon-v2-curious-2\\checkpoint_000077\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from pathlib import Path\n",
    "save_dir = Path(\"saved_models\",f\"{env_name}-curious-2\")\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "load_checkpoint = True\n",
    "if load_checkpoint:\n",
    "    try:\n",
    "        checkpoint_path = sorted(glob(str(save_dir / \"*\")))[-1]\n",
    "        print(f\"Restoring from checkpoint: {checkpoint_path}\")\n",
    "        algo.restore(checkpoint_path)\n",
    "    except IndexError as e:\n",
    "        print(f\"Failed to load checkpoint: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "def plot(rewards_history):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.title(\"Training...\")\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Rewards\")\n",
    "    plt.plot([x[\"episode_reward_mean\"] for x in rewards_history])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/IAAAHWCAYAAADUwLIxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA29klEQVR4nO3dfZhWdZ0/8M+M46DO3jOmEA+T+gMJNCkE0YRADIt0awXFNNNLsCwVKrVWjdUk2EL8bYqFqOW2qCnttqViq5HCT0wNMh9AQlEUFByeVB5mkIcZ4Pv7w7y3iQGZcYZ7jrxe1/W55HzP95z7c4ZzzcXb83AXRUQKAAAAIBOKC90AAAAAsPsEeQAAAMgQQR4AAAAyRJAHAACADBHkAQAAIEMEeQAAAMgQQR4AAAAyRJAHAACADBHkAQAAIEMEeQCgQVOmTIklS5Y0adsxY8ZESqmZOwIAIgR5AMiclNJu1cCBAwvdKgDQAooiwv8uB4AMOeecc+otn3feeTF48OA499xz640//PDDsXr16iZ/TklJSRQXF0dtbW2jt91nn32ipKQktmzZ0uTPBwAaJsgDQMZNmjQpvvGNb0RRUdEu5+2///6xadOmPdQVANBS3FoPAB9AjzzySMyfPz969+4djz76aLz99tsxfvz4iIg49dRT43/+53+iqqoqNm/eHC+//HJcffXVUVxc/58Ff/+M/GGHHRYppfjOd74TX/va1+Lll1+OzZs3x5NPPhl9+vSpt21Dz8inlGLSpEkxZMiQmD9/fmzevDn+8pe/xOc+97kd+h84cGD8+c9/jk2bNsXLL78cX//61z13DwB/VVLoBgCAlnHwwQfH7373u/jP//zPuOuuu2LVqlURETFixIjYsGFD3HDDDbFhw4YYNGhQ/Ou//muUl5fHFVdc8Z77/fKXvxy5XC5++tOfRkoprrjiirjnnnuiS5cusXXr1l1u279//zj99NPj5ptvjpqamvjWt74Vv/nNb+LQQw+NNWvWRETE0UcfHdOnT48VK1bEmDFjYp999olrrrkm3njjjff/QwGAD4iklFJKqezWpEmTUnrnUnW+HnnkkZRSSl//+td3mL/ffvvtMHbLLbekDRs2pNLS0vzYlClT0pIlS/LLhx12WEoppTfeeCMdeOCB+fF/+qd/Siml9PnPfz4/NmbMmB16SimlzZs3py5duuTHPv7xj6eUUho1alR+bNq0aWnDhg2pY8eO+bHDDz881dbW7rBPpZRSam8st9YDwAfU5s2bY8qUKQ2Ov+sf/uEf4uCDD47HHnssysrK4ogjjnjP/f7Xf/1XrFu3Lr/82GOPRUREly5d3nPbGTNmxOLFi/PL8+fPj/Xr1+e3LS4ujs985jNx3333xYoVK/LzXnnllfjd7373nvsHgL2BW+sB4AOqqqoq6urqdhj/2Mc+Fj/4wQ9i0KBBUVFRUW/d3y83ZOnSpfWW3w31H/rQhxq9bUTE2rVr89t++MMfjgMOOCBefvnlHeY1NAYAeyNBHgA+oBp6Q31FRUU8+uijUV1dHddcc0288sorsXnz5ujdu3f83//7f3d44V1Dtm3b1uD4e701//1uCwC8Q5AHgL3IiSeeGG3bto3TTz89f0t8RETnzp0L2NX/Wr16dWzatCm6du26w7qGxgBgb+QZeQDYi7x7Rfxvr4Dvu+++MXLkyEK1VM/27dtjxowZMXTo0OjYsWN+/PDDD49TTjllh/mHHHJIdO/evd7YwQcfHN27d4/9998/P7b//vtH9+7d4+CDD2655gFgDxHkAWAv8sc//jHWrFkTd9xxR1x22WVx6aWXxpw5c1rVre3f//73o6SkJJ544om4/PLL47vf/W48+uij8Ze//GWHuXfeeWcsXLiw3tg3vvGNWLhwYRx33HH5seOOOy4WLlwY3/jGN1q8fwBoaYI8AOxF1qxZE1/4whdixYoV8YMf/CD++Z//OR5++OHd+v74PeWZZ56JU045JdauXRv/+q//Gl/96lfjmmuuiZkzZzb43D8A7G2K4p3voQMAaNXuvffeOOqoo6Jbt26FbgUACsoVeQCg1dlvv/3qLXft2jX+8R//MWbNmlWYhgCgFXFFHgBodZYvXx633357LF68OA477LC4+OKLo02bNtGrVy/fJw/AXs/XzwEArc706dPj7LPPjg4dOsSWLVti9uzZ8S//8i9CPACEK/IAAACQKZ6RBwAAgAwR5AEAACBDPCO/E506dYqamppCtwEAAMBeIpfLxfLly99zniDfgE6dOkVVVVWh2wAAAGAvU1lZ+Z5hXpBvwLtX4isrK12VBwAAoMXlcrmoqqrarQwqyO9CTU2NIA8AAECr4mV3AAAAkCGCPAAAAGSIIA8AAAAZIsgDAABAhgjyAAAAkCGCPAAAAGSIIA8AAAAZIsgDAABAhgjyAAAAkCGCPAAAAGSIIA8AAAAZIsgDAABAhgjyAAAAkCGCPAAAAGRIQYP8gAED4v7774+qqqpIKcWQIUN2OX/gwIGRUtqh2rdv3+D8K6+8MlJKMXHixJZoHwAAAPa4ggb5srKymDdvXowaNapR23Xr1i06dOiQr9WrV+8wp0+fPnHhhRfGvHnzmqtdAAAAKLiSQn749OnTY/r06Y3ebvXq1bF+/fqdri8rK4u77747vva1r8XVV1/9nvsrLS2NNm3a5JdzuVyjewIAAIA9IZPPyM+dOzeWL18eDz30UPTr12+H9ZMnT44HHnggZs6cuVv7Gz16dFRXV+erqqqquVsGAACAZpGpIL9ixYq48MILY9iwYTFs2LBYtmxZzJo1K3r16pWfc9ZZZ0Xv3r1j9OjRu73fa6+9NsrLy/NVWVnZEu0DAADA+1bQW+sb66WXXoqXXnopvzx79uw4/PDD47LLLovzzjsvPvKRj8SPf/zj+OxnPxtbtmzZ7f3W1tZGbW1tS7QMAAAAzSpTV+Qb8uSTT0bXrl0jIuKYY46J9u3bxzPPPBN1dXVRV1cXJ554YnzrW9+Kurq6KC7O/OECAACwl8vUFfmGHH300bFixYqIiJg5c2b06NGj3vopU6bEwoUL47rrrovt27cXokUAAABoNgUN8mVlZfmr6RERnTt3jp49e8aaNWti2bJlMX78+KisrIzhw4dHRMQll1wSS5YsiQULFsR+++0XF1xwQQwaNCgGDx4cEREbNmyIBQsW1PuMt99+O956660dxgEAACCLChrk+/TpE7NmzcovT5w4MSIibr/99jj//POjY8eOceihh+bXl5aWxvXXXx+VlZWxcePGeO655+Izn/lMvX0AAADAB1lRRKRCN9Ha5HK5qK6ujvLy8qipqSl0OwAAAHzANSaHevsbAAAAZIggDwAAABkiyAMAAECGCPIAAACQIYI8AAAAZIggDwAAABkiyAMAAECGCPIAAACQIYI8AAAAZIggDwAAABkiyAMAAECGCPIAAACQIYI8AAAAZIggDwAAABkiyAMAAECGCPIAAACQIYI8AAAAZIggDwAAABkiyAMAAECGCPIAAACQIYI8AAAAZIggDwAAABkiyAMAAECGCPIAAACQIYI8AAAAZIggDwAAABkiyAMAAECGCPIAAACQIYI8AAAAZIggDwAAABkiyAMAAECGCPIAAACQIYI8AAAAZIggDwAAABkiyAMAAECGCPIAAACQIQUN8gMGDIj7778/qqqqIqUUQ4YM2eX8gQMHRkpph2rfvn1+zne/+9148skno7q6OlatWhX33ntvdOvWraUPBQAAAPaIggb5srKymDdvXowaNapR23Xr1i06dOiQr9WrV+fXDRw4MCZPnhzHH398fPazn4199903HnrooTjggAOau30AAADY40oK+eHTp0+P6dOnN3q71atXx/r16xtcd8opp9RbHjFiRLzxxhtxzDHHxGOPPdakPgEAAKC1yOQz8nPnzo3ly5fHQw89FP369dvl3IqKioiIWLNmzU7nlJaWRi6Xq1cAAADQGmUqyK9YsSIuvPDCGDZsWAwbNiyWLVsWs2bNil69ejU4v6ioKG688cZ4/PHHY8GCBTvd7+jRo6O6ujpfVVVVLXUIAAAA8L4URUQqdBMRESmlGDp0aEybNq1R282aNSuWLl0a55133g7rbr755jjllFOif//+uwznpaWl0aZNm/xyLpeLqqqqKC8vj5qamkb1AwAAAI2Vy+Wiurp6t3JoQZ+Rbw5PPvlk9O/ff4fxSZMmxRe+8IU44YQT3vMKe21tbdTW1rZUiwAAANBsMh/kjz766FixYkW9sUmTJsVpp50WJ554Yrz66quFaQwAAABaQEGDfFlZWXTt2jW/3Llz5+jZs2esWbMmli1bFuPHj4/KysoYPnx4RERccsklsWTJkliwYEHst99+ccEFF8SgQYNi8ODB+X1Mnjw5vvzlL8eQIUOipqYm/x3z69evj82bN+/ZAwQAAIAWkApVAwcOTA2ZMmVKiog0ZcqU9Mgjj+TnX3755WnRokVp48aN6c0330z/7//9v3TiiSfW2+fODB8+fLf7yuVyKaWUcrlcwX42SimllFJKKaX2nmpMDm01L7trTRrzkgEAAAB4vxqTQzP19XMAAACwtxPkAQAAIEMEeQAAAMgQQR4AAAAyRJAHAACADBHkAQAAIEMEeQAAAMgQQR4AAAAyRJAHAACADBHkAQAAIEMEeQAAAMgQQR4AAAAyRJAHAACADBHkAQAAIEMEeQAAAMgQQR4AAAAyRJAHAACADBHkAQAAIEMEeQAAAMgQQR4AAAAyRJAHAACADBHkAQAAIEMEeQAAAMgQQR4AAAAyRJAHAACADBHkAQAAIEMEeQAAAMgQQR4AAAAyRJAHAACADBHkAQAAIEMEeQAAAMgQQR4AAAAyRJAHAACADBHkAQAAIEMEeQAAAMgQQR4AAAAyRJAHAACADClokB8wYEDcf//9UVVVFSmlGDJkyC7nDxw4MFJKO1T79u3rzRs5cmQsWbIkNm3aFHPmzIljjz22JQ8DAAAA9piCBvmysrKYN29ejBo1qlHbdevWLTp06JCv1atX59edeeaZccMNN8TYsWOjd+/eMW/evPj9738f7dq1a+72AQAAoCBSa6iUUhoyZMgu5wwcODCllFJFRcVO58yZMydNmjQpv1xUVJRef/31dOWVV+52L7lcLqWUUi6XK/jPRSmllFJKKaXUB78ak0Mz+Yz83LlzY/ny5fHQQw9Fv3798uP77rtvHHPMMTFjxoz8WEopZsyYEX379t3p/kpLSyOXy9UrAAAAaI0yFeRXrFgRF154YQwbNiyGDRsWy5Yti1mzZkWvXr0iIqJt27ZRUlISq1atqrfdqlWrokOHDjvd7+jRo6O6ujpfVVVVLXocAAAA0FQlhW6gMV566aV46aWX8suzZ8+Oww8/PC677LI477zzmrzfa6+9Nm644Yb8ci6XE+YBAABolTIV5Bvy5JNPRv/+/SMi4s0334ytW7fu8Bb79u3bx8qVK3e6j9ra2qitrW3RPgEAAKA5ZOrW+oYcffTRsWLFioiIqKuri6effjpOOumk/PqioqI46aSTYvbs2YVqEQAAAJpNQa/Il5WVRdeuXfPLnTt3jp49e8aaNWti2bJlMX78+KisrIzhw4dHRMQll1wSS5YsiQULFsR+++0XF1xwQQwaNCgGDx6c38cNN9wQd9xxRzz11FPx5JNPxqWXXhplZWUxZcqUPX58AAAA0NwKGuT79OkTs2bNyi9PnDgxIiJuv/32OP/886Njx45x6KGH5teXlpbG9ddfH5WVlbFx48Z47rnn4jOf+Uy9ffzqV7+Kdu3axbhx46JDhw4xd+7cOPnkk+t91zwAAABkVVG88z10/I1cLhfV1dVRXl4eNTU1hW4HAACAD7jG5NDMPyMPAAAAexNBHgAAADJEkAcAAIAMEeQBAAAgQwR5AAAAyBBBHgAAADJEkAcAAIAMEeQBAAAgQwR5AAAAyBBBHgAAADJEkAcAAIAMEeQBAAAgQwR5AAAAyBBBHgAAADJEkAcAAIAMEeQBAAAgQwR5AAAAyBBBHgAAADJEkAcAAIAMEeQBAAAgQwR5AAAAyBBBHgAAADJEkAcAAIAMEeQBAAAgQwR5AAAAyBBBHgAAADJEkAcAAIAMEeQBAAAgQwR5AAAAyBBBHgAAADJEkAcAAIAMEeQBAAAgQwR5AAAAyBBBHgAAADJEkAcAAIAMEeQBAAAgQwR5AAAAyJCCBvkBAwbE/fffH1VVVZFSiiFDhuz2tv369Yu6urp49tln640XFxfHuHHjYvHixbFx48Z4+eWX4+qrr27u1gEAAKAgChrky8rKYt68eTFq1KhGbVdRURF33nlnzJw5c4d1V155ZVx88cXxjW98I4488si48sor44orrohvfvObzdU2AAAAFExJIT98+vTpMX369EZvd+utt8bUqVNj27ZtMXTo0Hrr+vXrF9OmTYsHH3wwIiJee+21OPvss+O4447b6f5KS0ujTZs2+eVcLtfongAAAGBPyNwz8iNGjIguXbrE2LFjG1z/xz/+MU466aT46Ec/GhERn/jEJ6J///7xu9/9bqf7HD16dFRXV+erqqqqRXoHAACA96ugV+Qbq2vXrjFhwoQYMGBAbNu2rcE5EyZMiPLy8li4cGFs27Yt9tlnn7jqqqti6tSpO93vtddeGzfccEN+OZfLCfMAAAC0SpkJ8sXFxTF16tQYM2ZMLFq0aKfzzjzzzDjnnHPiy1/+cixYsCCOPvrouPHGG2P58uVx5513NrhNbW1t1NbWtlTrAAAA0KzS+61cLpeGDBmSjjjiiCbvI6WUhgwZstP1FRUVKaWU6urq8rVt27b82Kc//ekUEWnp0qVp5MiR9ba96qqr0gsvvNCo40kppVwu975/NkoppZRSSiml1HtVY3Jok67I/9d//Vf84Q9/iMmTJ8d+++0XTz31VPyf//N/oqioKL70pS/FPffc05Td7lJ1dXX06NGj3tjIkSNj0KBBccYZZ8SSJUsiIuKAAw6I7du315u3bdu2KC7O3OsAAAAAYAdNCvInnHBC/PCHP4yIiNNOOy2KioriwAMPjOHDh8fVV1+920G+rKwsunbtml/u3Llz9OzZM9asWRPLli2L8ePHR2VlZQwfPjxSSrFgwYJ6269evTo2b95cb/y3v/1tXHXVVbF06dJYsGBB9OrVK7797W/Hf/zHfzTlUAEAAKBVadJl6oqKilizZk1ERJx88snxm9/8JjZt2hQPPPBA/m3xu6NPnz4xd+7cmDt3bkRETJw4MebOnRvjxo2LiIiOHTvGoYce2qjevvnNb8avf/3ruPnmm+OFF16IH/3oR/HTn/40vve97zVqPwAAANAaFcU799g3yosvvhhXX311PPDAA7FkyZL40pe+FI888kh84hOfiJkzZ0a7du1aoNU9J5fLRXV1dZSXl0dNTU2h2wEAAOADrjE5tEm31t94441x9913x4YNG+K1116LWbNmRcQ7t9zPnz+/KbsEAAAAdkOTgvwtt9wSTz75ZBxyyCHx8MMPR0rvXNRfvHhxXH311c3aIAAAAPC/mnRr/QedW+sBAADYk1rk1vrrr79+txv4zne+s9tzAQAAgN2320G+V69e9ZZ79+4dJSUl8eKLL0ZERLdu3WLbtm3x9NNPN2+HAAAAQN5uB/lBgwbl/3zZZZdFTU1NDB8+PNatWxcREQceeGBMmTIlHnvssWZvEgAAAHhHk56Rf/3112Pw4MHx/PPP1xs/6qij4qGHHorKysrm6q8gPCMPAADAntSYHFrclA8oLy9v8Lvi27VrF7lcrim7BAAAAHZDk4L8vffeG1OmTInTTjstKisro7KyMk4//fT4+c9/Hvfcc09z9wgAAAD8VZO+R/6iiy6KH/3oRzF16tTYd999IyJi69at8fOf/zwuv/zyZm0QAAAA+F+Nfka+uLg4PvWpT8X8+fOjtrY2Dj/88IiIeOWVV2Ljxo0t0eMe5xl5AAAA9qQW+R75d23fvj0eeuihOPLII+PVV1+N+fPnN7lRAAAAoHGa9Iz8X/7yl+jSpUtz9wIAAAC8hyYF+auvvjp+9KMfxec///no0KFD5HK5egUAAAC0jCZ9j/y2bdvyf07pfzcvKiqKlFKUlDTpHXqthmfkAQAA2JNa9Bn5iIhPf/rTTWoMAAAAeH+aFOT/8Ic/NHcfAAAAwG54X/fA77///nHooYdGaWlpvXFvsgcAAICW0aQg37Zt25gyZUqccsopDe8048/IAwAAQGvVpLfW33jjjXHggQfGJz/5ydi0aVOcfPLJMXz48Fi0aFGceuqpzd0jAAAA8FdNunQ+aNCgGDJkSDz99NOxffv2eO2112LGjBlRXV0do0ePjgcffLC5+wQAAACiiVfky8rKYvXq1RERsXbt2mjXrl1EvPNsfO/evZuvOwAAAKCeJgX5F198Mbp37x4REfPmzYsLL7wwOnXqFBdddFGsWLGiWRsEAAAA/leTbq3/8Y9/HB07doyIiLFjx8b06dPjnHPOidra2hgxYkRz9gcAAAD8jaKISO93J/vvv38cccQRsXTp0njrrbeaoa3CyuVyUV1dHeXl5VFTU1PodgAAAPiAa0wObdKt9Z07d663vGnTpnj22Wc/ECEeAAAAWrMm3Vr/8ssvx+uvvx6PPvpozJo1Kx599NF45ZVXmrs3AAAA4O806Yr8IYccEqNHj45NmzbFFVdcES+99FIsW7Ys7rrrrvjqV7/a3D0CAAAAf9Usz8h37do1rrrqqjjnnHOiuLg4SkqadKG/1fCMPAAAAHtSY3JokxL3/vvvH/37948TTzwxTjzxxOjVq1csXLgwbrrpppg1a1ZTdgkAAADshiYF+XXr1sXatWvj7rvvjgkTJsRjjz0W69ata+bWAAAAgL/XpCD/4IMPRv/+/eNLX/pSdOjQITp06BCzZs2KRYsWNXd/AAAAwN9o0svuTjvttGjXrl2cfPLJMXv27Bg8eHA89thj8frrr8ddd93V3D0CAAAAf/W+3ko3f/78KCkpidLS0thvv/3ic5/7XJx11llx7rnnNld/AAAAwN9o0hX5yy67LKZNmxZvvfVW/OlPf4qzzz47XnrppRg2bFi0a9euuXsEAAAA/qpJV+TPPvvsePTRR+NnP/tZPPbYY1FdXd3cfQEAAAANaNIV+eOOOy4uv/zyeOCBB95XiB8wYEDcf//9UVVVFSmlGDJkyG5v269fv6irq4tnn312h3WdOnWKX/ziF/Hmm2/Gxo0b47nnnotjjjmmyX0CAABAa9GkIB8R0b9///jFL34Rf/zjH6NTp04REXHuuefGpz71qd3eR1lZWcybNy9GjRrVqM+uqKiIO++8M2bOnLnDugMPPDCeeOKJqKuri1NOOSU+9rGPxXe+851Yu3Ztoz4DAAAAWqMm3Vp/+umnxy9+8Yu4++67o1evXtGmTZuIeCdg/8u//Et8/vOf3639TJ8+PaZPn97oz7/11ltj6tSpsW3bthg6dGi9dVdeeWUsW7YsvvKVr+THXn311UZ/BgAAALRGTboif/XVV8dFF10UX//616Ouri4//sQTT0Tv3r2brbmGjBgxIrp06RJjx45tcP2pp54aTz31VPzqV7+KVatWxTPPPBMXXHDBLvdZWloauVyuXgEAAEBr1KQg37179/jDH/6ww/j69evjwAMPfL897VTXrl1jwoQJce6558a2bdsanNOlS5e4+OKLY9GiRfG5z30ubrnllvjJT34S55133k73O3r06Kiurs5XVVVVSx0CAAAAvC9NCvIrV66Mrl277jDev3//WLx48ftuqiHFxcUxderUGDNmTCxatGiX85555pm46qqrYu7cuXHbbbfFbbfdFhdddNFOt7n22mujvLw8X5WVlS1xCAAAAPC+NekZ+dtuuy1+/OMfx1e+8pVIKUWnTp2ib9++cf3118e4ceOau8eIiMjlcnHsscdGr1694qabboqId0J7cXFx1NXVxeDBg+ORRx6JFStWxPPPP19v2xdeeCGGDRu2033X1tZGbW1ti/QNAAAAzalJQX7ChAlRXFwcM2fOjAMOOCD+8Ic/xJYtW+Lf/u3f4t///d+bu8eIiKiuro4ePXrUGxs5cmQMGjQozjjjjFiyZElEvPOcfvfu3evN69atW7z22mst0hcAAADsSU3++rnx48fHQQcdFD169Ijjjz8+2rVrF+vXr88H6t1RVlYWPXv2jJ49e0ZEROfOnaNnz55xyCGH5D/jjjvuiIiIlFIsWLCgXq1evTo2b94cCxYsiI0bN0ZExMSJE+P444+P0aNHx+GHHx5nn312fP3rX4/Jkyc39VABAACg1WhUkC8tLY3x48fHn//853j88cfjH//xH+OFF16Io446Kl588cW45JJLYuLEibu9vz59+sTcuXNj7ty5EfFOCJ87d27+9vyOHTvGoYce2pgW46mnnorTTjstzj777PjLX/4S3/ve9+LSSy+NqVOnNmo/AAAA0BoVRUTa3ckTJkyICy+8MGbMmBH9+vWLdu3axZQpU+L444+P8ePHx3//93/H9u3bW7DdPSOXy0V1dXWUl5dHTU1NodsBAADgA64xObRRz8h/8YtfjPPOOy9++9vfxlFHHRXPPfdclJSU5G+NBwAAAFpWo26t/8hHPhJPP/10REQsWLAgtmzZ0qhb6QEAAID3p1FBfp999qn3NW1bt26NDRs2NHtTAAAAQMMadWt9UVFR3H777bFly5aIiNhvv/3i1ltvjbfffrvevF19ZzsAAADQdI0K8u9+Fdy77rrrrmZtBgAAANi1RgX5r3zlKy3VBwAAALAbGvWMPAAAAFBYgjwAAABkiCAPAAAAGSLIAwAAQIYI8gAAAJAhgjwAAABkiCAPAAAAGSLIAwAAQIYI8gAAAJAhgjwAAABkiCAPAAAAGSLIAwAAQIYI8gAAAJAhgjwAAABkiCAPAAAAGSLIAwAAQIYI8gAAAJAhgjwAAABkiCAPAAAAGSLIAwAAQIYI8gAAAJAhgjwAAABkiCAPAAAAGSLIAwAAQIYI8gAAAJAhgjwAAABkiCAPAAAAGSLIAwAAQIYI8gAAAJAhgjwAAABkiCAPAAAAGVLQID9gwIC4//77o6qqKlJKMWTIkN3etl+/flFXVxfPPvvsTudceeWVkVKKiRMnNke7AAAAUHAFDfJlZWUxb968GDVqVKO2q6ioiDvvvDNmzpy50zl9+vSJCy+8MObNm/d+2wQAAIBWo6BBfvr06fG9730v7rvvvkZtd+utt8bUqVNj9uzZDa4vKyuLu+++O772ta/F2rVrm6FTAAAAaB0y94z8iBEjokuXLjF27Nidzpk8eXI88MADu7xi/7dKS0sjl8vVKwAAAGiNSgrdQGN07do1JkyYEAMGDIht27Y1OOess86K3r17x7HHHrvb+x09enR8//vfb6YuAQAAoOVk5op8cXFxTJ06NcaMGROLFi1qcM5HPvKR+PGPfxznnHNObNmyZbf3fe2110Z5eXm+Kisrm6ttAAAAaFZFEZEK3UREREophg4dGtOmTWtwfUVFRaxbty62bt2aHysuLo7i4uLYunVrDB48OMrLy+O+++6rN6ekpCS2b98e27dvjzZt2sT27dvfs5dcLhfV1dVRXl4eNTU17//gAAAAYBcak0Mzc2t9dXV19OjRo97YyJEjY9CgQXHGGWfEkiVLori4eIc5U6ZMiYULF8Z11123WyEeAAAAWrOCBvmysrLo2rVrfrlz587Rs2fPWLNmTSxbtizGjx8flZWVMXz48EgpxYIFC+ptv3r16ti8eXO98b+f8/bbb8dbb721wzgAAABkUUGDfJ8+fWLWrFn55YkTJ0ZExO233x7nn39+dOzYMQ499NACdQcAAACtT6t5Rr418Yw8AAAAe1Jjcmhm3loPAAAACPIAAACQKYI8AAAAZIggDwAAABkiyAMAAECGCPIAAACQIYI8AAAAZIggDwAAABkiyAMAAECGCPIAAACQIYI8AAAAZIggDwAAABkiyAMAAECGCPIAAACQIYI8AAAAZIggDwAAABkiyAMAAECGCPIAAACQIYI8AAAAZIggDwAAABkiyAMAAECGCPIAAACQIYI8AAAAZIggDwAAABkiyAMAAECGCPIAAACQIYI8AAAAZIggDwAAABkiyAMAAECGCPIAAACQIYI8AAAAZIggDwAAABkiyAMAAECGCPIAAACQIYI8AAAAZIggDwAAABkiyAMAAECGFDTIDxgwIO6///6oqqqKlFIMGTJkt7ft169f1NXVxbPPPltv/Lvf/W48+eSTUV1dHatWrYp77703unXr1tytAwAAQEEUNMiXlZXFvHnzYtSoUY3arqKiIu68886YOXPmDusGDhwYkydPjuOPPz4++9nPxr777hsPPfRQHHDAAc3VNgAAABRMUUSkQjcREZFSiqFDh8a0adPec+4vf/nLWLRoUWzbti2GDh0avXr12unctm3bxhtvvBEnnHBCPPbYY7vVSy6Xi+rq6igvL4+amprdPgYAAABoisbk0Mw9Iz9ixIjo0qVLjB07drfmV1RURETEmjVrdjqntLQ0crlcvQIAAIDWKFNBvmvXrjFhwoQ499xzY9u2be85v6ioKG688cZ4/PHHY8GCBTudN3r06Kiurs5XVVVVc7YNAAAAzSYzQb64uDimTp0aY8aMiUWLFu3WNpMnT44ePXrEl770pV3Ou/baa6O8vDxflZWVzdEyAAAANLuSQjewu3K5XBx77LHRq1evuOmmmyLinXBfXFwcdXV1MXjw4HjkkUfy8ydNmhRf+MIX4oQTTnjPK+y1tbVRW1vbov0DAABAc8hMkK+uro4ePXrUGxs5cmQMGjQozjjjjFiyZEl+fNKkSXHaaafFiSeeGK+++uoe7hQAAABaTkGDfFlZWXTt2jW/3Llz5+jZs2esWbMmli1bFuPHj4/KysoYPnx4pJR2eM599erVsXnz5nrjkydPji9/+csxZMiQqKmpifbt20dExPr162Pz5s175sAAAACghRT0Gfk+ffrE3LlzY+7cuRERMXHixJg7d26MGzcuIiI6duwYhx56aKP2OXLkyDjwwAPj0UcfjZUrV+brrLPOau72AQAAYI9rNd8j35r4HnkAAAD2pA/098gDAADA3kyQBwAAgAwR5AEAACBDBHkAAADIEEEeAAAAMkSQBwAAgAwR5AEAACBDBHkAAADIEEEeAAAAMkSQBwAAgAwR5AEAACBDBHkAAADIEEEeAAAAMkSQBwAAgAwR5AEAACBDBHkAAADIEEEeAAAAMkSQBwAAgAwR5AEAACBDBHkAAADIEEEeAAAAMkSQBwAAgAwR5AEAACBDBHkAAADIEEEeAAAAMkSQBwAAgAwR5AEAACBDBHkAAADIEEEeAAAAMkSQBwAAgAwR5AEAACBDBHkAAADIEEEeAAAAMkSQBwAAgAwR5AEAACBDBHkAAADIkIIG+QEDBsT9998fVVVVkVKKIUOG7Pa2/fr1i7q6unj22Wd3WDdy5MhYsmRJbNq0KebMmRPHHntsc7YNAAAABVPQIF9WVhbz5s2LUaNGNWq7ioqKuPPOO2PmzJk7rDvzzDPjhhtuiLFjx0bv3r1j3rx58fvf/z7atWvXXG0DAABAwRRFRCp0ExERKaUYOnRoTJs27T3n/vKXv4xFixbFtm3bYujQodGrV6/8ujlz5sSf//zn+OY3vxkREUVFRbFs2bKYNGlSXHfddbvVSy6Xi+rq6igvL4+ampqmHRAAAADspsbk0Mw9Iz9ixIjo0qVLjB07dod1++67bxxzzDExY8aM/FhKKWbMmBF9+/bd6T5LS0sjl8vVKwAAAGiNMhXku3btGhMmTIhzzz03tm3btsP6tm3bRklJSaxatare+KpVq6JDhw473e/o0aOjuro6X1VVVc3eOwAAADSHzAT54uLimDp1aowZMyYWLVrUrPu+9tpro7y8PF+VlZXNun8AAABoLiWFbmB35XK5OPbYY6NXr15x0003RcQ74b64uDjq6upi8ODB8fjjj8fWrVujffv29bZt3759rFy5cqf7rq2tjdra2hbtHwAAAJpDZq7IV1dXR48ePeLoo4/O16233hoLFy6Mo48+Ov70pz9FXV1dPP3003HSSSfltysqKoqTTjopZs+eXcDuAQAAoHkU9Ip8WVlZdO3aNb/cuXPn6NmzZ6xZsyaWLVsW48ePj8rKyhg+fHiklGLBggX1tl+9enVs3ry53vgNN9wQd9xxRzz11FPx5JNPxqWXXhplZWUxZcqUPXZcAAAA0FIKGuT79OkTs2bNyi9PnDgxIiJuv/32OP/886Njx45x6KGHNmqfv/rVr6Jdu3Yxbty46NChQ8ydOzdOPvnkWL16dXO2DgAAAAXRar5HvjXxPfIAAADsSR/o75EHAACAvZkgDwAAABkiyAMAAECGCPIAAACQIYI8AAAAZIggDwAAABkiyAMAAECGCPIAAACQIYI8AAAAZIggDwAAABkiyAMAAECGCPIAAACQIYI8AAAAZIggDwAAABkiyAMAAECGCPIAAACQIYI8AAAAZIggDwAAABkiyAMAAECGCPIAAACQIYI8AAAAZIggDwAAABkiyAMAAECGlBS6gdYsl8sVugUAAAD2Ao3Jn4J8A979AVZVVRW4EwAAAPYmuVwuampqdjmnKCLSnmknWzp16vSePzw+eHK5XFRVVUVlZaW/f1ol5yitnXOU1s45SmvnHN275XK5WL58+XvOc0V+J3bnh8cHV01NjV+ctGrOUVo75yitnXOU1s45unfa3b9zL7sDAACADBHkAQAAIEMEefgbW7Zsie9///uxZcuWQrcCDXKO0to5R2ntnKO0ds5RdoeX3QEAAECGuCIPAAAAGSLIAwAAQIYI8gAAAJAhgjwAAABkiCDPXuVDH/pQ3HXXXbF+/fpYu3Zt/Pu//3uUlZXtcps2bdrETTfdFG+++WbU1NTEr3/96/jwhz/c4NyDDjooli1bFimlqKioaIlD4AOuJc7RT3ziEzF16tRYunRpbNy4MZ5//vn41re+1dKHwgfIyJEjY8mSJbFp06aYM2dOHHvssbucf8YZZ8QLL7wQmzZtiueeey5OOeWUHeaMHTs2li9fHhs3boyHH344unbt2lLtsxdoznO0pKQkJkyYEM8991xs2LAhqqqq4o477oiOHTu29GHwAdYSv0ffdcstt0RKKS655JLmbptWLim1t9SDDz6Ynn322XTcccelT33qU+mll15Kd9999y63ufnmm9Nrr72WPv3pT6fevXunP/7xj+nxxx9vcO69996bHnjggZRSShUVFQU/XpW9aolz9Pzzz0833nhjOuGEE1Lnzp3TOeeck95+++00atSogh+vav115plnps2bN6cRI0akI488Mv30pz9Na9asSe3atWtwft++fVNdXV3653/+53TEEUekcePGpS1btqSjjjoqP+eKK65Ia9euTaeeemr6+Mc/nu677770yiuvpDZt2hT8eFX2qrnP0fLy8vTQQw+lL37xi6lbt27pk5/8ZJozZ07685//XPBjVdmslvg9+m4NHTo0Pfvss+n1119Pl1xyScGPVe3RKngDSu2ROuKII1JKKR1zzDH5sc997nNp27ZtqWPHjg1uU15enrZs2ZKGDRuWH+vevXtKKaVPfvKT9eZedNFF6ZFHHkmf/vSnBXnVpGrpc/Rv66abbkozZ84s+DGr1l9z5sxJkyZNyi8XFRWl119/PV155ZUNzv/P//zP9Nvf/rbe2OzZs9Mtt9ySX16+fHn6zne+k18uLy9PmzZtSmeddVbBj1dlr1riHP376tOnT0oppUMOOaTgx6uyVy11jnbq1CktW7YsfexjH0tLliwR5Peycms9e42+ffvG2rVr4+mnn86PzZgxI7Zv3x6f/OQnG9zmmGOOidLS0pgxY0Z+7MUXX4zXXnst+vbtmx878sgj45prronzzjsvtm/f3nIHwQdaS56jf6+ioiLWrFnTfM3zgbTvvvvGMcccU+/8SinFjBkzdnp+9e3bt978iIjf//73+fmdO3eOjh071ptTXV0df/rTn3Z5zkJDWuIcbUhFRUVs37491q1b1yx9s/doqXO0qKgofvGLX8S//du/xfPPP98yzdOqCfLsNTp06BCrV6+uN7Zt27ZYs2ZNdOjQYafbbNmyJdavX19vfNWqVfltSktL45e//GVcfvnlsWzZspZpnr1CS52jf69v375x1llnxc9+9rPmaZwPrLZt20ZJSUmsWrWq3viuzq8OHTrscv67/23MPmFnWuIc/Xtt2rSJ6667Ln75y19GTU1N8zTOXqOlztErr7wytm7dGj/5yU+av2kyQZAn86699tpIKe2yunfv3qKf/8ILL8Tdd9/dYp9BthX6HP1bRx11VEybNi3Gjh0bDz/88B75TICsKikpiV/96ldRVFQUF198caHbgYiI6N27d1xyySUxYsSIQrdCAZUUugF4v66//vq4/fbbdzln8eLFsXLlyh3eNr/PPvvEQQcdFCtXrmxwu5UrV0abNm2ioqKi3hXP9u3b57cZNGhQfPzjH48zzjgjIt651Ski4s0334wf/vCH8f3vf7+JR8YHRaHP0XcdeeSRMXPmzPjZz34WP/zhD5t2MOxV3nzzzdi6dWu0b9++3nhD59e7Vq5cucv57/737/fRvn37mDt3bjN2z96gJc7Rd70b4g877LAYNGiQq/E0SUucowMGDIgPf/jDsXTp0vz6kpKSuP766+PSSy+Nzp07N/NR0FoV/EF9pfZEvfsisd69e+fHPvvZz+7Wi8ROP/30/Fi3bt3qvUisS5cu6aijjsrXiBEjUkopHX/88Tt9G6lSDVVLnaMRkT72sY+llStXpuuuu67gx6myVXPmzEk/+clP8stFRUVp2bJlu3xJ0/33319v7IknntjhZXff/va388u5XM7L7lSTqyXO0ZKSknTPPfek+fPnp7Zt2xb8GFW2q7nP0YMOOqjevz2POuqo9Prrr6drr702devWreDHq/ZYFbwBpfZYPfjgg+npp59Oxx57bOrXr1968cUX6321V6dOndILL7yQjj322PzYzTffnF599dV04oknpt69e6cnnngiPfHEEzv9jIEDB3prvWpytcQ5etRRR6VVq1alO++8M7Vv3z5f/nGqdqfOPPPMtGnTpnTeeeelI444It16661pzZo16cMf/nCKiHTHHXek8ePH5+f37ds31dbWpm9/+9upe/fuacyYMQ1+/dyaNWvSP/3TP6UePXqke++919fPqSZXc5+jJSUl6b777ktLly5Nn/jEJ+r93tx3330Lfrwqe9USv0f/vry1fq+sgjeg1B6rD33oQ+nuu+9O1dXVad26dennP/95Kisry68/7LDDUkopDRw4MD/Wpk2bdNNNN6W33norbdiwIf3mN79J7du33+lnCPLq/VRLnKNjxoxJDVmyZEnBj1dlo0aNGpVeffXVtHnz5jRnzpx03HHH5dc98sgjacqUKfXmn3HGGWnhwoVp8+bNaf78+emUU07ZYZ9jx45NK1asSJs2bUoPP/xw+uhHP1rw41TZreY8R9/9PduQv/3dq1RjqiV+j/5tCfJ7XxX99Q8AAABABnhrPQAAAGSIIA8AAAAZIsgDAABAhgjyAAAAkCGCPAAAAGSIIA8AAAAZIsgDAABAhgjyAAAAkCGCPAAAAGSIIA8ANKht27Zx8803x2uvvRabN2+OFStWxPTp06Nfv34REZFSiiFDhhS4SwDY+5QUugEAoHX6zW9+E6WlpTF8+PBYvHhxtG/fPk466aQ4+OCDC90aAOz1klJKKaXU31ZFRUVKKaUTTjihwfVLlixJf2vJkiX5daeeemp6+umn06ZNm9Irr7ySrrnmmrTPPvvk16eU0kUXXZQefPDBtHHjxvTKK6+kYcOGFfyYlVJKqQxVwRtQSimlVCurffbZJ1VXV6cbbrghlZaW7rC+bdu2KaWUhg8fntq3b5/atm2bIiL1798/rVu3Lp133nmpc+fO6TOf+UxavHhxuuaaa/LbppTSG2+8kb761a+mj370o2ncuHGprq4uHXHEEQU/bqWUUiojVfAGlFJKKdUK6/TTT09vvfVW2rhxY3r88cfTD3/4w/Txj388vz6llIYMGVJvm4cffjh997vfrTd2zjnnpKqqqnrb3XzzzfXmzJ49O02ePLngx6yUUkplobzsDgBo0D333BOdOnWKU089NaZPnx4nnnhiPPPMMzF8+PCdbtOzZ8+45pproqamJl+33XZbdOrUKfbff//8vNmzZ9fbbvbs2XHkkUe22LEAwAeJl90BADu1ZcuWmDFjRsyYMSN+8IMfxG233RZjx46NO+64o8H5//AP/xBjxoyJe+65Z4d1mzdvbul2AWCv4Io8ALDbnn/++SgrK4uIiNra2thnn33qrX/mmWeie/fu8corr+xQKaX8vOOPP77edscff3y88MILLX8AAPAB4Io8ALCDgw46KP77v/87/uM//iOee+65qKmpiT59+sQVV1wR06ZNi4iIV199NU466aR44oknYsuWLbFu3boYN25c/M///E8sXbo0fv3rX8f27dujZ8+e0aNHj/je976X3/8Xv/jFeOqpp+Lxxx+Pc845J4477rj46le/WqjDBYDMKfiD+koppZRqXVVaWprGjx+fnnrqqbR27dq0YcOG9MILL6Rx48al/fbbL0VE+sIXvpBeeumlVFtbW+/r5wYPHpwef/zx9Pbbb6d169alOXPmpAsuuCC/PqWULr744vT73/8+bdq0KS1evDh98YtfLPgxK6WUUlmpor/+AQBgj0gpxdChQ/NX9gGAxvGMPAAAAGSIIA8AAAAZ4tZ6AAAAyBBX5AEAACBDBHkAAADIEEEeAAAAMkSQBwAAgAwR5AEAACBDBHkAAADIEEEeAAAAMkSQBwAAgAz5/y2ZVwbihqacAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reward mean=1.47: 100%|██████████| 1/1 [00:20<00:00, 20.10s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from itertools import count\n",
    "import matplotlib.pyplot as plt\n",
    "plot_every = 1\n",
    "train_steps = 1\n",
    "\n",
    "with tqdm(total=train_steps) as pbar:\n",
    "    for i in count() if train_steps == 0 else range(train_steps):\n",
    "        try:\n",
    "            results = algo.train()\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Interrupting training\")\n",
    "            checkpoint_path = algo.save(save_dir)\n",
    "            print(f\"Checkpoint saved at: {checkpoint_path}\")\n",
    "            break\n",
    "        pbar.set_description(f\"reward mean={results['episode_reward_mean']:.02f}\")\n",
    "        results_history.append(results)\n",
    "        pbar.update()\n",
    "        if i % plot_every == 0:\n",
    "            plot(results_history)\n",
    "            pbar.display()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learner': {'default_policy': {'custom_metrics': {},\n",
       "   'learner_stats': {'cur_kl_coeff': 0.6750000000000002,\n",
       "    'cur_lr': 0.00010000000000000003,\n",
       "    'total_loss': -0.022744262916967274,\n",
       "    'policy_loss': -0.0668562723784357,\n",
       "    'vf_loss': 0.03365269314738051,\n",
       "    'vf_explained_var': 0.999404497684971,\n",
       "    'kl': 0.015495284816763972,\n",
       "    'entropy': 0.6587168878124606,\n",
       "    'entropy_coeff': 0.0},\n",
       "   'model': {},\n",
       "   'num_grad_updates_lifetime': 465.5,\n",
       "   'diff_num_grad_updates_vs_sampler_policy': 464.5}},\n",
       " 'num_env_steps_sampled': 312000,\n",
       " 'num_env_steps_trained': 312000,\n",
       " 'num_agent_steps_sampled': 312000,\n",
       " 'num_agent_steps_trained': 312000}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"info\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'saved_models\\\\Platoon-v2-curious-2\\\\checkpoint_000078'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.save(save_dir)\n",
    "# checkpoint path is grabbed by glob when restoring earlier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 18:04:45,890\tINFO algorithm.py:882 -- Evaluating current policy for 10 episodes.\n",
      "2023-01-10 18:04:45,891\tINFO rollout_worker.py:905 -- Generating sample batch of size 400\n",
      "2023-01-10 18:04:45,892\tINFO sampler.py:610 -- Raw obs from env: { 0: { 'agent0': np.ndarray((20,), dtype=float32, min=-10.0, max=8.0, mean=-0.05)}}\n",
      "2023-01-10 18:04:45,893\tINFO sampler.py:611 -- Info return from env: {0: {'agent0': {}}}\n",
      "2023-01-10 18:04:45,894\tINFO sampler.py:853 -- Preprocessed obs: np.ndarray((20,), dtype=float32, min=-10.0, max=8.0, mean=-0.05)\n",
      "2023-01-10 18:04:45,895\tINFO sampler.py:858 -- Filtered obs: np.ndarray((20,), dtype=float32, min=-10.0, max=8.0, mean=-0.05)\n",
      "2023-01-10 18:04:45,897\tINFO sampler.py:1144 -- Inputs to compute_actions():\n",
      "\n",
      "{ 'default_policy': [ { 'data': { 'agent_id': 'agent0',\n",
      "                                  'env_id': 0,\n",
      "                                  'info': {},\n",
      "                                  'obs': np.ndarray((20,), dtype=float32, min=-10.0, max=8.0, mean=-0.05),\n",
      "                                  'prev_action': None,\n",
      "                                  'prev_reward': 0.0,\n",
      "                                  'rnn_state': None},\n",
      "                        'type': '_PolicyEvalData'}]}\n",
      "\n",
      "2023-01-10 18:04:45,904\tINFO sampler.py:1171 -- Outputs of compute_actions():\n",
      "\n",
      "{ 'default_policy': ( np.ndarray((1,), dtype=int64, min=9.0, max=9.0, mean=9.0),\n",
      "                      [],\n",
      "                      { 'action_dist_inputs': np.ndarray((1, 11), dtype=float32, min=-10.254, max=7.935, mean=-0.081),\n",
      "                        'action_logp': np.ndarray((1,), dtype=float32, min=-0.052, max=-0.052, mean=-0.052),\n",
      "                        'action_prob': np.ndarray((1,), dtype=float32, min=0.95, max=0.95, mean=0.95),\n",
      "                        'vf_preds': np.ndarray((1,), dtype=float32, min=12.236, max=12.236, mean=12.236)})}\n",
      "\n",
      "2023-01-10 18:04:45,944\tINFO simple_list_collector.py:520 -- Trajectory fragment after postprocess_trajectory():\n",
      "\n",
      "{ 'agent0': { 'action_dist_inputs': np.ndarray((11, 11), dtype=float32, min=-10.254, max=7.935, mean=-0.062),\n",
      "              'action_logp': np.ndarray((11,), dtype=float32, min=-1.281, max=-0.052, mean=-0.501),\n",
      "              'actions': np.ndarray((11,), dtype=int64, min=0.0, max=10.0, mean=3.636),\n",
      "              'advantages': np.ndarray((11,), dtype=float32, min=0.106, max=0.79, mean=0.528),\n",
      "              'agent_index': np.ndarray((11,), dtype=int32, min=0.0, max=0.0, mean=0.0),\n",
      "              'eps_id': np.ndarray((11,), dtype=int64, min=6.608091317004686e+17, max=6.608091317004686e+17, mean=6.608091317004686e+17),\n",
      "              'infos': np.ndarray((11,), dtype=object, head={}),\n",
      "              'new_obs': np.ndarray((11, 20), dtype=float32, min=-10.0, max=8.0, mean=0.182),\n",
      "              'obs': np.ndarray((11, 20), dtype=float32, min=-10.0, max=8.0, mean=0.155),\n",
      "              'rewards': np.ndarray((11,), dtype=float32, min=-0.01, max=0.23, mean=0.176),\n",
      "              't': np.ndarray((11,), dtype=int32, min=0.0, max=10.0, mean=5.0),\n",
      "              'terminateds': np.ndarray((11,), dtype=bool, min=0.0, max=0.0, mean=0.0),\n",
      "              'truncateds': np.ndarray((11,), dtype=bool, min=0.0, max=1.0, mean=0.091),\n",
      "              'unroll_id': np.ndarray((11,), dtype=int32, min=0.0, max=0.0, mean=0.0),\n",
      "              'value_targets': np.ndarray((11,), dtype=float32, min=12.529, max=13.141, mean=12.922),\n",
      "              'vf_preds': np.ndarray((11,), dtype=float32, min=12.236, max=12.466, mean=12.394)}}\n",
      "\n",
      "2023-01-10 18:04:47,132\tINFO rollout_worker.py:946 -- Completed sample batch:\n",
      "\n",
      "{ 'action_dist_inputs': np.ndarray((400, 11), dtype=float32, min=-12.485, max=18.127, mean=-0.03),\n",
      "  'action_logp': np.ndarray((400,), dtype=float32, min=-5.646, max=0.0, mean=-0.667),\n",
      "  'actions': np.ndarray((400,), dtype=int64, min=0.0, max=10.0, mean=4.588),\n",
      "  'advantages': np.ndarray((400,), dtype=float32, min=-1.767, max=1.152, mean=0.198),\n",
      "  'agent_index': np.ndarray((400,), dtype=int32, min=0.0, max=0.0, mean=0.0),\n",
      "  'eps_id': np.ndarray((400,), dtype=int64, min=248442009557203.0, max=9.871140891059191e+17, mean=5.869924836113421e+17),\n",
      "  'infos': np.ndarray((400,), dtype=object, head={}),\n",
      "  'new_obs': np.ndarray((400, 20), dtype=float32, min=-10.0, max=10.0, mean=0.289),\n",
      "  'obs': np.ndarray((400, 20), dtype=float32, min=-10.0, max=10.0, mean=0.263),\n",
      "  'rewards': np.ndarray((400,), dtype=float32, min=-0.22, max=0.48, mean=0.147),\n",
      "  't': np.ndarray((400,), dtype=int32, min=0.0, max=10.0, mean=4.965),\n",
      "  'terminateds': np.ndarray((400,), dtype=bool, min=0.0, max=0.0, mean=0.0),\n",
      "  'truncateds': np.ndarray((400,), dtype=bool, min=0.0, max=1.0, mean=0.09),\n",
      "  'unroll_id': np.ndarray((400,), dtype=int32, min=0.0, max=36.0, mean=17.685),\n",
      "  'value_targets': np.ndarray((400,), dtype=float32, min=-11.92, max=26.539, mean=12.809),\n",
      "  'vf_preds': np.ndarray((400,), dtype=float32, min=-11.931, max=26.355, mean=12.611)}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'evaluation': {'episode_reward_max': 3.79,\n",
       "  'episode_reward_min': -1.17,\n",
       "  'episode_reward_mean': 1.488953168044077,\n",
       "  'episode_len_mean': 11.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 363,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [1.94,\n",
       "    2.73,\n",
       "    3.36,\n",
       "    2.22,\n",
       "    -0.44999999999999996,\n",
       "    1.96,\n",
       "    1.43,\n",
       "    2.27,\n",
       "    2.77,\n",
       "    1.32,\n",
       "    0.8899999999999999,\n",
       "    2.1100000000000003,\n",
       "    1.4300000000000002,\n",
       "    1.06,\n",
       "    2.07,\n",
       "    2.91,\n",
       "    1.26,\n",
       "    1.91,\n",
       "    2.87,\n",
       "    2.69,\n",
       "    0.9299999999999999,\n",
       "    1.23,\n",
       "    1.3499999999999999,\n",
       "    1.64,\n",
       "    2.2399999999999998,\n",
       "    1.52,\n",
       "    1.28,\n",
       "    -0.42000000000000004,\n",
       "    1.8399999999999999,\n",
       "    2.03,\n",
       "    0.83,\n",
       "    2.49,\n",
       "    -1.02,\n",
       "    1.52,\n",
       "    1.6899999999999997,\n",
       "    0.7499999999999999,\n",
       "    1.1800000000000002,\n",
       "    1.5899999999999999,\n",
       "    1.45,\n",
       "    2.58,\n",
       "    0.57,\n",
       "    1.52,\n",
       "    2.0700000000000003,\n",
       "    0.8299999999999998,\n",
       "    1.9500000000000002,\n",
       "    1.8,\n",
       "    1.6699999999999997,\n",
       "    2.72,\n",
       "    1.83,\n",
       "    3.29,\n",
       "    1.5100000000000002,\n",
       "    0.5199999999999999,\n",
       "    1.39,\n",
       "    1.1099999999999999,\n",
       "    0.95,\n",
       "    2.8400000000000003,\n",
       "    1.4900000000000002,\n",
       "    0.7,\n",
       "    1.02,\n",
       "    1.3399999999999999,\n",
       "    2.11,\n",
       "    2.23,\n",
       "    0.55,\n",
       "    2.3800000000000003,\n",
       "    2.23,\n",
       "    0.48000000000000004,\n",
       "    -0.03000000000000002,\n",
       "    1.9299999999999997,\n",
       "    1.5899999999999999,\n",
       "    1.21,\n",
       "    1.34,\n",
       "    1.6600000000000001,\n",
       "    1.6900000000000002,\n",
       "    1.4799999999999998,\n",
       "    -0.6200000000000001,\n",
       "    1.5699999999999998,\n",
       "    3.02,\n",
       "    2.17,\n",
       "    0.8500000000000001,\n",
       "    1.56,\n",
       "    1.5999999999999999,\n",
       "    1.35,\n",
       "    1.97,\n",
       "    1.0100000000000002,\n",
       "    -0.5599999999999999,\n",
       "    2.34,\n",
       "    2.16,\n",
       "    1.26,\n",
       "    2.1900000000000004,\n",
       "    2.19,\n",
       "    1.49,\n",
       "    1.89,\n",
       "    0.9099999999999999,\n",
       "    2.03,\n",
       "    1.3699999999999999,\n",
       "    3.2699999999999996,\n",
       "    1.4100000000000001,\n",
       "    0.45000000000000007,\n",
       "    1.23,\n",
       "    2.44,\n",
       "    0.37,\n",
       "    1.56,\n",
       "    1.9999999999999998,\n",
       "    1.4000000000000001,\n",
       "    -0.6099999999999999,\n",
       "    0.31,\n",
       "    0.83,\n",
       "    2.21,\n",
       "    2.05,\n",
       "    -0.7100000000000001,\n",
       "    2.11,\n",
       "    2.8600000000000003,\n",
       "    1.4,\n",
       "    1.46,\n",
       "    1.5,\n",
       "    0.18,\n",
       "    1.4000000000000001,\n",
       "    2.54,\n",
       "    1.09,\n",
       "    0.27,\n",
       "    1.5000000000000002,\n",
       "    2.06,\n",
       "    1.91,\n",
       "    1.61,\n",
       "    1.4100000000000001,\n",
       "    3.79,\n",
       "    1.55,\n",
       "    1.6199999999999999,\n",
       "    0.7899999999999998,\n",
       "    0.99,\n",
       "    2.3800000000000003,\n",
       "    1.19,\n",
       "    1.54,\n",
       "    1.29,\n",
       "    2.97,\n",
       "    0.6700000000000002,\n",
       "    0.95,\n",
       "    -0.2,\n",
       "    2.39,\n",
       "    2.5000000000000004,\n",
       "    1.3600000000000003,\n",
       "    1.56,\n",
       "    -0.44,\n",
       "    2.1,\n",
       "    1.29,\n",
       "    1.05,\n",
       "    1.31,\n",
       "    0.52,\n",
       "    2.17,\n",
       "    3.2799999999999994,\n",
       "    1.8099999999999998,\n",
       "    2.3,\n",
       "    1.4800000000000002,\n",
       "    0.87,\n",
       "    2.04,\n",
       "    2.16,\n",
       "    -0.7000000000000001,\n",
       "    2.07,\n",
       "    0.35,\n",
       "    1.6700000000000002,\n",
       "    0.63,\n",
       "    2.46,\n",
       "    0.7599999999999999,\n",
       "    1.61,\n",
       "    1.5499999999999998,\n",
       "    0.12,\n",
       "    1.71,\n",
       "    0.56,\n",
       "    2.2,\n",
       "    1.27,\n",
       "    1.58,\n",
       "    1.6399999999999997,\n",
       "    3.19,\n",
       "    1.2399999999999998,\n",
       "    0.71,\n",
       "    2.02,\n",
       "    1.41,\n",
       "    0.59,\n",
       "    1.28,\n",
       "    -0.5599999999999999,\n",
       "    2.13,\n",
       "    1.02,\n",
       "    0.37,\n",
       "    2.16,\n",
       "    2.56,\n",
       "    1.97,\n",
       "    1.7799999999999998,\n",
       "    0.56,\n",
       "    2.11,\n",
       "    -0.020000000000000004,\n",
       "    2.0700000000000003,\n",
       "    -0.16000000000000003,\n",
       "    1.33,\n",
       "    2.69,\n",
       "    2.64,\n",
       "    1.6699999999999997,\n",
       "    0.8199999999999998,\n",
       "    1.42,\n",
       "    1.63,\n",
       "    1.24,\n",
       "    1.77,\n",
       "    1.26,\n",
       "    -0.24000000000000002,\n",
       "    1.09,\n",
       "    0.89,\n",
       "    1.5699999999999998,\n",
       "    -1.17,\n",
       "    1.36,\n",
       "    0.33999999999999997,\n",
       "    0.9,\n",
       "    1.02,\n",
       "    0.73,\n",
       "    1.4900000000000002,\n",
       "    2.47,\n",
       "    0.31999999999999995,\n",
       "    0.99,\n",
       "    0.58,\n",
       "    0.6599999999999999,\n",
       "    0.45,\n",
       "    3.21,\n",
       "    1.3,\n",
       "    0.12000000000000001,\n",
       "    2.76,\n",
       "    1.36,\n",
       "    1.87,\n",
       "    2.4600000000000004,\n",
       "    2.5500000000000003,\n",
       "    1.62,\n",
       "    -0.39999999999999997,\n",
       "    2.63,\n",
       "    2.8,\n",
       "    1.63,\n",
       "    1.6,\n",
       "    1.6499999999999997,\n",
       "    1.4700000000000002,\n",
       "    1.55,\n",
       "    1.46,\n",
       "    1.8199999999999998,\n",
       "    1.3699999999999999,\n",
       "    1.75,\n",
       "    1.06,\n",
       "    0.54,\n",
       "    0.93,\n",
       "    1.2000000000000002,\n",
       "    2.1,\n",
       "    1.1900000000000002,\n",
       "    0.57,\n",
       "    1.4800000000000002,\n",
       "    1.19,\n",
       "    1.93,\n",
       "    1.34,\n",
       "    1.03,\n",
       "    0.73,\n",
       "    1.44,\n",
       "    0.37999999999999995,\n",
       "    2.5599999999999996,\n",
       "    2.96,\n",
       "    1.26,\n",
       "    0.5599999999999999,\n",
       "    -0.14,\n",
       "    3.05,\n",
       "    3.16,\n",
       "    2.54,\n",
       "    0.050000000000000024,\n",
       "    1.1,\n",
       "    0.18000000000000005,\n",
       "    1.91,\n",
       "    1.45,\n",
       "    1.01,\n",
       "    0.22,\n",
       "    1.54,\n",
       "    1.83,\n",
       "    2.8,\n",
       "    1.16,\n",
       "    1.83,\n",
       "    0.85,\n",
       "    0.54,\n",
       "    1.8299999999999998,\n",
       "    1.81,\n",
       "    2.5500000000000003,\n",
       "    2.5100000000000002,\n",
       "    2.94,\n",
       "    1.95,\n",
       "    0.71,\n",
       "    2.53,\n",
       "    3.16,\n",
       "    0.6599999999999999,\n",
       "    2.44,\n",
       "    1.23,\n",
       "    -0.020000000000000004,\n",
       "    3.5100000000000002,\n",
       "    2.5200000000000005,\n",
       "    0.9700000000000002,\n",
       "    2.3,\n",
       "    2.21,\n",
       "    0.7300000000000001,\n",
       "    0.6000000000000001,\n",
       "    3.08,\n",
       "    1.1700000000000002,\n",
       "    1.15,\n",
       "    1.15,\n",
       "    1.78,\n",
       "    1.6699999999999997,\n",
       "    1.44,\n",
       "    -0.24000000000000002,\n",
       "    3.3699999999999997,\n",
       "    -0.26,\n",
       "    1.78,\n",
       "    1.94,\n",
       "    1.95,\n",
       "    0.9500000000000001,\n",
       "    0.8300000000000001,\n",
       "    2.16,\n",
       "    1.7499999999999998,\n",
       "    2.19,\n",
       "    2.12,\n",
       "    1.44,\n",
       "    2.65,\n",
       "    0.7599999999999999,\n",
       "    0.26,\n",
       "    2.49,\n",
       "    2.0700000000000003,\n",
       "    0.61,\n",
       "    0.7,\n",
       "    1.13,\n",
       "    2.22,\n",
       "    0.69,\n",
       "    1.5,\n",
       "    -0.4999999999999999,\n",
       "    1.5400000000000003,\n",
       "    1.56,\n",
       "    0.8800000000000001,\n",
       "    1.81,\n",
       "    1.4000000000000001,\n",
       "    2.3800000000000003,\n",
       "    3.33,\n",
       "    1.94,\n",
       "    1.36,\n",
       "    1.1800000000000002,\n",
       "    1.27,\n",
       "    1.74,\n",
       "    2.27,\n",
       "    0.6699999999999999,\n",
       "    2.3,\n",
       "    2.41,\n",
       "    2.3000000000000003,\n",
       "    1.33,\n",
       "    -0.54,\n",
       "    1.3000000000000003,\n",
       "    2.8099999999999996,\n",
       "    2.7600000000000002,\n",
       "    1.03,\n",
       "    1.4200000000000002,\n",
       "    1.56,\n",
       "    0.51,\n",
       "    1.21,\n",
       "    -0.4,\n",
       "    0.7599999999999999,\n",
       "    2.6900000000000004,\n",
       "    2.8,\n",
       "    2.97,\n",
       "    1.4,\n",
       "    1.5],\n",
       "   'episode_lengths': [11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11,\n",
       "    11]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.49610937633862406,\n",
       "   'mean_inference_ms': 2.2358741202493877,\n",
       "   'mean_action_processing_ms': 0.08124323136745112,\n",
       "   'mean_env_wait_ms': 0.06249564136752065,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'num_faulty_episodes': 0,\n",
       "  'num_agent_steps_sampled_this_iter': 4000,\n",
       "  'num_env_steps_sampled_this_iter': 4000,\n",
       "  'timesteps_this_iter': 4000}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "412af3893f3d4a0ca95ce43798f08e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(height=286, width=1060)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ended after 10 steps with reward 2.3000000000000003 (spec: 500)\n"
     ]
    }
   ],
   "source": [
    "# inference\n",
    "from IPython.display import display, clear_output\n",
    "from time import sleep\n",
    "\n",
    "env = gym.make(env_name)\n",
    "# obs, info = env.reset(seed=10)\n",
    "obs, info = env.reset()\n",
    "reward_total = 0\n",
    "for episode_step in count():\n",
    "    action = algo.compute_single_action(obs,explore=False)\n",
    "    next_obs, reward, terminated, truncated, info = env.step(action)\n",
    "    reward_total += float(reward)\n",
    "    clear_output()\n",
    "    display(env.render())\n",
    "    if terminated or truncated:\n",
    "        print(f\"ended after {episode_step} steps with reward {reward_total} (spec: {env.spec.reward_threshold})\")\n",
    "        break\n",
    "    obs = next_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rllib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "524f818cd743d7abf57cb48d668c781df3b45c3f425c53d80f3bb0fcd0df7a52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
