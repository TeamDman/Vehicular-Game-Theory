{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TeamD\\.conda\\envs\\rllib\\lib\\site-packages\\tensorflow_probability\\python\\__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if (distutils.version.LooseVersion(tf.__version__) <\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import ray\n",
    "from ray import air, tune\n",
    "from ray.rllib.algorithms.algorithm import Algorithm\n",
    "from ray.tune.registry import get_trainable_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.0.0.dev0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.__version__\n",
    "# using nightly 3.0.0 build since gymnasium isn't supported in 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage stats collection is enabled by default for nightly wheels. To disable this, run the following command: `ray disable-usage-stats` before starting Ray. See https://docs.ray.io/en/master/cluster/usage-stats.html for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-31 15:04:15,242\tINFO worker.py:1536 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.15</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 3.0.0.dev0</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://127.0.0.1:8265\" target=\"_blank\">http://127.0.0.1:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='127.0.0.1:8265', python_version='3.8.15', ray_version='3.0.0.dev0', ray_commit='3e18487d7427a3ffcea9fecd5c79ca3e81fb92d0', address_info={'node_ip_address': '127.0.0.1', 'raylet_ip_address': '127.0.0.1', 'redis_address': None, 'object_store_address': 'tcp://127.0.0.1:59507', 'raylet_socket_name': 'tcp://127.0.0.1:37778', 'webui_url': '127.0.0.1:8265', 'session_dir': 'C:\\\\Users\\\\TeamD\\\\AppData\\\\Local\\\\Temp\\\\ray\\\\session_2022-12-31_15-04-12_366050_8960', 'metrics_export_port': 42812, 'gcs_address': '127.0.0.1:53303', 'address': '127.0.0.1:53303', 'dashboard_agent_listen_port': 52365, 'node_id': 'ab859759a74cc3ac90a3109a357e33d4be274a5178e579e2ab7f9d67'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platoonenv\n",
    "env_cls = platoonenv.PlatoonEnvV1\n",
    "env=env_cls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-31 15:04:18,275\tWARNING env.py:156 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "2022-12-31 15:04:18,276\tWARNING env.py:166 -- Your env reset() method appears to take 'seed' or 'return_info' arguments. Note that these are not yet supported in RLlib. Seeding will take place using 'env.seed()' and the info dict will not be returned from reset.\n"
     ]
    }
   ],
   "source": [
    "ray.rllib.utils.check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env_name = \"CartPole-v1\"\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.rllib.algorithms.dqn import DQNConfig\n",
    "# train_class = \"PPO\"\n",
    "# config = (\n",
    "#     PPOConfig()\n",
    "#     .environment(env_cls)\n",
    "#     .framework(\"torch\")\n",
    "#     .rollouts(num_rollout_workers=10)\n",
    "#     .resources(num_gpus=0)\n",
    "    \n",
    "# )\n",
    "train_class=\"DQN\"\n",
    "config = (\n",
    "    DQNConfig()\n",
    "    .environment(env_cls)\n",
    "    .framework(\"torch\")\n",
    "    .rollouts(num_rollout_workers=10)\n",
    "    .resources(num_gpus=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-48\n"
     ]
    }
   ],
   "source": [
    "stop = {\n",
    "    \"training_iteration\": 200,\n",
    "    \"timesteps_total\": 800_000,\n",
    "    \"episode_reward_mean\": env.metadata[\"reward_threshold\"],\n",
    "}\n",
    "print(stop[\"episode_reward_mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-31 15:59:04,413\tINFO experiment_analysis.py:795 -- No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n"
     ]
    }
   ],
   "source": [
    "resume = False\n",
    "resume_path = \"C:/Users/TeamD/ray_results/PPO\"\n",
    "if resume:\n",
    "    tuner = tune.Tuner.restore(resume_path)\n",
    "else:\n",
    "    tuner = tune.Tuner(\n",
    "        train_class,\n",
    "        param_space=config.to_dict(),\n",
    "        run_config=air.RunConfig(\n",
    "            stop=stop,\n",
    "            verbose=2,\n",
    "            checkpoint_config=air.CheckpointConfig(\n",
    "                checkpoint_frequency=1, checkpoint_at_end=True\n",
    "            ),\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2022-12-31 15:59:09</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:00.93        </td></tr>\n",
       "<tr><td>Memory:      </td><td>15.0/31.9 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 0/12 CPUs, 0/0 GPUs, 0.0/10.82 GiB heap, 0.0/5.41 GiB objects\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_PlatoonEnvV1_56ad8_00000</td><td>TERMINATED</td><td>127.0.0.1:13116</td><td style=\"text-align: right;\">   200</td><td style=\"text-align: right;\">         2620.85</td><td style=\"text-align: right;\">800000</td><td style=\"text-align: right;\"> -49.285</td><td style=\"text-align: right;\">                 -49</td><td style=\"text-align: right;\">                 -60</td><td style=\"text-align: right;\">                10</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-31 15:59:08,756\tINFO trial_runner.py:695 -- A local experiment checkpoint was found and will be used to restore the previous experiment state.\n",
      "2022-12-31 15:59:08,758\tINFO trial_runner.py:832 -- Using following checkpoint to resume: C:\\Users\\TeamD\\ray_results\\PPO\\experiment_state-2022-12-31_15-04-31.json\n",
      "2022-12-31 15:59:08,797\tWARNING trial_runner.py:837 -- Attempting to resume experiment from C:\\Users\\TeamD\\ray_results\\PPO. This will ignore any new changes to the specification.\n",
      "2022-12-31 15:59:08,869\tINFO tune.py:711 -- TrialRunner resumed, ignoring new add_experiment but updating trial resources.\n",
      "2022-12-31 15:59:09,797\tINFO tune.py:774 -- Total run time: 1.05 seconds (0.00 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-31 15:53:21,158\tWARNING algorithm_config.py:614 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint(local_path=C:\\Users\\TeamD\\ray_results\\PPO\\PPO_PlatoonEnvV1_56ad8_00000_0_2022-12-31_15-04-31\\checkpoint_000200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14904)\u001b[0m c:\\Users\\TeamD\\.conda\\envs\\rllib\\lib\\site-packages\\win32\\lib\\pywintypes.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\u001b[2m\u001b[36m(pid=14904)\u001b[0m   import imp, sys, os\n",
      "\u001b[2m\u001b[36m(pid=10716)\u001b[0m c:\\Users\\TeamD\\.conda\\envs\\rllib\\lib\\site-packages\\win32\\lib\\pywintypes.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\u001b[2m\u001b[36m(pid=10716)\u001b[0m   import imp, sys, os\n",
      "\u001b[2m\u001b[36m(pid=14904)\u001b[0m c:\\Users\\TeamD\\.conda\\envs\\rllib\\lib\\site-packages\\tensorflow_probability\\python\\__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=14904)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "\u001b[2m\u001b[36m(pid=10716)\u001b[0m c:\\Users\\TeamD\\.conda\\envs\\rllib\\lib\\site-packages\\tensorflow_probability\\python\\__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(pid=10716)\u001b[0m   if (distutils.version.LooseVersion(tf.__version__) <\n",
      "2022-12-31 15:53:29,501\tINFO worker_set.py:309 -- Inferred observation/action spaces from remote worker (local worker has no env): {'default_policy': (Box(-10.0, 1.0, (20,), float32), Discrete(11)), '__env__': (Box(-10.0, 1.0, (20,), float32), Discrete(11))}\n",
      "2022-12-31 15:53:29,518\tINFO policy.py:1196 -- Policy (worker=local) running on CPU.\n",
      "2022-12-31 15:53:29,518\tINFO torch_policy_v2.py:110 -- Found 0 visible cuda devices.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=14904)\u001b[0m 2022-12-31 15:53:29,466\tWARNING env.py:156 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=14904)\u001b[0m 2022-12-31 15:53:29,466\tWARNING env.py:166 -- Your env reset() method appears to take 'seed' or 'return_info' arguments. Note that these are not yet supported in RLlib. Seeding will take place using 'env.seed()' and the info dict will not be returned from reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=14904)\u001b[0m 2022-12-31 15:53:29,479\tINFO policy.py:1196 -- Policy (worker=1) running on CPU.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=14904)\u001b[0m 2022-12-31 15:53:29,480\tINFO torch_policy_v2.py:110 -- Found 0 visible cuda devices.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=10716)\u001b[0m 2022-12-31 15:53:29,479\tINFO policy.py:1196 -- Policy (worker=2) running on CPU.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=10716)\u001b[0m 2022-12-31 15:53:29,479\tINFO torch_policy_v2.py:110 -- Found 0 visible cuda devices.\n",
      "2022-12-31 15:53:29,534\tINFO rollout_worker.py:2037 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['default_policy']>\n",
      "2022-12-31 15:53:29,535\tINFO rollout_worker.py:2038 -- Built preprocessor map: {'default_policy': <ray.rllib.models.preprocessors.NoPreprocessor object at 0x000001BDBCF19610>}\n",
      "2022-12-31 15:53:29,536\tINFO rollout_worker.py:757 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {'default_policy': <ray.rllib.utils.filter.NoFilter object at 0x000001BD9236A640>})\n",
      "2022-12-31 15:53:29,543\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = results.get_best_result().checkpoint\n",
    "# Checkpoint(local_path=C:\\Users\\TeamD\\ray_results\\PPO\\PPO_PlatoonEnvV1_56ad8_00000_0_2022-12-31_15-04-31\\checkpoint_000200)\n",
    "assert checkpoint is not None, \"checkpoint doesn't exist, training failed?\"\n",
    "print(checkpoint)\n",
    "algo = Algorithm.from_checkpoint(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind, act, rew\n",
      " [[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      " [ 9.  7.  6.  5.  1.  4. 10.  3.  5.  5.]\n",
      " [-9. -8. -7. -6. -5. -4. -3. -2. -3. -2.]]\n",
      "obs\n",
      " [[  1.   0.   1.   1.   1.   1.   1.   0.   1.   1.]\n",
      " [  0. -10.   0.   0.   0.   0.   0. -10.   0.   0.]]\n",
      "Episode done: Total reward = -49.0, steps = 10\n",
      "ind, act, rew\n",
      " [[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      " [10.  9.  5.  8.  7.  1.  3.  6.  5.  5.]\n",
      " [-9. -8. -7. -6. -5. -4. -3. -2. -3. -2.]]\n",
      "obs\n",
      " [[  1.   0.   1.   0.   1.   1.   1.   1.   1.   1.]\n",
      " [  0. -10.   0. -10.   0.   0.   0.   0.   0.   0.]]\n",
      "Episode done: Total reward = -49.0, steps = 10\n",
      "ind, act, rew\n",
      " [[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      " [10.  9.  2.  7.  1.  5.  4.  6.  5.  5.]\n",
      " [-9. -8. -7. -6. -5. -4. -3. -2. -3. -2.]]\n",
      "obs\n",
      " [[  1.   1.   0.   1.   1.   1.   1.   0.   1.   1.]\n",
      " [  0.   0. -10.   0.   0.   0.   0. -10.   0.   0.]]\n",
      "Episode done: Total reward = -49.0, steps = 10\n",
      "ind, act, rew\n",
      " [[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      " [ 1.  8.  6.  2.  5. 10.  3.  7.  8.  8.]\n",
      " [-9. -8. -7. -6. -5. -4. -3. -2. -3. -2.]]\n",
      "obs\n",
      " [[  1.   1.   1.   0.   1.   1.   1.   1.   0.   1.]\n",
      " [  0.   0.   0. -10.   0.   0.   0.   0. -10.   0.]]\n",
      "Episode done: Total reward = -49.0, steps = 10\n",
      "ind, act, rew\n",
      " [[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      " [10.  1.  6.  7.  4.  2.  9.  3.  7.  7.]\n",
      " [-9. -8. -7. -6. -5. -4. -3. -2. -3. -2.]]\n",
      "obs\n",
      " [[  1.   1.   1.   1.   0.   1.   1.   0.   1.   1.]\n",
      " [  0.   0.   0.   0. -10.   0.   0. -10.   0.   0.]]\n",
      "Episode done: Total reward = -49.0, steps = 10\n",
      "ind, act, rew\n",
      " [[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      " [ 1. 10.  6.  5.  2.  4.  3.  9.  5.  5.]\n",
      " [-9. -8. -7. -6. -5. -4. -3. -2. -3. -2.]]\n",
      "obs\n",
      " [[  1.   1.   1.   1.   1.   1.   0.   0.   1.   1.]\n",
      " [  0.   0.   0.   0.   0.   0. -10. -10.   0.   0.]]\n",
      "Episode done: Total reward = -49.0, steps = 10\n",
      "ind, act, rew\n",
      " [[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      " [ 1.  8.  6.  2.  5. 10.  3.  7.  8.  8.]\n",
      " [-9. -8. -7. -6. -5. -4. -3. -2. -3. -2.]]\n",
      "obs\n",
      " [[  1.   1.   1.   0.   1.   1.   1.   1.   0.   1.]\n",
      " [  0.   0.   0. -10.   0.   0.   0.   0. -10.   0.]]\n",
      "Episode done: Total reward = -49.0, steps = 10\n",
      "ind, act, rew\n",
      " [[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      " [ 1.  3.  8.  5. 10.  2.  9.  6.  5.  5.]\n",
      " [-9. -8. -7. -6. -5. -4. -3. -2. -3. -2.]]\n",
      "obs\n",
      " [[  1.   1.   1.   0.   1.   1.   0.   1.   1.   1.]\n",
      " [  0.   0.   0. -10.   0.   0. -10.   0.   0.   0.]]\n",
      "Episode done: Total reward = -49.0, steps = 10\n",
      "ind, act, rew\n",
      " [[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      " [ 6.  8.  5.  1. 10.  7.  2.  9.  5.  5.]\n",
      " [-9. -8. -7. -6. -5. -4. -3. -2. -3. -2.]]\n",
      "obs\n",
      " [[  1.   1.   0.   0.   1.   1.   1.   1.   1.   1.]\n",
      " [  0.   0. -10. -10.   0.   0.   0.   0.   0.   0.]]\n",
      "Episode done: Total reward = -49.0, steps = 10\n",
      "ind, act, rew\n",
      " [[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      " [10.  8.  5.  2.  7.  3.  6.  4.  7.  7.]\n",
      " [-9. -8. -7. -6. -5. -4. -3. -2. -3. -2.]]\n",
      "obs\n",
      " [[  0.   1.   1.   1.   1.   1.   1.   1.   0.   1.]\n",
      " [-10.   0.   0.   0.   0.   0.   0.   0. -10.   0.]]\n",
      "Episode done: Total reward = -49.0, steps = 10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "num_episodes = 0\n",
    "episode_reward = 0.0\n",
    "episode_steps = 0\n",
    "truncated_already = False\n",
    "actions = []\n",
    "rewards = []\n",
    "while num_episodes < 10:\n",
    "    # Compute an action (`a`).\n",
    "    a = algo.compute_single_action(\n",
    "        observation=obs,\n",
    "        explore=False,\n",
    "        policy_id=\"default_policy\",  # <- default value\n",
    "    )\n",
    "    # Send the computed action `a` to the env.\n",
    "    obs, reward, done, truncated, _ = env.step(a)\n",
    "    actions.append(a)\n",
    "    rewards.append(reward)\n",
    "    episode_reward += reward\n",
    "    episode_steps += 1\n",
    "\n",
    "    if done or truncated:\n",
    "        print(\"ind, act, rew\\n\",np.array(np.vstack([np.arange(1,11), actions, rewards])))\n",
    "        print(\"obs\\n\",obs.reshape(2,10))\n",
    "        print(f\"Episode done: Total reward = {episode_reward}, steps = {episode_steps}\")\n",
    "        obs, info = env.reset()\n",
    "        actions = []\n",
    "        rewards = []\n",
    "        num_episodes += 1\n",
    "        episode_steps = 0\n",
    "        episode_reward = 0.0\n",
    "        truncated_already = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 -9.0 \n",
      " [[  0.   0.   0.   0.   0.   1.   0.   0.   0.   0.]\n",
      " [  0.   0.   0. -10. -10.   0.   0.   0.   0.   0.]]\n",
      "7 -8.0 \n",
      " [[  0.   0.   0.   0.   0.   1.   1.   0.   0.   0.]\n",
      " [  0.   0.   0. -10. -10.   0.   0.   0.   0.   0.]]\n",
      "1 -7.0 \n",
      " [[  1.   0.   0.   0.   0.   1.   1.   0.   0.   0.]\n",
      " [  0.   0.   0. -10. -10.   0.   0.   0.   0.   0.]]\n",
      "9 -6.0 \n",
      " [[  1.   0.   0.   0.   0.   1.   1.   0.   1.   0.]\n",
      " [  0.   0.   0. -10. -10.   0.   0.   0.   0.   0.]]\n",
      "2 -5.0 \n",
      " [[  1.   1.   0.   0.   0.   1.   1.   0.   1.   0.]\n",
      " [  0.   0.   0. -10. -10.   0.   0.   0.   0.   0.]]\n",
      "10 -4.0 \n",
      " [[  1.   1.   0.   0.   0.   1.   1.   0.   1.   1.]\n",
      " [  0.   0.   0. -10. -10.   0.   0.   0.   0.   0.]]\n",
      "8 -3.0 \n",
      " [[  1.   1.   0.   0.   0.   1.   1.   1.   1.   1.]\n",
      " [  0.   0.   0. -10. -10.   0.   0.   0.   0.   0.]]\n",
      "3 -2.0 \n",
      " [[  1.   1.   1.   0.   0.   1.   1.   1.   1.   1.]\n",
      " [  0.   0.   0. -10. -10.   0.   0.   0.   0.   0.]]\n",
      "9 -3.0 \n",
      " [[  1.   1.   1.   0.   0.   1.   1.   1.   0.   1.]\n",
      " [  0.   0.   0. -10. -10.   0.   0.   0.   0.   0.]]\n",
      "9 -2.0 \n",
      " [[  1.   1.   1.   0.   0.   1.   1.   1.   1.   1.]\n",
      " [  0.   0.   0. -10. -10.   0.   0.   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "obs, info = env.reset()\n",
    "from itertools import count\n",
    "for i in count():\n",
    "    a = algo.compute_single_action(\n",
    "        observation=obs,\n",
    "        explore=False,\n",
    "        policy_id=\"default_policy\",  # <- default value\n",
    "    )\n",
    "    # Send the computed action `a` to the env.\n",
    "    obs, reward, done, truncated, _ = env.step(a)\n",
    "    print(a, reward, \"\\n\",obs.reshape(2,-1))\n",
    "    if done or truncated:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., -10.,\n",
       "          0.,   0.,   0.,   0.,   0., -10.,   0.,   0.,   0.],\n",
       "       dtype=float32),\n",
       " {})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., -10.,\n",
       "          0.,   0.,   0.,   0.,   0., -10.,   0.,   0.,   0.],\n",
       "       dtype=float32),\n",
       " -19.0,\n",
       " False,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([941., 870., 895., 943., 887., 910., 911., 871., 898., 913., 961.]),\n",
       " array([ 0.        ,  0.90909091,  1.81818182,  2.72727273,  3.63636364,\n",
       "         4.54545455,  5.45454545,  6.36363636,  7.27272727,  8.18181818,\n",
       "         9.09090909, 10.        ]),\n",
       " <BarContainer object of 11 artists>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "plt.hist([env.action_space.sample() for _ in range(10000)], bins=env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algo.stop()\n",
    "# ray.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rllib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "524f818cd743d7abf57cb48d668c781df3b45c3f425c53d80f3bb0fcd0df7a52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
