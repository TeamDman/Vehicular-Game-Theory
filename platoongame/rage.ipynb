{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import random\n",
    "import math\n",
    "from typing import List, Tuple, Union, Iterable, Callable, Optional\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "State = Tensor # vehicle, vuln, feature\n",
    "StateBatch = Tensor\n",
    "DefenderAction = Tensor # vehicles\n",
    "DefenderActionBatch = Tensor\n",
    "AttackerAction = Tensor # vehicles\n",
    "AttackerActionBatch = Tensor\n",
    "Reward = Tensor\n",
    "RewardBatch = Tensor\n",
    "Terminal = Tensor\n",
    "TerminalBatch = Tensor\n",
    "\n",
    "MAX_VEHICLES                        = 10     #@param {type:\"integer\"}\n",
    "MAX_VULNS                           = 3      #@param {type:\"integer\"}\n",
    "MAX_ATTACK                          = 2      #@param {type:\"integer\"}\n",
    "\n",
    "BATCH_SIZE                          = 100    #@param {type:\"integer\"}\n",
    "MEMORY_SIZE                         = 10000  #@param {type:\"integer\"}\n",
    "MEMORY_WARMUP_STEPS                 = 20     #@param {type:\"integer\"} # scaled by batch size\n",
    "\n",
    "TRAIN_STEPS                         = 25     #@param {type:\"integer\"}\n",
    "EXPLORATION_STEPS_PER_TRAIN_STEP    = 1      #@param {type:\"integer\"} # scaled by batch size\n",
    "\n",
    "LEARNING_RATE                       = 0.001  #@param {type:\"number\"}\n",
    "LEARNING_RATE_GAMMA                 = 0.9    #@param {type:\"number\"}\n",
    "LEARNING_RATE_GAMMA_FREQUENCY       = 100    #@param {type:\"integer\"}\n",
    "\n",
    "REWARD_GAMMA                        = 0.99   #@param {type:\"number\"}\n",
    "\n",
    "EPSILON_DECAY_STEPS                 = 10000  #@param {type:\"integer\"}\n",
    "EPSILON_THETA                       = 0.0    #@param {type:\"number\"}\n",
    "EPSILON_MU                          = 0.0    #@param {type:\"number\"}\n",
    "EPSILON_SIGMA                       = 3      #@param {type:\"number\"}\n",
    "\n",
    "SOFT_UPDATE_TAU                     = 0.001   #@param {type:\"number\"}\n",
    "\n",
    "DEVICE = torch.cuda.is_available() and torch.device('cuda') or torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_random_starting_state() -> State:\n",
    "    prob_dist = torch.distributions.Normal(\n",
    "        loc=torch.as_tensor(0.5, dtype=torch.float32),\n",
    "        scale=torch.as_tensor(0.25, dtype=torch.float32),\n",
    "    )\n",
    "    sev_dist = torch.distributions.Normal(\n",
    "        loc=torch.as_tensor(2, dtype=torch.float32),\n",
    "        scale=torch.as_tensor(1, dtype=torch.float32),\n",
    "    )\n",
    "    state = torch.zeros((MAX_VEHICLES, MAX_VULNS, 4), dtype=torch.float32)\n",
    "    for i in range(MAX_VEHICLES):\n",
    "        for j in range(random.randint(0, MAX_VULNS)):\n",
    "            state[i,j,0] = float(prob_dist.sample().clamp(0.05,1)) # prob\n",
    "            state[i,j,1] = int(sev_dist.sample().clamp(1,5)) ** 2 # sev\n",
    "            state[i,j,2] = 0 # compromised\n",
    "            state[i,j,3] = 0 # membership\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_empty_state() -> State:\n",
    "    return torch.zeros((MAX_VEHICLES, MAX_VULNS, 4), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_states(states: Union[Tuple[State, ...], List[State]]) -> StateBatch:\n",
    "    return torch.stack(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_starting_state_batch(num_batches: int) -> StateBatch:\n",
    "    return batch_states([get_random_starting_state() for _ in range(num_batches)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attacker_actions(states: StateBatch) -> AttackerActionBatch:\n",
    "    priority = (states[:,:,:,0] * states[:,:,:,1] * (1-states[:,:,:,2])).sum(dim=-1)\n",
    "    # find indices of vehicles to attack\n",
    "    attack = priority.topk(MAX_ATTACK).indices\n",
    "    # return mask of vehicles to attack\n",
    "    return torch.zeros((states.shape[0], MAX_VEHICLES), dtype=torch.float32).scatter_(1, attack, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_attacker_actions(states: StateBatch, actions: AttackerActionBatch) -> StateBatch:\n",
    "    # batch size must be the same\n",
    "    assert states.shape[0] == actions.shape[0]\n",
    "\n",
    "    # create a copy so we don't modify the original\n",
    "    states = states.clone()\n",
    "\n",
    "    # roll probability for each vulnerability\n",
    "    probs = torch.rand((states.shape[0], MAX_VEHICLES, MAX_VULNS), dtype=torch.float32)\n",
    "\n",
    "    # only keep vulns for vehicles that are being attacked\n",
    "    for i in range(states.shape[0]):\n",
    "        probs[i, actions[i]!=1, :] = 0 \n",
    "\n",
    "    # set the vulnerability compromised flag to 1 for each successful attack\n",
    "    states[:,:,:,2] += (probs > 1-states[:,:,:,0]).float()\n",
    "    states[:,:,:,2] = states[:,:,:,2].clamp(0, 1)\n",
    "    return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_defender_actions(states: StateBatch) -> DefenderActionBatch:\n",
    "    return (torch.rand((states.shape[0], MAX_VEHICLES), dtype=torch.float32) > 0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_defender_actions(states: StateBatch, actions: DefenderActionBatch) -> StateBatch:\n",
    "    # batch size must be the same\n",
    "    assert states.shape[0] == actions.shape[0]\n",
    "\n",
    "    # create a copy so we don't modify the original\n",
    "    states = states.clone()\n",
    "\n",
    "    # set the membership flag to 1 for each vuln in each vehicle that is chosen\n",
    "    states[:,:,:,3] = 0\n",
    "    for i in range(states.shape[0]):\n",
    "        states[i,actions[i,:]==1,:,3] = 1\n",
    "    return states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_defender_utilities(states: StateBatch) -> RewardBatch:\n",
    "    # identify which platoons contain compromised vehicles\n",
    "    compromise_free_platoons = (states[:,:,:,2] * states[:,:,:,3]).sum(dim=[-1,-2]) == 0\n",
    "    # identify size of each platoon\n",
    "    members = states[:,:,:,3].max(dim=-1).values.sum(dim=-1)\n",
    "    # return 0 if platoon is compromised, size of platoon otherwise\n",
    "    return members * compromise_free_platoons.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefenderActor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.LazyConv2d(out_channels=5, kernel_size=2, stride=1)\n",
    "        self.fc1 = nn.LazyLinear(256)\n",
    "        self.fc2 = nn.LazyLinear(128)\n",
    "        self.fc3 = nn.LazyLinear(MAX_VEHICLES)\n",
    "\n",
    "    def forward(self, x: StateBatch) -> DefenderActionBatch:\n",
    "        x = torch.hstack((\n",
    "            F.gelu(self.conv1(x)).flatten(start_dim=1),\n",
    "            x.flatten(start_dim=1), # skip connection after conv\n",
    "        ))\n",
    "        x = F.gelu(self.fc1(x))\n",
    "        x = F.gelu(self.fc2(x))\n",
    "        x = torch.tanh(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefenderCritic(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.LazyConv2d(out_channels=5, kernel_size=2, stride=1)\n",
    "        self.fc1 = nn.LazyLinear(256)\n",
    "        self.fc2 = nn.LazyLinear(128)\n",
    "        self.fc3 = nn.LazyLinear(1)\n",
    "    def forward(self, x1: StateBatch, x2: DefenderActionBatch) -> Reward:\n",
    "        x = torch.hstack((\n",
    "            F.gelu(self.conv1(x1)).flatten(start_dim=1),\n",
    "            x1.flatten(start_dim=1), # skip connection after conv\n",
    "            x2,\n",
    "        ))\n",
    "        x = F.gelu(self.fc1(x))\n",
    "        x = F.gelu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TeamD\\.conda\\envs\\subgame\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor = DefenderActor()\n",
    "actor_target = DefenderActor()\n",
    "actor_target.load_state_dict(actor.state_dict())\n",
    "critic = DefenderCritic()\n",
    "critic_target = DefenderCritic()\n",
    "critic_target.load_state_dict(critic.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensure weights are initialized\n",
    "critic(get_random_starting_state_batch(1), actor(get_random_starting_state_batch(1)))\n",
    "critic_target(get_random_starting_state_batch(1), actor_target(get_random_starting_state_batch(1)))\n",
    "\n",
    "# hard update weights\n",
    "critic_target.load_state_dict(critic.state_dict())\n",
    "actor_target.load_state_dict(actor.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Transition:\n",
    "    state: State\n",
    "    action: DefenderAction\n",
    "    reward: Reward\n",
    "    next_state: State\n",
    "    terminal: Terminal\n",
    "\n",
    "@dataclass\n",
    "class TransitionBatch:\n",
    "    states: StateBatch\n",
    "    actions: DefenderActionBatch\n",
    "    rewards: RewardBatch\n",
    "    next_states: StateBatch\n",
    "    terminals: TerminalBatch\n",
    "\n",
    "memory: deque[Transition] = deque(maxlen=MEMORY_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_memory(batch_size: int) -> TransitionBatch:\n",
    "    samples = random.sample(memory, batch_size)\n",
    "    return TransitionBatch(\n",
    "        states=torch.stack([s.state for s in samples]),\n",
    "        actions=torch.stack([s.action for s in samples]),\n",
    "        rewards=torch.stack([s.reward for s in samples]),\n",
    "        next_states=torch.stack([s.next_state for s in samples]),\n",
    "        terminals=torch.stack([s.terminal for s in samples]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warmup memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75877a1c96e343988d698d99f3adc9dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "states = get_random_starting_state_batch(BATCH_SIZE)\n",
    "\n",
    "for _ in tqdm(range(MEMORY_WARMUP_STEPS)):\n",
    "    # random exploration\n",
    "    defender_actions = get_random_defender_actions(states)\n",
    "    next_states = apply_defender_actions(states, defender_actions)\n",
    "    attacker_actions = get_attacker_actions(next_states)\n",
    "    next_states = apply_attacker_actions(next_states, attacker_actions)\n",
    "    rewards = get_defender_utilities(next_states)\n",
    "    terminals = rewards == 0\n",
    "\n",
    "    # track next states as empty if terminal\n",
    "    next_states[terminals] = get_empty_state()\n",
    "\n",
    "    # save each transition in the batch to memory\n",
    "    for i in range(BATCH_SIZE):\n",
    "        memory.append(Transition(\n",
    "            state=states[i],\n",
    "            action=defender_actions[i],\n",
    "            reward=rewards[i],\n",
    "            next_state=next_states[i],\n",
    "            terminal=torch.as_tensor(rewards[i] == 0),\n",
    "        ))\n",
    "\n",
    "    # reset environment for terminal states\n",
    "    states = next_states.clone()\n",
    "    states[terminals] = get_random_starting_state_batch(int(terminals.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([711.,   8.,  28.,  49.,  79.,  65.,  37.,  17.,   4.,   2.]),\n",
       " array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ],\n",
       "       dtype=float32),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sample_memory(1000).rewards.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e8cb39b7f0>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(sample_memory(1000).rewards.cumsum(0).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_optimizer = torch.optim.Adam(actor.parameters(), lr=LEARNING_RATE)\n",
    "actor_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    actor_optimizer,\n",
    "    step_size=LEARNING_RATE_GAMMA_FREQUENCY,\n",
    "    gamma=LEARNING_RATE_GAMMA,\n",
    ")\n",
    "critic_optimizer = torch.optim.Adam(critic.parameters(), lr=LEARNING_RATE)\n",
    "critic_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    critic_optimizer,\n",
    "    step_size=LEARNING_RATE_GAMMA_FREQUENCY,\n",
    "    gamma=LEARNING_RATE_GAMMA,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/ghliu/pytorch-ddpg/blob/master/util.py#L26\n",
    "\n",
    "def soft_update(target, source, tau):\n",
    "        for target_param, param in zip(target.parameters(), source.parameters()):\n",
    "            ## shouldn't be necessary since we use target networks to calculate loss\n",
    "            # if isinstance(target_param, torch.nn.parameter.UninitializedParameter):\n",
    "            #     # target model uninitialize, hard update\n",
    "            #     target_param.data.copy_(param.data)\n",
    "            # else:\n",
    "            target_param.data.copy_(target_param.data * (1.0 - tau) + param.data * tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from original deepRL author code\n",
    "class RandomProcess(object):\n",
    "    def reset_states(self):\n",
    "        pass\n",
    "class AnnealedGaussianProcess(RandomProcess):\n",
    "    def __init__(self, mu, sigma, sigma_min, n_steps_annealing):\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.n_steps = 0\n",
    "\n",
    "        if sigma_min is not None:\n",
    "            self.m = -float(sigma - sigma_min) / float(n_steps_annealing)\n",
    "            self.c = sigma\n",
    "            self.sigma_min = sigma_min\n",
    "        else:\n",
    "            self.m = 0.\n",
    "            self.c = sigma\n",
    "            self.sigma_min = sigma\n",
    "\n",
    "    @property\n",
    "    def current_sigma(self):\n",
    "        sigma = max(self.sigma_min, self.m * float(self.n_steps) + self.c)\n",
    "        return sigma\n",
    "\n",
    "# Based on http://math.stackexchange.com/questions/1287634/implementing-ornstein-uhlenbeck-in-matlab\n",
    "class OrnsteinUhlenbeckProcess(AnnealedGaussianProcess):\n",
    "    def __init__(self, theta, mu=0., sigma=1., dt=1e-2, x0=None, size=1, sigma_min=None, n_steps_annealing=1000):\n",
    "        super(OrnsteinUhlenbeckProcess, self).__init__(mu=mu, sigma=sigma, sigma_min=sigma_min, n_steps_annealing=n_steps_annealing)\n",
    "        self.theta = theta\n",
    "        self.mu = mu\n",
    "        self.dt = dt\n",
    "        self.x0 = x0\n",
    "        self.size = size\n",
    "        self.normal = torch.distributions.Normal(torch.as_tensor(0, dtype=torch.float32), torch.as_tensor(1, dtype=torch.float32))\n",
    "        self.reset_states()\n",
    "\n",
    "    def sample(self):\n",
    "        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + self.current_sigma * torch.sqrt(torch.as_tensor(self.dt, dtype=torch.float32)) * self.normal.sample((self.size,))  # type: ignore\n",
    "        self.x_prev = x\n",
    "        self.n_steps += 1\n",
    "        return x\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.x_prev = self.x0 if self.x0 is not None else torch.zeros(self.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b007d7e95e8b487f93c152a1950933c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step 00 exploring optimizing "
     ]
    }
   ],
   "source": [
    "states = get_random_starting_state_batch(BATCH_SIZE).to(DEVICE)\n",
    "\n",
    "epsilon = 1.0\n",
    "epsilon_decay = epsilon / EPSILON_DECAY_STEPS\n",
    "epsilon_noise = OrnsteinUhlenbeckProcess(\n",
    "    size=MAX_VEHICLES,\n",
    "    theta=EPSILON_SIGMA,\n",
    "    mu=EPSILON_MU,\n",
    "    sigma=EPSILON_SIGMA,\n",
    ")\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "digits = math.ceil(math.log10(TRAIN_STEPS))\n",
    "for i in tqdm(range(TRAIN_STEPS)):\n",
    "    print(f\"train step {i:0{digits}d}\", end=\" \")\n",
    "    # epsilon-noise exploration\n",
    "    print(f\"exploring\", end=\" \")\n",
    "    for j in range(EXPLORATION_STEPS_PER_TRAIN_STEP):\n",
    "        proto_defender_actions = actor(states)\n",
    "        for i in range(BATCH_SIZE):\n",
    "            proto_defender_actions[i] += epsilon * epsilon_noise.sample().to(proto_defender_actions.device)\n",
    "        epsilon = max(0.0, epsilon - epsilon_decay)\n",
    "        defender_actions: DefenderActionBatch = (proto_defender_actions > 0.5).float() # convert to binary\n",
    "        next_states = apply_defender_actions(states, defender_actions)\n",
    "        attacker_actions = get_attacker_actions(next_states)\n",
    "        next_states = apply_attacker_actions(next_states, attacker_actions)\n",
    "        rewards = get_defender_utilities(next_states)\n",
    "        terminals = rewards == 0\n",
    "\n",
    "        # track next states as empty if terminal\n",
    "        next_states[terminals] = get_empty_state()\n",
    "        \n",
    "        # save each transition in the batch to memory\n",
    "        for i in range(BATCH_SIZE):\n",
    "            memory.append(Transition(\n",
    "                state=states[i],\n",
    "                action=defender_actions[i],\n",
    "                reward=rewards[i],\n",
    "                next_state=next_states[i],\n",
    "                terminal=torch.as_tensor(rewards[i] == 0, dtype=torch.bool),\n",
    "            ))\n",
    "\n",
    "        # reset environment for terminal states\n",
    "        states = next_states.clone()\n",
    "        states[terminals] = get_random_starting_state_batch(int(terminals.sum()))\n",
    "\n",
    "    # train\n",
    "    print(f\"optimizing\", end=\" \")\n",
    "    batch = sample_memory(BATCH_SIZE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        q_next: Tensor = critic_target(\n",
    "            batch.next_states,\n",
    "            actor_target(batch.next_states),\n",
    "        )\n",
    "    q_next.requires_grad_()\n",
    "    q_target = q_next * REWARD_GAMMA * (1-batch.terminals.float().unsqueeze(1)) + batch.rewards.unsqueeze(1)\n",
    "\n",
    "    critic.zero_grad()\n",
    "    q_pred = critic(batch.states, batch.actions)\n",
    "    critic_loss = criterion(q_pred, q_target)\n",
    "    critic_loss.backward()\n",
    "    critic_optimizer.step()\n",
    "    critic_scheduler.step()\n",
    "    print(f\"critic loss: {critic_loss.item():.4f}\", end=\" \")\n",
    "\n",
    "    actor.zero_grad()\n",
    "    actor_loss = -critic(batch.states, actor(batch.states)).mean()\n",
    "    actor_loss.backward()\n",
    "    actor_optimizer.step()\n",
    "    actor_scheduler.step()\n",
    "    print(f\"actor loss: {actor_loss.item():.4f}\", end=\" \")\n",
    "\n",
    "    soft_update(actor_target, actor, SOFT_UPDATE_TAU)\n",
    "    soft_update(critic_target, critic, SOFT_UPDATE_TAU)\n",
    "\n",
    "\n",
    "    print()\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('subgame')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09b31e4957d63d79e1e76c5537c345194b9f565583fac53cbbb105281d72baf4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
