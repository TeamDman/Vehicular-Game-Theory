{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import random\n",
    "import math\n",
    "from typing import List, Tuple, Union, Iterable, Callable, Optional\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "State = Tensor # vehicle, vuln, feature\n",
    "StateBatch = Tensor\n",
    "DefenderAction = Tensor # vehicles\n",
    "DefenderActionBatch = Tensor\n",
    "AttackerAction = Tensor # vehicles\n",
    "AttackerActionBatch = Tensor\n",
    "Reward = Tensor\n",
    "RewardBatch = Tensor\n",
    "Terminal = Tensor\n",
    "TerminalBatch = Tensor\n",
    "\n",
    "MAX_VEHICLES                        = 10     #@param {type:\"integer\"}\n",
    "MAX_VULNS                           = 3      #@param {type:\"integer\"}\n",
    "MAX_ATTACK                          = 2      #@param {type:\"integer\"}\n",
    "\n",
    "BATCH_SIZE                          = 1000    #@param {type:\"integer\"}\n",
    "MEMORY_SIZE                         = 10000  #@param {type:\"integer\"}\n",
    "MEMORY_WARMUP_STEPS                 = 2000     #@param {type:\"integer\"} # scaled by batch size\n",
    "\n",
    "TRAIN_STEPS                         = 25     #@param {type:\"integer\"}\n",
    "EXPLORATION_STEPS_PER_TRAIN_STEP    = 1      #@param {type:\"integer\"} # scaled by batch size\n",
    "\n",
    "LEARNING_RATE                       = 0.001  #@param {type:\"number\"}\n",
    "LEARNING_RATE_GAMMA                 = 0.9    #@param {type:\"number\"}\n",
    "LEARNING_RATE_GAMMA_FREQUENCY       = 100    #@param {type:\"integer\"}\n",
    "\n",
    "REWARD_GAMMA                        = 0.99   #@param {type:\"number\"}\n",
    "\n",
    "EPSILON_DECAY_STEPS                 = 10000  #@param {type:\"integer\"}\n",
    "EPSILON_THETA                       = 0.0    #@param {type:\"number\"}\n",
    "EPSILON_MU                          = 0.0    #@param {type:\"number\"}\n",
    "EPSILON_SIGMA                       = 3      #@param {type:\"number\"}\n",
    "\n",
    "SOFT_UPDATE_TAU                     = 0.001  #@param {type:\"number\"}\n",
    "\n",
    "EVAL_STEPS                          = 100    #@param {type:\"integer\"}\n",
    "\n",
    "DEVICE = torch.cuda.is_available() and torch.device('cuda') or torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### States"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get random starting state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_random_starting_state() -> State:\n",
    "    prob_dist = torch.distributions.Normal(\n",
    "        loc=torch.as_tensor(0.5, dtype=torch.float32),\n",
    "        scale=torch.as_tensor(0.25, dtype=torch.float32),\n",
    "    )\n",
    "    sev_dist = torch.distributions.Normal(\n",
    "        loc=torch.as_tensor(2, dtype=torch.float32),\n",
    "        scale=torch.as_tensor(1, dtype=torch.float32),\n",
    "    )\n",
    "    state = torch.zeros((MAX_VEHICLES, MAX_VULNS, 4), dtype=torch.float32)\n",
    "    for i in range(MAX_VEHICLES):\n",
    "        for j in range(random.randint(0, MAX_VULNS)):\n",
    "            state[i,j,0] = float(prob_dist.sample().clamp(0.05,1)) # prob\n",
    "            state[i,j,1] = int(sev_dist.sample().clamp(1,5)) ** 2 # sev\n",
    "            state[i,j,2] = 0 # compromised\n",
    "            state[i,j,3] = 0 # membership\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get empty state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_empty_state() -> State:\n",
    "    return torch.zeros((MAX_VEHICLES, MAX_VULNS, 4), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### batch states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_states(states: Union[Tuple[State, ...], List[State]]) -> StateBatch:\n",
    "    return torch.stack(states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get random starting state batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_starting_state_batch(num_batches: int) -> StateBatch:\n",
    "    return batch_states([get_random_starting_state() for _ in range(num_batches)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get attacker actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attacker_actions(states: StateBatch) -> AttackerActionBatch:\n",
    "    priority = (states[:,:,:,0] * states[:,:,:,1] * (1-states[:,:,:,2])).sum(dim=-1)\n",
    "    # find indices of vehicles to attack\n",
    "    attack = priority.topk(MAX_ATTACK).indices\n",
    "    # return mask of vehicles to attack\n",
    "    return torch.zeros((states.shape[0], MAX_VEHICLES), dtype=torch.float32).to(states.device).scatter_(1, attack, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### apply attacker actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_attacker_actions(states: StateBatch, actions: AttackerActionBatch) -> StateBatch:\n",
    "    assert states.shape[0] == actions.shape[0]\n",
    "    assert states.device == actions.device\n",
    "\n",
    "    # create a copy so we don't modify the original\n",
    "    states = states.clone()\n",
    "\n",
    "    # roll probability for each vulnerability\n",
    "    probs = torch.rand((states.shape[0], MAX_VEHICLES, MAX_VULNS), dtype=torch.float32, device=states.device)\n",
    "\n",
    "    # only keep vulns for vehicles that are being attacked\n",
    "    for i in range(states.shape[0]):\n",
    "        probs[i, actions[i]!=1, :] = 0 \n",
    "\n",
    "    # set the vulnerability compromised flag to 1 for each successful attack\n",
    "    states[:,:,:,2] += (probs > 1-states[:,:,:,0]).float()\n",
    "    states[:,:,:,2] = states[:,:,:,2].clamp(0, 1)\n",
    "    return states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get exploring defender actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exploring_defender_actions(states: StateBatch) -> DefenderActionBatch:\n",
    "    assert states.shape[0] > MAX_VEHICLES * 2 # we want to give diagonal and random actions a chance\n",
    "\n",
    "    diag = torch.eye(MAX_VEHICLES, dtype=torch.float32, device=states.device)\n",
    "    rand = (torch.rand((states.shape[0] - MAX_VEHICLES, MAX_VEHICLES), dtype=torch.float32, device=states.device) > 0.5).float()\n",
    "    return torch.cat((diag, rand))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### apply defender actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_defender_actions(states: StateBatch, actions: DefenderActionBatch) -> StateBatch:\n",
    "    assert states.shape[0] == actions.shape[0]\n",
    "    assert states.device == actions.device\n",
    "\n",
    "    # create a copy so we don't modify the original\n",
    "    states = states.clone()\n",
    "\n",
    "    # set the membership flag to 1 for each vuln in each vehicle that is chosen\n",
    "    states[:,:,:,3] = 0\n",
    "    for i in range(states.shape[0]):\n",
    "        states[i,actions[i,:]==1,:,3] = 1\n",
    "    return states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get defender utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_defender_utilities(states: StateBatch) -> RewardBatch:\n",
    "    # identify which platoons contain compromised vehicles\n",
    "    compromise_free_platoons = (states[:,:,:,2] * states[:,:,:,3]).sum(dim=[-1,-2]) == 0\n",
    "    # identify size of each platoon\n",
    "    members = states[:,:,:,3].max(dim=-1).values.sum(dim=-1)\n",
    "    # return 0 if platoon is compromised, size of platoon otherwise\n",
    "    return members * compromise_free_platoons.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefenderActor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.LazyConv2d(out_channels=5, kernel_size=2, stride=1)\n",
    "        self.fc1 = nn.LazyLinear(256)\n",
    "        self.fc2 = nn.LazyLinear(128)\n",
    "        self.fc3 = nn.LazyLinear(MAX_VEHICLES)\n",
    "\n",
    "    def forward(self, x: StateBatch) -> DefenderActionBatch:\n",
    "        x = torch.hstack((\n",
    "            F.gelu(self.conv1(x)).flatten(start_dim=1),\n",
    "            x.flatten(start_dim=1), # skip connection after conv\n",
    "        ))\n",
    "        x = F.gelu(self.fc1(x))\n",
    "        x = F.gelu(self.fc2(x))\n",
    "        x = torch.tanh(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefenderCritic(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.LazyConv2d(out_channels=5, kernel_size=2, stride=1)\n",
    "        self.fc1 = nn.LazyLinear(256)\n",
    "        self.fc2 = nn.LazyLinear(128)\n",
    "        self.fc3 = nn.LazyLinear(1)\n",
    "    def forward(self, x1: StateBatch, x2: DefenderActionBatch) -> Reward:\n",
    "        x = torch.hstack((\n",
    "            F.gelu(self.conv1(x1)).flatten(start_dim=1),\n",
    "            x1.flatten(start_dim=1), # skip connection after conv\n",
    "            x2,\n",
    "        ))\n",
    "        x = F.gelu(self.fc1(x))\n",
    "        x = F.gelu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replay memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Transition:\n",
    "    state: State\n",
    "    action: DefenderAction\n",
    "    reward: Reward\n",
    "    next_state: State\n",
    "    terminal: Terminal\n",
    "\n",
    "    def to(self, device: torch.device) -> 'Transition':\n",
    "        return Transition(\n",
    "            state=self.state.to(device),\n",
    "            action=self.action.to(device),\n",
    "            reward=self.reward.to(device),\n",
    "            next_state=self.next_state.to(device),\n",
    "            terminal=self.terminal.to(device),\n",
    "        )\n",
    "\n",
    "@dataclass\n",
    "class TransitionBatch:\n",
    "    states: StateBatch\n",
    "    actions: DefenderActionBatch\n",
    "    rewards: RewardBatch\n",
    "    next_states: StateBatch\n",
    "    terminals: TerminalBatch\n",
    "\n",
    "    \n",
    "    def to(self, device: torch.device) -> 'TransitionBatch':\n",
    "        return TransitionBatch(\n",
    "            states=self.states.to(device),\n",
    "            actions=self.actions.to(device),\n",
    "            rewards=self.rewards.to(device),\n",
    "            next_states=self.next_states.to(device),\n",
    "            terminals=self.terminals.to(device),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_memory(memory: deque, batch_size: int) -> TransitionBatch:\n",
    "    samples = random.sample(memory, batch_size)\n",
    "    return TransitionBatch(\n",
    "        states=torch.stack([s.state for s in samples]),\n",
    "        actions=torch.stack([s.action for s in samples]),\n",
    "        rewards=torch.stack([s.reward for s in samples]),\n",
    "        next_states=torch.stack([s.next_state for s in samples]),\n",
    "        terminals=torch.stack([s.terminal for s in samples]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/ghliu/pytorch-ddpg/blob/master/util.py#L26\n",
    "\n",
    "def soft_update(target, source, tau):\n",
    "        for target_param, param in zip(target.parameters(), source.parameters()):\n",
    "            ## shouldn't be necessary since we use target networks to calculate loss\n",
    "            # if isinstance(target_param, torch.nn.parameter.UninitializedParameter):\n",
    "            #     # target model uninitialize, hard update\n",
    "            #     target_param.data.copy_(param.data)\n",
    "            # else:\n",
    "            target_param.data.copy_(target_param.data * (1.0 - tau) + param.data * tau)\n",
    "\n",
    "def hard_update(target, source):\n",
    "    for target_param, param in zip(target.parameters(), source.parameters()):\n",
    "            target_param.data.copy_(param.data)\n",
    "# from original deepRL author code\n",
    "class RandomProcess(object):\n",
    "    def reset_states(self):\n",
    "        pass\n",
    "class AnnealedGaussianProcess(RandomProcess):\n",
    "    def __init__(self, mu, sigma, sigma_min, n_steps_annealing):\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.n_steps = 0\n",
    "\n",
    "        if sigma_min is not None:\n",
    "            self.m = -float(sigma - sigma_min) / float(n_steps_annealing)\n",
    "            self.c = sigma\n",
    "            self.sigma_min = sigma_min\n",
    "        else:\n",
    "            self.m = 0.\n",
    "            self.c = sigma\n",
    "            self.sigma_min = sigma\n",
    "\n",
    "    @property\n",
    "    def current_sigma(self):\n",
    "        sigma = max(self.sigma_min, self.m * float(self.n_steps) + self.c)\n",
    "        return sigma\n",
    "\n",
    "# Based on http://math.stackexchange.com/questions/1287634/implementing-ornstein-uhlenbeck-in-matlab\n",
    "class OrnsteinUhlenbeckProcess(AnnealedGaussianProcess):\n",
    "    def __init__(self, theta, mu=0., sigma=1., dt=1e-2, x0=None, size=1, sigma_min=None, n_steps_annealing=1000):\n",
    "        super(OrnsteinUhlenbeckProcess, self).__init__(mu=mu, sigma=sigma, sigma_min=sigma_min, n_steps_annealing=n_steps_annealing)\n",
    "        self.theta = theta\n",
    "        self.mu = mu\n",
    "        self.dt = dt\n",
    "        self.x0 = x0\n",
    "        self.size = size\n",
    "        self.normal = torch.distributions.Normal(torch.as_tensor(0, dtype=torch.float32), torch.as_tensor(1, dtype=torch.float32))\n",
    "        self.reset_states()\n",
    "\n",
    "    def sample(self):\n",
    "        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + self.current_sigma * torch.sqrt(torch.as_tensor(self.dt, dtype=torch.float32)) * self.normal.sample((self.size,))  # type: ignore\n",
    "        self.x_prev = x\n",
    "        self.n_steps += 1\n",
    "        return x\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.x_prev = self.x0 if self.x0 is not None else torch.zeros(self.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning and exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/ghliu/pytorch-ddpg/blob/master/util.py#L26\n",
    "\n",
    "def soft_update(target, source, tau):\n",
    "        for target_param, param in zip(target.parameters(), source.parameters()):\n",
    "            ## shouldn't be necessary since we use target networks to calculate loss\n",
    "            # if isinstance(target_param, torch.nn.parameter.UninitializedParameter):\n",
    "            #     # target model uninitialize, hard update\n",
    "            #     target_param.data.copy_(param.data)\n",
    "            # else:\n",
    "            target_param.data.copy_(target_param.data * (1.0 - tau) + param.data * tau)\n",
    "\n",
    "def hard_update(target, source):\n",
    "    for target_param, param in zip(target.parameters(), source.parameters()):\n",
    "            target_param.data.copy_(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from original deepRL author code\n",
    "class RandomProcess(object):\n",
    "    def reset_states(self):\n",
    "        pass\n",
    "class AnnealedGaussianProcess(RandomProcess):\n",
    "    def __init__(self, mu, sigma, sigma_min, n_steps_annealing):\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.n_steps = 0\n",
    "\n",
    "        if sigma_min is not None:\n",
    "            self.m = -float(sigma - sigma_min) / float(n_steps_annealing)\n",
    "            self.c = sigma\n",
    "            self.sigma_min = sigma_min\n",
    "        else:\n",
    "            self.m = 0.\n",
    "            self.c = sigma\n",
    "            self.sigma_min = sigma\n",
    "\n",
    "    @property\n",
    "    def current_sigma(self):\n",
    "        sigma = max(self.sigma_min, self.m * float(self.n_steps) + self.c)\n",
    "        return sigma\n",
    "\n",
    "# Based on http://math.stackexchange.com/questions/1287634/implementing-ornstein-uhlenbeck-in-matlab\n",
    "class OrnsteinUhlenbeckProcess(AnnealedGaussianProcess):\n",
    "    def __init__(self, theta, mu=0., sigma=1., dt=1e-2, x0=None, size=1, sigma_min=None, n_steps_annealing=1000):\n",
    "        super(OrnsteinUhlenbeckProcess, self).__init__(mu=mu, sigma=sigma, sigma_min=sigma_min, n_steps_annealing=n_steps_annealing)\n",
    "        self.theta = theta\n",
    "        self.mu = mu\n",
    "        self.dt = dt\n",
    "        self.x0 = x0\n",
    "        self.size = size\n",
    "        self.normal = torch.distributions.Normal(torch.as_tensor(0, dtype=torch.float32), torch.as_tensor(1, dtype=torch.float32))\n",
    "        self.reset_states()\n",
    "\n",
    "    def sample(self):\n",
    "        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + self.current_sigma * torch.sqrt(torch.as_tensor(self.dt, dtype=torch.float32)) * self.normal.sample((self.size,))  # type: ignore\n",
    "        self.x_prev = x\n",
    "        self.n_steps += 1\n",
    "        return x\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.x_prev = self.x0 if self.x0 is not None else torch.zeros(self.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory: deque[Transition] = deque(maxlen=MEMORY_SIZE) # colab uses old python version that doesn't support this :P\n",
    "memory = deque(maxlen=MEMORY_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TeamD\\.conda\\envs\\subgame\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "actor = DefenderActor().to(DEVICE)\n",
    "actor_target = DefenderActor().to(DEVICE)\n",
    "critic = DefenderCritic().to(DEVICE)\n",
    "critic_target = DefenderCritic().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure weights are initialized\n",
    "states = get_random_starting_state_batch(1).to(DEVICE)\n",
    "critic(states, actor(states))\n",
    "critic_target(states, actor_target(states))\n",
    "\n",
    "# hard update weights\n",
    "hard_update(actor_target, actor)\n",
    "hard_update(critic_target, critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_optimizer = torch.optim.Adam(actor.parameters(), lr=LEARNING_RATE)\n",
    "actor_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    actor_optimizer,\n",
    "    step_size=LEARNING_RATE_GAMMA_FREQUENCY,\n",
    "    gamma=LEARNING_RATE_GAMMA,\n",
    ")\n",
    "critic_optimizer = torch.optim.Adam(critic.parameters(), lr=LEARNING_RATE)\n",
    "critic_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    critic_optimizer,\n",
    "    step_size=LEARNING_RATE_GAMMA_FREQUENCY,\n",
    "    gamma=LEARNING_RATE_GAMMA,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1.0\n",
    "epsilon_decay = epsilon / EPSILON_DECAY_STEPS\n",
    "epsilon_noise = OrnsteinUhlenbeckProcess(\n",
    "    size=MAX_VEHICLES,\n",
    "    theta=EPSILON_SIGMA,\n",
    "    mu=EPSILON_MU,\n",
    "    sigma=EPSILON_SIGMA,\n",
    ")\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "digits = math.ceil(math.log10(TRAIN_STEPS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cda207ed2e42416ea7bd05c010b55b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "states = get_random_starting_state_batch(BATCH_SIZE).to(DEVICE)\n",
    "\n",
    "# perform random exploration for one set of state sequences\n",
    "for _ in tqdm(range(MEMORY_WARMUP_STEPS // 4)):\n",
    "    # random exploration\n",
    "    defender_actions = get_exploring_defender_actions(states)\n",
    "    next_states = apply_defender_actions(states, defender_actions)\n",
    "    attacker_actions = get_attacker_actions(next_states)\n",
    "    next_states = apply_attacker_actions(next_states, attacker_actions)\n",
    "    rewards = get_defender_utilities(next_states)\n",
    "    terminals = rewards == 0\n",
    "\n",
    "    # track next states as empty if terminal\n",
    "    next_states[terminals] = get_empty_state()\n",
    "\n",
    "    # save each transition in the batch to memory\n",
    "    for i in range(BATCH_SIZE):\n",
    "        memory.append(Transition(\n",
    "            state=states[i],\n",
    "            action=defender_actions[i],\n",
    "            reward=rewards[i],\n",
    "            next_state=next_states[i],\n",
    "            terminal=torch.as_tensor(rewards[i] == 0),\n",
    "        ))\n",
    "\n",
    "    # reset environment for terminal states\n",
    "    states = next_states.clone()\n",
    "    states[terminals] = get_random_starting_state_batch(int(terminals.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternate paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb8499e5929f47c9ad2f0df2762ebd28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using random states from the memory, see what would happen if we took different actions at those states\n",
    "for _ in tqdm(range(MEMORY_WARMUP_STEPS // 4 * 3)):\n",
    "    states = sample_memory(memory, BATCH_SIZE).states\n",
    "\n",
    "    # random exploration\n",
    "    defender_actions = get_exploring_defender_actions(states)\n",
    "    next_states = apply_defender_actions(states, defender_actions)\n",
    "    attacker_actions = get_attacker_actions(next_states)\n",
    "    next_states = apply_attacker_actions(next_states, attacker_actions)\n",
    "    rewards = get_defender_utilities(next_states)\n",
    "    terminals = rewards == 0\n",
    "\n",
    "    # track next states as empty if terminal\n",
    "    next_states[terminals] = get_empty_state()\n",
    "\n",
    "    # save each transition in the batch to memory\n",
    "    for i in range(BATCH_SIZE):\n",
    "        memory.append(Transition(\n",
    "            state=states[i],\n",
    "            action=defender_actions[i],\n",
    "            reward=rewards[i],\n",
    "            next_state=next_states[i],\n",
    "            terminal=torch.as_tensor(rewards[i] == 0),\n",
    "        ))\n",
    "\n",
    "    # reset environment for terminal states\n",
    "    states = next_states.clone()\n",
    "    states[terminals] = get_random_starting_state_batch(int(terminals.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preflight checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([648.,  93.,  29.,  56.,   0.,  67.,  54.,  38.,  13.,   2.]),\n",
       " array([0. , 0.8, 1.6, 2.4, 3.2, 4. , 4.8, 5.6, 6.4, 7.2, 8. ],\n",
       "       dtype=float32),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sample_memory(memory, 1000).rewards.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21dbb1b1970>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(sample_memory(memory, 1000).rewards.cumsum(0).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_loss_history = []\n",
    "actor_loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = get_random_starting_state_batch(BATCH_SIZE).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea001c7c994c43f58efba1a520ea3161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step 00 exploring optimizing critic loss: 6.2893 actor loss: -0.3094 \n",
      "train step 01 exploring optimizing critic loss: 5.0385 actor loss: -0.5422 \n",
      "train step 02 exploring optimizing critic loss: 4.9382 actor loss: -0.8416 \n",
      "train step 03 exploring optimizing critic loss: 4.1262 actor loss: -1.1511 \n",
      "train step 04 exploring optimizing critic loss: 3.8404 actor loss: -1.3261 \n",
      "train step 05 exploring optimizing critic loss: 4.3313 actor loss: -1.4203 \n",
      "train step 06 exploring optimizing critic loss: 4.3813 actor loss: -1.4826 \n",
      "train step 07 exploring optimizing critic loss: 3.5567 actor loss: -1.4466 \n",
      "train step 08 exploring optimizing critic loss: 4.3499 actor loss: -1.3340 \n",
      "train step 09 exploring optimizing critic loss: 3.2199 actor loss: -1.2237 \n",
      "train step 10 exploring optimizing critic loss: 3.9822 actor loss: -1.2135 \n",
      "train step 11 exploring optimizing critic loss: 4.5845 actor loss: -1.1157 \n",
      "train step 12 exploring optimizing critic loss: 5.7925 actor loss: -1.1533 \n",
      "train step 13 exploring optimizing critic loss: 3.9124 actor loss: -1.1729 \n",
      "train step 14 exploring optimizing critic loss: 3.7982 actor loss: -1.0724 \n",
      "train step 15 exploring optimizing critic loss: 6.2827 actor loss: -1.0870 \n",
      "train step 16 exploring optimizing critic loss: 3.7703 actor loss: -1.0523 \n",
      "train step 17 exploring optimizing critic loss: 5.0555 actor loss: -1.1767 \n",
      "train step 18 exploring optimizing critic loss: 5.0128 actor loss: -1.1979 \n",
      "train step 19 exploring optimizing critic loss: 4.3503 actor loss: -1.1920 \n",
      "train step 20 exploring optimizing critic loss: 5.2003 actor loss: -1.2318 \n",
      "train step 21 exploring optimizing critic loss: 3.9882 actor loss: -1.2693 \n",
      "train step 22 exploring optimizing critic loss: 5.1805 actor loss: -1.2524 \n",
      "train step 23 exploring optimizing critic loss: 5.2092 actor loss: -1.2976 \n",
      "train step 24 exploring optimizing critic loss: 4.5455 actor loss: -1.3419 \n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(TRAIN_STEPS)):\n",
    "    print(f\"train step {i:0{digits}d}\", end=\" \")\n",
    "    # epsilon-noise exploration\n",
    "    print(f\"exploring\", end=\" \")\n",
    "    for j in range(EXPLORATION_STEPS_PER_TRAIN_STEP):\n",
    "        proto_defender_actions = actor(states)\n",
    "        for i in range(BATCH_SIZE):\n",
    "            proto_defender_actions[i] += epsilon * epsilon_noise.sample().to(proto_defender_actions.device)\n",
    "        epsilon = max(0.0, epsilon - epsilon_decay)\n",
    "        defender_actions: DefenderActionBatch = (proto_defender_actions > 0.5).float() # convert to binary\n",
    "        next_states = apply_defender_actions(states, defender_actions)\n",
    "        attacker_actions = get_attacker_actions(next_states)\n",
    "        next_states = apply_attacker_actions(next_states, attacker_actions)\n",
    "        rewards = get_defender_utilities(next_states)\n",
    "        terminals = rewards == 0\n",
    "\n",
    "        # track next states as empty if terminal\n",
    "        next_states[terminals] = get_empty_state().to(DEVICE)\n",
    "        \n",
    "        # save each transition in the batch to memory\n",
    "        for i in range(BATCH_SIZE):\n",
    "            memory.append(Transition(\n",
    "                state=states[i],\n",
    "                action=defender_actions[i],\n",
    "                reward=rewards[i],\n",
    "                next_state=next_states[i],\n",
    "                terminal=torch.as_tensor(rewards[i] == 0, dtype=torch.bool),\n",
    "            ).to(torch.device(\"cpu\")))\n",
    "\n",
    "        # reset environment for terminal states\n",
    "        states = next_states.clone()\n",
    "        states[terminals] = get_random_starting_state_batch(int(terminals.sum())).to(DEVICE)\n",
    "\n",
    "    # train\n",
    "    print(f\"optimizing\", end=\" \")\n",
    "    batch = sample_memory(memory, BATCH_SIZE).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        q_next: Tensor = critic_target(\n",
    "            batch.next_states,\n",
    "            actor_target(batch.next_states),\n",
    "        )\n",
    "    q_next.requires_grad_()\n",
    "    q_target = q_next * REWARD_GAMMA * (1-batch.terminals.float().unsqueeze(1)) + batch.rewards.unsqueeze(1)\n",
    "\n",
    "    critic.zero_grad()\n",
    "    q_pred = critic(batch.states, batch.actions)\n",
    "    critic_loss = criterion(q_pred, q_target)\n",
    "    critic_loss.backward()\n",
    "    critic_optimizer.step()\n",
    "    critic_scheduler.step()\n",
    "    print(f\"critic loss: {critic_loss.item():.4f}\", end=\" \")\n",
    "    critic_loss_history.append(critic_loss.item())\n",
    "\n",
    "    actor.zero_grad()\n",
    "    actor_loss = -critic(batch.states, actor(batch.states)).mean()\n",
    "    actor_loss.backward()\n",
    "    actor_optimizer.step()\n",
    "    actor_scheduler.step()\n",
    "    print(f\"actor loss: {actor_loss.item():.4f}\", end=\" \")\n",
    "    actor_loss_history.append(actor_loss.item())\n",
    "\n",
    "    soft_update(actor_target, actor, SOFT_UPDATE_TAU)\n",
    "    soft_update(critic_target, critic, SOFT_UPDATE_TAU)\n",
    "\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x25adad4ce50>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(critic_loss_history, label=\"critic_loss\")\n",
    "plt.plot(actor_loss_history, label=\"actor_loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f7354b5b77646a79c93b2e5ee68a58e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "states = get_random_starting_state_batch(BATCH_SIZE).to(DEVICE)\n",
    "\n",
    "for _ in tqdm(range(EVAL_STEPS)):\n",
    "    proto_defender_actions = actor(states)\n",
    "    defender_actions: DefenderActionBatch = (proto_defender_actions > 0.5).float() # convert to binary\n",
    "    next_states = apply_defender_actions(states, defender_actions)\n",
    "    attacker_actions = get_attacker_actions(next_states)\n",
    "    next_states = apply_attacker_actions(next_states, attacker_actions)\n",
    "    rewards = get_defender_utilities(next_states)\n",
    "    terminals = rewards == 0\n",
    "\n",
    "    # track next states as empty if terminal\n",
    "    next_states[terminals] = get_empty_state().to(DEVICE)\n",
    "\n",
    "    eval_rewards.append(rewards)\n",
    "\n",
    "    # reset environment for terminal states\n",
    "    states = next_states.clone()\n",
    "    states[terminals] = get_random_starting_state_batch(int(terminals.sum())).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab83e47e5f6a4aef84ba2b75abe9a7f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i', max=99), Output()), _dom_classes=('widget-interact',"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "@widgets.interact(i=(0, BATCH_SIZE-1))\n",
    "def asd(i=0):\n",
    "    plt.plot(torch.vstack(eval_rewards)[:,i].cpu().numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('subgame')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09b31e4957d63d79e1e76c5537c345194b9f565583fac53cbbb105281d72baf4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
