{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __quick_start_begin__\n",
    "import gymnasium as gym\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "\n",
    "\n",
    "# Define your problem using python and openAI's gym API:\n",
    "class SimpleCorridor(gym.Env):\n",
    "    \"\"\"Corridor in which an agent must learn to move right to reach the exit.\n",
    "\n",
    "    ---------------------\n",
    "    | S | 1 | 2 | 3 | G |   S=start; G=goal; corridor_length=5\n",
    "    ---------------------\n",
    "\n",
    "    Possible actions to chose from are: 0=left; 1=right\n",
    "    Observations are floats indicating the current field index, e.g. 0.0 for\n",
    "    starting position, 1.0 for the field next to the starting position, etc..\n",
    "    Rewards are -0.1 for all steps, except when reaching the goal (+1.0).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.end_pos = config[\"corridor_length\"]\n",
    "        self.cur_pos = 0\n",
    "        self.action_space = gym.spaces.Discrete(2)  # left and right\n",
    "        self.observation_space = gym.spaces.Box(0.0, self.end_pos, shape=(1,))\n",
    "\n",
    "    def reset(self, *, seed=None, options=None):\n",
    "        \"\"\"Resets the episode.\n",
    "\n",
    "        Returns:\n",
    "           Initial observation of the new episode and an info dict.\n",
    "        \"\"\"\n",
    "        self.cur_pos = 0\n",
    "        # Return initial observation.\n",
    "        return [self.cur_pos], {}\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Takes a single step in the episode given `action`.\n",
    "\n",
    "        Returns:\n",
    "            New observation, reward, terminated-flag, truncated-flag, info-dict (empty).\n",
    "        \"\"\"\n",
    "        # Walk left.\n",
    "        if action == 0 and self.cur_pos > 0:\n",
    "            self.cur_pos -= 1\n",
    "        # Walk right.\n",
    "        elif action == 1:\n",
    "            self.cur_pos += 1\n",
    "        # Set `terminated` flag when end of corridor (goal) reached.\n",
    "        terminated = self.cur_pos >= self.end_pos\n",
    "        truncated = False\n",
    "        # +1 when goal reached, otherwise -1.\n",
    "        reward = 1.0 if terminated else -0.1\n",
    "        return [self.cur_pos], reward, terminated, truncated, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage stats collection is enabled by default for nightly wheels. To disable this, run the following command: `ray disable-usage-stats` before starting Ray. See https://docs.ray.io/en/master/cluster/usage-stats.html for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-07 17:35:46,004\tINFO worker.py:1536 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.15</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 3.0.0.dev0</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://127.0.0.1:8265\" target=\"_blank\">http://127.0.0.1:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='127.0.0.1:8265', python_version='3.8.15', ray_version='3.0.0.dev0', ray_commit='3e18487d7427a3ffcea9fecd5c79ca3e81fb92d0', address_info={'node_ip_address': '127.0.0.1', 'raylet_ip_address': '127.0.0.1', 'redis_address': None, 'object_store_address': 'tcp://127.0.0.1:62349', 'raylet_socket_name': 'tcp://127.0.0.1:50918', 'webui_url': '127.0.0.1:8265', 'session_dir': 'C:\\\\Users\\\\TeamD\\\\AppData\\\\Local\\\\Temp\\\\ray\\\\session_2023-01-07_17-35-43_348246_21960', 'metrics_export_port': 35568, 'gcs_address': '127.0.0.1:19570', 'address': '127.0.0.1:19570', 'dashboard_agent_listen_port': 52365, 'node_id': '5d34da699fec6d8a690246b5aaeec0c362231d1250537d057cb21940'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "ray.init(num_gpus=1, local_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"Platoon-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=4340)\u001b[0m 2023-01-07 17:35:58,474\tWARNING env.py:156 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4340)\u001b[0m 2023-01-07 17:35:58,474\tWARNING env.py:166 -- Your env reset() method appears to take 'seed' or 'return_info' arguments. Note that these are not yet supported in RLlib. Seeding will take place using 'env.seed()' and the info dict will not be returned from reset.\n",
      "2023-01-07 17:35:58,565\tINFO worker_set.py:309 -- Inferred observation/action spaces from remote worker (local worker has no env): {'default_policy': (Box(-10.0, 1.0, (20,), float32), Discrete(11)), '__env__': (Box(-10.0, 1.0, (20,), float32), Discrete(11))}\n",
      "2023-01-07 17:35:58,607\tINFO policy.py:1196 -- Policy (worker=local) running on 1 GPUs.\n",
      "2023-01-07 17:35:58,608\tINFO torch_policy_v2.py:110 -- Found 1 visible cuda devices.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4340)\u001b[0m 2023-01-07 17:35:58,546\tINFO policy.py:1196 -- Policy (worker=1) running on CPU.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4340)\u001b[0m 2023-01-07 17:35:58,546\tINFO torch_policy_v2.py:110 -- Found 1 visible cuda devices.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=20032)\u001b[0m 2023-01-07 17:35:58,546\tINFO policy.py:1196 -- Policy (worker=3) running on CPU.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=20032)\u001b[0m 2023-01-07 17:35:58,546\tINFO torch_policy_v2.py:110 -- Found 1 visible cuda devices.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=21264)\u001b[0m 2023-01-07 17:35:58,548\tINFO policy.py:1196 -- Policy (worker=2) running on CPU.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=21264)\u001b[0m 2023-01-07 17:35:58,548\tINFO torch_policy_v2.py:110 -- Found 1 visible cuda devices.\n",
      "2023-01-07 17:36:00,624\tINFO rollout_worker.py:2037 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['default_policy']>\n",
      "2023-01-07 17:36:00,625\tINFO rollout_worker.py:2038 -- Built preprocessor map: {'default_policy': <ray.rllib.models.preprocessors.NoPreprocessor object at 0x000001D008E155E0>}\n",
      "2023-01-07 17:36:00,625\tINFO rollout_worker.py:757 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {'default_policy': <ray.rllib.utils.filter.NoFilter object at 0x000001D008E7AC40>})\n",
      "2023-01-07 17:36:00,633\tINFO trainable.py:172 -- Trainable.setup took 10.946 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    }
   ],
   "source": [
    "# Create an RLlib Algorithm instance from a PPOConfig object.\n",
    "import platoonenv\n",
    "config = (\n",
    "    PPOConfig().environment(\n",
    "        # Env class to use (here: our gym.Env sub-class from above).\n",
    "        # env=SimpleCorridor,\n",
    "        env=env_name,\n",
    "        # Config dict to be passed to our custom env's constructor.\n",
    "        # Use corridor with 20 fields (including S and G).\n",
    "        # env_config={\"corridor_length\": 28},\n",
    "    )\n",
    "    .framework(\"torch\")\n",
    "    .resources(num_gpus=1)\n",
    "    # Parallelize environment rollouts.\n",
    "    .rollouts(num_rollout_workers=3)\n",
    ")\n",
    "# Construct the actual (PPO) algorithm object from the config.\n",
    "algo = config.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0; avg. reward=-49.288220551378444\n",
      "Iter: 1; avg. reward=-49.35839598997494\n",
      "Iter: 2; avg. reward=-49.27\n",
      "Iter: 3; avg. reward=-49.229426433915215\n",
      "Iter: 4; avg. reward=-49.385\n",
      "Iter: 5; avg. reward=-49.30576441102757\n",
      "Iter: 6; avg. reward=-49.32418952618454\n",
      "Iter: 7; avg. reward=-49.2275\n",
      "Iter: 8; avg. reward=-49.37593984962406\n",
      "Iter: 9; avg. reward=-49.32835820895522\n",
      "Iter: 10; avg. reward=-49.38095238095238\n",
      "Iter: 11; avg. reward=-49.16541353383459\n",
      "Iter: 12; avg. reward=-49.34\n",
      "Iter: 13; avg. reward=-49.33416458852868\n",
      "Iter: 14; avg. reward=-49.52\n",
      "Iter: 15; avg. reward=-49.769423558897245\n",
      "Iter: 16; avg. reward=-49.6359102244389\n",
      "Iter: 17; avg. reward=-49.5075\n",
      "Iter: 18; avg. reward=-49.478696741854634\n",
      "Iter: 19; avg. reward=-49.308457711442784\n",
      "Iter: 20; avg. reward=-49.27568922305765\n",
      "Iter: 21; avg. reward=-49.40852130325815\n",
      "Iter: 22; avg. reward=-49.435\n",
      "Iter: 23; avg. reward=-49.33665835411471\n",
      "Iter: 24; avg. reward=-49.3625\n",
      "Iter: 25; avg. reward=-49.230576441102755\n",
      "Iter: 26; avg. reward=-49.281795511221944\n",
      "Iter: 27; avg. reward=-49.405\n",
      "Iter: 28; avg. reward=-49.34335839598997\n",
      "Iter: 29; avg. reward=-49.30099502487562\n",
      "Iter: 30; avg. reward=-49.32080200501253\n",
      "Iter: 31; avg. reward=-49.26817042606516\n",
      "Iter: 32; avg. reward=-49.18\n",
      "Iter: 33; avg. reward=-49.29675810473815\n",
      "Iter: 34; avg. reward=-49.18\n",
      "Iter: 35; avg. reward=-49.32581453634085\n",
      "Iter: 36; avg. reward=-49.22693266832918\n",
      "Iter: 37; avg. reward=-49.1725\n",
      "Iter: 38; avg. reward=-49.21553884711779\n",
      "Iter: 39; avg. reward=-49.30597014925373\n",
      "Iter: 40; avg. reward=-49.18796992481203\n",
      "Iter: 41; avg. reward=-49.37593984962406\n",
      "Iter: 42; avg. reward=-49.2\n",
      "Iter: 43; avg. reward=-49.15211970074813\n",
      "Iter: 44; avg. reward=-49.725\n",
      "Iter: 45; avg. reward=-49.531328320802004\n",
      "Iter: 46; avg. reward=-49.39650872817955\n",
      "Iter: 47; avg. reward=-49.465\n",
      "Iter: 48; avg. reward=-49.41353383458647\n",
      "Iter: 49; avg. reward=-49.2636815920398\n",
      "Iter: 50; avg. reward=-49.30325814536341\n",
      "Iter: 51; avg. reward=-49.2406015037594\n",
      "Iter: 52; avg. reward=-49.19\n",
      "Iter: 53; avg. reward=-49.29426433915212\n",
      "Iter: 54; avg. reward=-49.405\n",
      "Iter: 55; avg. reward=-49.30576441102757\n",
      "Iter: 56; avg. reward=-49.3640897755611\n",
      "Iter: 57; avg. reward=-49.21\n",
      "Iter: 58; avg. reward=-49.27568922305765\n",
      "Iter: 59; avg. reward=-49.450248756218905\n",
      "Iter: 60; avg. reward=-49.29573934837093\n",
      "Iter: 61; avg. reward=-49.35839598997494\n",
      "Iter: 62; avg. reward=-49.275\n",
      "Iter: 63; avg. reward=-49.12219451371571\n",
      "Iter: 64; avg. reward=-49.365\n",
      "Iter: 65; avg. reward=-49.288220551378444\n",
      "Iter: 66; avg. reward=-49.12219451371571\n",
      "Iter: 67; avg. reward=-49.28\n",
      "Iter: 68; avg. reward=-49.36842105263158\n",
      "Iter: 69; avg. reward=-49.318407960199\n",
      "Iter: 70; avg. reward=-49.27318295739348\n",
      "Iter: 71; avg. reward=-49.32330827067669\n",
      "Iter: 72; avg. reward=-49.335\n",
      "Iter: 73; avg. reward=-49.254364089775564\n",
      "Iter: 74; avg. reward=-49.3425\n",
      "Iter: 75; avg. reward=-49.283208020050125\n",
      "Iter: 76; avg. reward=-49.43640897755611\n",
      "Iter: 77; avg. reward=-49.49\n",
      "Iter: 78; avg. reward=-49.23809523809524\n",
      "Iter: 79; avg. reward=-49.28109452736319\n",
      "Iter: 80; avg. reward=-49.65162907268171\n",
      "Iter: 81; avg. reward=-49.225563909774436\n",
      "Iter: 82; avg. reward=-49.2375\n",
      "Iter: 83; avg. reward=-49.42643391521197\n",
      "Iter: 84; avg. reward=-49.445\n",
      "Iter: 85; avg. reward=-49.35588972431078\n",
      "Iter: 86; avg. reward=-49.723192019950126\n",
      "Iter: 87; avg. reward=-49.3775\n",
      "Iter: 88; avg. reward=-49.46365914786968\n",
      "Iter: 89; avg. reward=-49.298507462686565\n",
      "Iter: 90; avg. reward=-49.27067669172932\n",
      "Iter: 91; avg. reward=-49.17042606516291\n",
      "Iter: 92; avg. reward=-49.4975\n",
      "Iter: 93; avg. reward=-49.281795511221944\n",
      "Iter: 94; avg. reward=-49.4825\n",
      "Iter: 95; avg. reward=-49.39598997493734\n",
      "Iter: 96; avg. reward=-49.28927680798005\n",
      "Iter: 97; avg. reward=-49.3575\n",
      "Iter: 98; avg. reward=-49.2531328320802\n",
      "Iter: 99; avg. reward=-49.32835820895522\n",
      "Iter: 100; avg. reward=-49.822055137844615\n",
      "Iter: 101; avg. reward=-49.576441102756895\n",
      "Iter: 102; avg. reward=-49.6625\n",
      "Iter: 103; avg. reward=-49.433915211970074\n",
      "Iter: 104; avg. reward=-49.7575\n",
      "Iter: 105; avg. reward=-49.35338345864662\n",
      "Iter: 106; avg. reward=-49.36907730673317\n",
      "Iter: 107; avg. reward=-49.4525\n",
      "Iter: 108; avg. reward=-49.421052631578945\n",
      "Iter: 109; avg. reward=-49.50995024875622\n",
      "Iter: 110; avg. reward=-49.54887218045113\n",
      "Iter: 111; avg. reward=-49.30827067669173\n",
      "Iter: 112; avg. reward=-49.5375\n",
      "Iter: 113; avg. reward=-49.46134663341646\n",
      "Iter: 114; avg. reward=-49.35\n",
      "Iter: 115; avg. reward=-49.51378446115288\n",
      "Iter: 116; avg. reward=-49.31670822942643\n",
      "Iter: 117; avg. reward=-49.3725\n",
      "Iter: 118; avg. reward=-49.35338345864662\n",
      "Iter: 119; avg. reward=-49.375621890547265\n",
      "Iter: 120; avg. reward=-49.51127819548872\n",
      "Iter: 121; avg. reward=-49.27318295739348\n",
      "Iter: 122; avg. reward=-49.3175\n",
      "Iter: 123; avg. reward=-49.12468827930174\n",
      "Iter: 124; avg. reward=-49.45\n",
      "Iter: 125; avg. reward=-49.388471177944865\n",
      "Iter: 126; avg. reward=-49.406483790523694\n",
      "Iter: 127; avg. reward=-49.39\n",
      "Iter: 128; avg. reward=-49.36842105263158\n",
      "Iter: 129; avg. reward=-49.39054726368159\n",
      "Iter: 130; avg. reward=-49.34837092731829\n",
      "Iter: 131; avg. reward=-49.31328320802005\n",
      "Iter: 132; avg. reward=-49.29\n",
      "Iter: 133; avg. reward=-49.556109725685786\n",
      "Iter: 134; avg. reward=-49.4375\n",
      "Iter: 135; avg. reward=-49.43358395989975\n",
      "Iter: 136; avg. reward=-49.22693266832918\n",
      "Iter: 137; avg. reward=-49.7325\n",
      "Iter: 138; avg. reward=-49.288220551378444\n",
      "Iter: 139; avg. reward=-49.333333333333336\n",
      "Iter: 140; avg. reward=-49.531328320802004\n",
      "Iter: 141; avg. reward=-49.288220551378444\n",
      "Iter: 142; avg. reward=-49.155\n",
      "Iter: 143; avg. reward=-49.54862842892768\n",
      "Iter: 144; avg. reward=-49.4775\n",
      "Iter: 145; avg. reward=-49.340852130325814\n",
      "Iter: 146; avg. reward=-49.438902743142144\n",
      "Iter: 147; avg. reward=-49.55\n",
      "Iter: 148; avg. reward=-49.3734335839599\n",
      "Iter: 149; avg. reward=-49.27860696517413\n",
      "Iter: 150; avg. reward=-49.50375939849624\n",
      "Iter: 151; avg. reward=-49.36842105263158\n",
      "Iter: 152; avg. reward=-49.2875\n",
      "Iter: 153; avg. reward=-49.234413965087285\n",
      "Iter: 154; avg. reward=-49.3225\n",
      "Iter: 155; avg. reward=-49.45363408521303\n",
      "Iter: 156; avg. reward=-49.276807980049874\n",
      "Iter: 157; avg. reward=-49.625\n",
      "Iter: 158; avg. reward=-49.30576441102757\n",
      "Iter: 159; avg. reward=-49.38308457711443\n",
      "Iter: 160; avg. reward=-49.31578947368421\n",
      "Iter: 161; avg. reward=-49.225563909774436\n",
      "Iter: 162; avg. reward=-49.4075\n",
      "Iter: 163; avg. reward=-49.403990024937656\n",
      "Iter: 164; avg. reward=-49.305\n",
      "Iter: 165; avg. reward=-49.21804511278196\n",
      "Iter: 166; avg. reward=-49.2069825436409\n",
      "Iter: 167; avg. reward=-49.1925\n",
      "Iter: 168; avg. reward=-49.3609022556391\n",
      "Iter: 169; avg. reward=-49.27114427860697\n",
      "Iter: 170; avg. reward=-49.1578947368421\n",
      "Iter: 171; avg. reward=-49.230576441102755\n",
      "Iter: 172; avg. reward=-49.1725\n",
      "Iter: 173; avg. reward=-49.27431421446384\n",
      "Iter: 174; avg. reward=-49.5975\n",
      "Iter: 175; avg. reward=-49.5062656641604\n",
      "Iter: 176; avg. reward=-49.54364089775561\n",
      "Iter: 177; avg. reward=-49.3075\n",
      "Iter: 178; avg. reward=-49.34335839598997\n",
      "Iter: 179; avg. reward=-49.44278606965174\n",
      "Iter: 180; avg. reward=-49.46365914786968\n",
      "Iter: 181; avg. reward=-49.57393483709273\n",
      "Iter: 182; avg. reward=-49.275\n",
      "Iter: 183; avg. reward=-49.54613466334165\n",
      "Iter: 184; avg. reward=-49.525\n",
      "Iter: 185; avg. reward=-49.416040100250626\n",
      "Iter: 186; avg. reward=-49.71072319201995\n",
      "Iter: 187; avg. reward=-49.4925\n",
      "Iter: 188; avg. reward=-49.46616541353384\n",
      "Iter: 189; avg. reward=-49.34825870646766\n",
      "Iter: 190; avg. reward=-49.27067669172932\n",
      "Iter: 191; avg. reward=-49.40601503759399\n",
      "Iter: 192; avg. reward=-49.325\n",
      "Iter: 193; avg. reward=-49.399002493765586\n",
      "Iter: 194; avg. reward=-49.3425\n",
      "Iter: 195; avg. reward=-49.25062656641604\n",
      "Iter: 196; avg. reward=-49.54364089775561\n",
      "Iter: 197; avg. reward=-49.53\n",
      "Iter: 198; avg. reward=-49.68421052631579\n",
      "Iter: 199; avg. reward=-49.29353233830846\n"
     ]
    }
   ],
   "source": [
    "# Train for n iterations and report results (mean episode rewards).\n",
    "# Since we have to move at least 19 times in the env to reach the goal and\n",
    "# each move gives us -0.1 reward (except the last move at the end: +1.0),\n",
    "# we can expect to reach an optimal episode reward of -0.1*18 + 1.0 = -0.8\n",
    "for i in range(200):\n",
    "    results = algo.train()\n",
    "    print(f\"Iter: {i}; avg. reward={results['episode_reward_mean']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'custom_metrics': {},\n",
       " 'episode_media': {},\n",
       " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
       "    'learner_stats': {'cur_kl_coeff': 0.20000000000000004,\n",
       "     'cur_lr': 5.0000000000000016e-05,\n",
       "     'total_loss': 9.314977171087778,\n",
       "     'policy_loss': -0.0364526856590503,\n",
       "     'vf_loss': 9.347446115555302,\n",
       "     'vf_explained_var': -8.762523692141297e-07,\n",
       "     'kl': 0.019918766150615975,\n",
       "     'entropy': 1.9746735113923268,\n",
       "     'entropy_coeff': 0.0},\n",
       "    'model': {},\n",
       "    'num_grad_updates_lifetime': 18135.5,\n",
       "    'diff_num_grad_updates_vs_sampler_policy': 464.5}},\n",
       "  'num_env_steps_sampled': 80000,\n",
       "  'num_env_steps_trained': 80000,\n",
       "  'num_agent_steps_sampled': 80000,\n",
       "  'num_agent_steps_trained': 80000},\n",
       " 'sampler_results': {'episode_reward_max': -53.0,\n",
       "  'episode_reward_min': -157.0,\n",
       "  'episode_reward_mean': -74.1592039800995,\n",
       "  'episode_len_mean': 10.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 402,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-70.0,\n",
       "    -65.0,\n",
       "    -83.0,\n",
       "    -75.0,\n",
       "    -81.0,\n",
       "    -79.0,\n",
       "    -86.0,\n",
       "    -67.0,\n",
       "    -75.0,\n",
       "    -68.0,\n",
       "    -73.0,\n",
       "    -62.0,\n",
       "    -61.0,\n",
       "    -80.0,\n",
       "    -77.0,\n",
       "    -83.0,\n",
       "    -84.0,\n",
       "    -67.0,\n",
       "    -71.0,\n",
       "    -71.0,\n",
       "    -73.0,\n",
       "    -71.0,\n",
       "    -69.0,\n",
       "    -63.0,\n",
       "    -95.0,\n",
       "    -65.0,\n",
       "    -69.0,\n",
       "    -67.0,\n",
       "    -75.0,\n",
       "    -88.0,\n",
       "    -73.0,\n",
       "    -88.0,\n",
       "    -72.0,\n",
       "    -70.0,\n",
       "    -89.0,\n",
       "    -74.0,\n",
       "    -63.0,\n",
       "    -66.0,\n",
       "    -63.0,\n",
       "    -68.0,\n",
       "    -75.0,\n",
       "    -69.0,\n",
       "    -73.0,\n",
       "    -76.0,\n",
       "    -77.0,\n",
       "    -77.0,\n",
       "    -75.0,\n",
       "    -89.0,\n",
       "    -71.0,\n",
       "    -73.0,\n",
       "    -65.0,\n",
       "    -55.0,\n",
       "    -57.0,\n",
       "    -75.0,\n",
       "    -53.0,\n",
       "    -78.0,\n",
       "    -75.0,\n",
       "    -73.0,\n",
       "    -65.0,\n",
       "    -77.0,\n",
       "    -75.0,\n",
       "    -73.0,\n",
       "    -67.0,\n",
       "    -63.0,\n",
       "    -79.0,\n",
       "    -67.0,\n",
       "    -73.0,\n",
       "    -67.0,\n",
       "    -81.0,\n",
       "    -67.0,\n",
       "    -63.0,\n",
       "    -59.0,\n",
       "    -74.0,\n",
       "    -81.0,\n",
       "    -88.0,\n",
       "    -81.0,\n",
       "    -69.0,\n",
       "    -75.0,\n",
       "    -79.0,\n",
       "    -81.0,\n",
       "    -63.0,\n",
       "    -59.0,\n",
       "    -69.0,\n",
       "    -65.0,\n",
       "    -71.0,\n",
       "    -77.0,\n",
       "    -75.0,\n",
       "    -75.0,\n",
       "    -64.0,\n",
       "    -71.0,\n",
       "    -74.0,\n",
       "    -71.0,\n",
       "    -81.0,\n",
       "    -67.0,\n",
       "    -59.0,\n",
       "    -66.0,\n",
       "    -65.0,\n",
       "    -79.0,\n",
       "    -77.0,\n",
       "    -63.0,\n",
       "    -85.0,\n",
       "    -89.0,\n",
       "    -62.0,\n",
       "    -81.0,\n",
       "    -73.0,\n",
       "    -65.0,\n",
       "    -75.0,\n",
       "    -82.0,\n",
       "    -77.0,\n",
       "    -75.0,\n",
       "    -59.0,\n",
       "    -69.0,\n",
       "    -64.0,\n",
       "    -85.0,\n",
       "    -93.0,\n",
       "    -75.0,\n",
       "    -89.0,\n",
       "    -71.0,\n",
       "    -77.0,\n",
       "    -81.0,\n",
       "    -70.0,\n",
       "    -82.0,\n",
       "    -67.0,\n",
       "    -67.0,\n",
       "    -69.0,\n",
       "    -73.0,\n",
       "    -71.0,\n",
       "    -79.0,\n",
       "    -69.0,\n",
       "    -73.0,\n",
       "    -73.0,\n",
       "    -99.0,\n",
       "    -67.0,\n",
       "    -65.0,\n",
       "    -73.0,\n",
       "    -77.0,\n",
       "    -82.0,\n",
       "    -77.0,\n",
       "    -65.0,\n",
       "    -77.0,\n",
       "    -81.0,\n",
       "    -71.0,\n",
       "    -78.0,\n",
       "    -69.0,\n",
       "    -64.0,\n",
       "    -83.0,\n",
       "    -69.0,\n",
       "    -68.0,\n",
       "    -77.0,\n",
       "    -83.0,\n",
       "    -97.0,\n",
       "    -67.0,\n",
       "    -81.0,\n",
       "    -73.0,\n",
       "    -86.0,\n",
       "    -84.0,\n",
       "    -73.0,\n",
       "    -78.0,\n",
       "    -88.0,\n",
       "    -75.0,\n",
       "    -80.0,\n",
       "    -79.0,\n",
       "    -77.0,\n",
       "    -77.0,\n",
       "    -66.0,\n",
       "    -65.0,\n",
       "    -71.0,\n",
       "    -75.0,\n",
       "    -66.0,\n",
       "    -73.0,\n",
       "    -67.0,\n",
       "    -69.0,\n",
       "    -73.0,\n",
       "    -71.0,\n",
       "    -75.0,\n",
       "    -73.0,\n",
       "    -85.0,\n",
       "    -86.0,\n",
       "    -74.0,\n",
       "    -67.0,\n",
       "    -57.0,\n",
       "    -79.0,\n",
       "    -68.0,\n",
       "    -83.0,\n",
       "    -71.0,\n",
       "    -71.0,\n",
       "    -69.0,\n",
       "    -69.0,\n",
       "    -77.0,\n",
       "    -73.0,\n",
       "    -69.0,\n",
       "    -81.0,\n",
       "    -79.0,\n",
       "    -65.0,\n",
       "    -77.0,\n",
       "    -83.0,\n",
       "    -67.0,\n",
       "    -67.0,\n",
       "    -87.0,\n",
       "    -65.0,\n",
       "    -91.0,\n",
       "    -87.0,\n",
       "    -80.0,\n",
       "    -73.0,\n",
       "    -87.0,\n",
       "    -81.0,\n",
       "    -77.0,\n",
       "    -80.0,\n",
       "    -71.0,\n",
       "    -72.0,\n",
       "    -81.0,\n",
       "    -75.0,\n",
       "    -69.0,\n",
       "    -81.0,\n",
       "    -75.0,\n",
       "    -73.0,\n",
       "    -73.0,\n",
       "    -67.0,\n",
       "    -81.0,\n",
       "    -71.0,\n",
       "    -87.0,\n",
       "    -67.0,\n",
       "    -67.0,\n",
       "    -63.0,\n",
       "    -71.0,\n",
       "    -137.0,\n",
       "    -65.0,\n",
       "    -75.0,\n",
       "    -65.0,\n",
       "    -71.0,\n",
       "    -75.0,\n",
       "    -85.0,\n",
       "    -69.0,\n",
       "    -76.0,\n",
       "    -83.0,\n",
       "    -71.0,\n",
       "    -69.0,\n",
       "    -131.0,\n",
       "    -71.0,\n",
       "    -75.0,\n",
       "    -73.0,\n",
       "    -69.0,\n",
       "    -69.0,\n",
       "    -71.0,\n",
       "    -64.0,\n",
       "    -77.0,\n",
       "    -71.0,\n",
       "    -68.0,\n",
       "    -70.0,\n",
       "    -69.0,\n",
       "    -63.0,\n",
       "    -59.0,\n",
       "    -73.0,\n",
       "    -67.0,\n",
       "    -69.0,\n",
       "    -78.0,\n",
       "    -77.0,\n",
       "    -69.0,\n",
       "    -69.0,\n",
       "    -65.0,\n",
       "    -91.0,\n",
       "    -81.0,\n",
       "    -69.0,\n",
       "    -77.0,\n",
       "    -157.0,\n",
       "    -65.0,\n",
       "    -81.0,\n",
       "    -75.0,\n",
       "    -63.0,\n",
       "    -67.0,\n",
       "    -75.0,\n",
       "    -80.0,\n",
       "    -59.0,\n",
       "    -86.0,\n",
       "    -81.0,\n",
       "    -71.0,\n",
       "    -69.0,\n",
       "    -67.0,\n",
       "    -75.0,\n",
       "    -150.0,\n",
       "    -87.0,\n",
       "    -71.0,\n",
       "    -71.0,\n",
       "    -65.0,\n",
       "    -78.0,\n",
       "    -77.0,\n",
       "    -67.0,\n",
       "    -79.0,\n",
       "    -85.0,\n",
       "    -75.0,\n",
       "    -63.0,\n",
       "    -69.0,\n",
       "    -67.0,\n",
       "    -84.0,\n",
       "    -63.0,\n",
       "    -71.0,\n",
       "    -77.0,\n",
       "    -83.0,\n",
       "    -75.0,\n",
       "    -67.0,\n",
       "    -75.0,\n",
       "    -61.0,\n",
       "    -69.0,\n",
       "    -67.0,\n",
       "    -73.0,\n",
       "    -75.0,\n",
       "    -61.0,\n",
       "    -79.0,\n",
       "    -93.0,\n",
       "    -79.0,\n",
       "    -82.0,\n",
       "    -83.0,\n",
       "    -75.0,\n",
       "    -73.0,\n",
       "    -73.0,\n",
       "    -77.0,\n",
       "    -93.0,\n",
       "    -80.0,\n",
       "    -59.0,\n",
       "    -82.0,\n",
       "    -59.0,\n",
       "    -74.0,\n",
       "    -77.0,\n",
       "    -79.0,\n",
       "    -79.0,\n",
       "    -69.0,\n",
       "    -69.0,\n",
       "    -73.0,\n",
       "    -61.0,\n",
       "    -70.0,\n",
       "    -77.0,\n",
       "    -59.0,\n",
       "    -69.0,\n",
       "    -83.0,\n",
       "    -68.0,\n",
       "    -82.0,\n",
       "    -62.0,\n",
       "    -65.0,\n",
       "    -83.0,\n",
       "    -79.0,\n",
       "    -75.0,\n",
       "    -71.0,\n",
       "    -83.0,\n",
       "    -61.0,\n",
       "    -84.0,\n",
       "    -73.0,\n",
       "    -73.0,\n",
       "    -65.0,\n",
       "    -63.0,\n",
       "    -87.0,\n",
       "    -71.0,\n",
       "    -71.0,\n",
       "    -73.0,\n",
       "    -81.0,\n",
       "    -67.0,\n",
       "    -73.0,\n",
       "    -73.0,\n",
       "    -72.0,\n",
       "    -65.0,\n",
       "    -81.0,\n",
       "    -61.0,\n",
       "    -75.0,\n",
       "    -73.0,\n",
       "    -73.0,\n",
       "    -69.0,\n",
       "    -67.0,\n",
       "    -105.0,\n",
       "    -85.0,\n",
       "    -72.0,\n",
       "    -69.0,\n",
       "    -75.0,\n",
       "    -69.0,\n",
       "    -71.0,\n",
       "    -75.0,\n",
       "    -63.0,\n",
       "    -75.0,\n",
       "    -73.0,\n",
       "    -81.0,\n",
       "    -73.0,\n",
       "    -63.0,\n",
       "    -83.0,\n",
       "    -77.0,\n",
       "    -75.0,\n",
       "    -84.0,\n",
       "    -83.0,\n",
       "    -79.0,\n",
       "    -77.0,\n",
       "    -77.0,\n",
       "    -85.0,\n",
       "    -65.0,\n",
       "    -67.0,\n",
       "    -65.0,\n",
       "    -85.0,\n",
       "    -75.0,\n",
       "    -75.0,\n",
       "    -67.0,\n",
       "    -69.0,\n",
       "    -69.0,\n",
       "    -55.0,\n",
       "    -61.0,\n",
       "    -73.0,\n",
       "    -77.0],\n",
       "   'episode_lengths': [10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10,\n",
       "    10]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.5552402248782893,\n",
       "   'mean_inference_ms': 1.0480512246333493,\n",
       "   'mean_action_processing_ms': 0.09850113038643639,\n",
       "   'mean_env_wait_ms': 0.07877026139824651,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'num_faulty_episodes': 0},\n",
       " 'episode_reward_max': -53.0,\n",
       " 'episode_reward_min': -157.0,\n",
       " 'episode_reward_mean': -74.1592039800995,\n",
       " 'episode_len_mean': 10.0,\n",
       " 'episodes_this_iter': 402,\n",
       " 'policy_reward_min': {},\n",
       " 'policy_reward_max': {},\n",
       " 'policy_reward_mean': {},\n",
       " 'hist_stats': {'episode_reward': [-70.0,\n",
       "   -65.0,\n",
       "   -83.0,\n",
       "   -75.0,\n",
       "   -81.0,\n",
       "   -79.0,\n",
       "   -86.0,\n",
       "   -67.0,\n",
       "   -75.0,\n",
       "   -68.0,\n",
       "   -73.0,\n",
       "   -62.0,\n",
       "   -61.0,\n",
       "   -80.0,\n",
       "   -77.0,\n",
       "   -83.0,\n",
       "   -84.0,\n",
       "   -67.0,\n",
       "   -71.0,\n",
       "   -71.0,\n",
       "   -73.0,\n",
       "   -71.0,\n",
       "   -69.0,\n",
       "   -63.0,\n",
       "   -95.0,\n",
       "   -65.0,\n",
       "   -69.0,\n",
       "   -67.0,\n",
       "   -75.0,\n",
       "   -88.0,\n",
       "   -73.0,\n",
       "   -88.0,\n",
       "   -72.0,\n",
       "   -70.0,\n",
       "   -89.0,\n",
       "   -74.0,\n",
       "   -63.0,\n",
       "   -66.0,\n",
       "   -63.0,\n",
       "   -68.0,\n",
       "   -75.0,\n",
       "   -69.0,\n",
       "   -73.0,\n",
       "   -76.0,\n",
       "   -77.0,\n",
       "   -77.0,\n",
       "   -75.0,\n",
       "   -89.0,\n",
       "   -71.0,\n",
       "   -73.0,\n",
       "   -65.0,\n",
       "   -55.0,\n",
       "   -57.0,\n",
       "   -75.0,\n",
       "   -53.0,\n",
       "   -78.0,\n",
       "   -75.0,\n",
       "   -73.0,\n",
       "   -65.0,\n",
       "   -77.0,\n",
       "   -75.0,\n",
       "   -73.0,\n",
       "   -67.0,\n",
       "   -63.0,\n",
       "   -79.0,\n",
       "   -67.0,\n",
       "   -73.0,\n",
       "   -67.0,\n",
       "   -81.0,\n",
       "   -67.0,\n",
       "   -63.0,\n",
       "   -59.0,\n",
       "   -74.0,\n",
       "   -81.0,\n",
       "   -88.0,\n",
       "   -81.0,\n",
       "   -69.0,\n",
       "   -75.0,\n",
       "   -79.0,\n",
       "   -81.0,\n",
       "   -63.0,\n",
       "   -59.0,\n",
       "   -69.0,\n",
       "   -65.0,\n",
       "   -71.0,\n",
       "   -77.0,\n",
       "   -75.0,\n",
       "   -75.0,\n",
       "   -64.0,\n",
       "   -71.0,\n",
       "   -74.0,\n",
       "   -71.0,\n",
       "   -81.0,\n",
       "   -67.0,\n",
       "   -59.0,\n",
       "   -66.0,\n",
       "   -65.0,\n",
       "   -79.0,\n",
       "   -77.0,\n",
       "   -63.0,\n",
       "   -85.0,\n",
       "   -89.0,\n",
       "   -62.0,\n",
       "   -81.0,\n",
       "   -73.0,\n",
       "   -65.0,\n",
       "   -75.0,\n",
       "   -82.0,\n",
       "   -77.0,\n",
       "   -75.0,\n",
       "   -59.0,\n",
       "   -69.0,\n",
       "   -64.0,\n",
       "   -85.0,\n",
       "   -93.0,\n",
       "   -75.0,\n",
       "   -89.0,\n",
       "   -71.0,\n",
       "   -77.0,\n",
       "   -81.0,\n",
       "   -70.0,\n",
       "   -82.0,\n",
       "   -67.0,\n",
       "   -67.0,\n",
       "   -69.0,\n",
       "   -73.0,\n",
       "   -71.0,\n",
       "   -79.0,\n",
       "   -69.0,\n",
       "   -73.0,\n",
       "   -73.0,\n",
       "   -99.0,\n",
       "   -67.0,\n",
       "   -65.0,\n",
       "   -73.0,\n",
       "   -77.0,\n",
       "   -82.0,\n",
       "   -77.0,\n",
       "   -65.0,\n",
       "   -77.0,\n",
       "   -81.0,\n",
       "   -71.0,\n",
       "   -78.0,\n",
       "   -69.0,\n",
       "   -64.0,\n",
       "   -83.0,\n",
       "   -69.0,\n",
       "   -68.0,\n",
       "   -77.0,\n",
       "   -83.0,\n",
       "   -97.0,\n",
       "   -67.0,\n",
       "   -81.0,\n",
       "   -73.0,\n",
       "   -86.0,\n",
       "   -84.0,\n",
       "   -73.0,\n",
       "   -78.0,\n",
       "   -88.0,\n",
       "   -75.0,\n",
       "   -80.0,\n",
       "   -79.0,\n",
       "   -77.0,\n",
       "   -77.0,\n",
       "   -66.0,\n",
       "   -65.0,\n",
       "   -71.0,\n",
       "   -75.0,\n",
       "   -66.0,\n",
       "   -73.0,\n",
       "   -67.0,\n",
       "   -69.0,\n",
       "   -73.0,\n",
       "   -71.0,\n",
       "   -75.0,\n",
       "   -73.0,\n",
       "   -85.0,\n",
       "   -86.0,\n",
       "   -74.0,\n",
       "   -67.0,\n",
       "   -57.0,\n",
       "   -79.0,\n",
       "   -68.0,\n",
       "   -83.0,\n",
       "   -71.0,\n",
       "   -71.0,\n",
       "   -69.0,\n",
       "   -69.0,\n",
       "   -77.0,\n",
       "   -73.0,\n",
       "   -69.0,\n",
       "   -81.0,\n",
       "   -79.0,\n",
       "   -65.0,\n",
       "   -77.0,\n",
       "   -83.0,\n",
       "   -67.0,\n",
       "   -67.0,\n",
       "   -87.0,\n",
       "   -65.0,\n",
       "   -91.0,\n",
       "   -87.0,\n",
       "   -80.0,\n",
       "   -73.0,\n",
       "   -87.0,\n",
       "   -81.0,\n",
       "   -77.0,\n",
       "   -80.0,\n",
       "   -71.0,\n",
       "   -72.0,\n",
       "   -81.0,\n",
       "   -75.0,\n",
       "   -69.0,\n",
       "   -81.0,\n",
       "   -75.0,\n",
       "   -73.0,\n",
       "   -73.0,\n",
       "   -67.0,\n",
       "   -81.0,\n",
       "   -71.0,\n",
       "   -87.0,\n",
       "   -67.0,\n",
       "   -67.0,\n",
       "   -63.0,\n",
       "   -71.0,\n",
       "   -137.0,\n",
       "   -65.0,\n",
       "   -75.0,\n",
       "   -65.0,\n",
       "   -71.0,\n",
       "   -75.0,\n",
       "   -85.0,\n",
       "   -69.0,\n",
       "   -76.0,\n",
       "   -83.0,\n",
       "   -71.0,\n",
       "   -69.0,\n",
       "   -131.0,\n",
       "   -71.0,\n",
       "   -75.0,\n",
       "   -73.0,\n",
       "   -69.0,\n",
       "   -69.0,\n",
       "   -71.0,\n",
       "   -64.0,\n",
       "   -77.0,\n",
       "   -71.0,\n",
       "   -68.0,\n",
       "   -70.0,\n",
       "   -69.0,\n",
       "   -63.0,\n",
       "   -59.0,\n",
       "   -73.0,\n",
       "   -67.0,\n",
       "   -69.0,\n",
       "   -78.0,\n",
       "   -77.0,\n",
       "   -69.0,\n",
       "   -69.0,\n",
       "   -65.0,\n",
       "   -91.0,\n",
       "   -81.0,\n",
       "   -69.0,\n",
       "   -77.0,\n",
       "   -157.0,\n",
       "   -65.0,\n",
       "   -81.0,\n",
       "   -75.0,\n",
       "   -63.0,\n",
       "   -67.0,\n",
       "   -75.0,\n",
       "   -80.0,\n",
       "   -59.0,\n",
       "   -86.0,\n",
       "   -81.0,\n",
       "   -71.0,\n",
       "   -69.0,\n",
       "   -67.0,\n",
       "   -75.0,\n",
       "   -150.0,\n",
       "   -87.0,\n",
       "   -71.0,\n",
       "   -71.0,\n",
       "   -65.0,\n",
       "   -78.0,\n",
       "   -77.0,\n",
       "   -67.0,\n",
       "   -79.0,\n",
       "   -85.0,\n",
       "   -75.0,\n",
       "   -63.0,\n",
       "   -69.0,\n",
       "   -67.0,\n",
       "   -84.0,\n",
       "   -63.0,\n",
       "   -71.0,\n",
       "   -77.0,\n",
       "   -83.0,\n",
       "   -75.0,\n",
       "   -67.0,\n",
       "   -75.0,\n",
       "   -61.0,\n",
       "   -69.0,\n",
       "   -67.0,\n",
       "   -73.0,\n",
       "   -75.0,\n",
       "   -61.0,\n",
       "   -79.0,\n",
       "   -93.0,\n",
       "   -79.0,\n",
       "   -82.0,\n",
       "   -83.0,\n",
       "   -75.0,\n",
       "   -73.0,\n",
       "   -73.0,\n",
       "   -77.0,\n",
       "   -93.0,\n",
       "   -80.0,\n",
       "   -59.0,\n",
       "   -82.0,\n",
       "   -59.0,\n",
       "   -74.0,\n",
       "   -77.0,\n",
       "   -79.0,\n",
       "   -79.0,\n",
       "   -69.0,\n",
       "   -69.0,\n",
       "   -73.0,\n",
       "   -61.0,\n",
       "   -70.0,\n",
       "   -77.0,\n",
       "   -59.0,\n",
       "   -69.0,\n",
       "   -83.0,\n",
       "   -68.0,\n",
       "   -82.0,\n",
       "   -62.0,\n",
       "   -65.0,\n",
       "   -83.0,\n",
       "   -79.0,\n",
       "   -75.0,\n",
       "   -71.0,\n",
       "   -83.0,\n",
       "   -61.0,\n",
       "   -84.0,\n",
       "   -73.0,\n",
       "   -73.0,\n",
       "   -65.0,\n",
       "   -63.0,\n",
       "   -87.0,\n",
       "   -71.0,\n",
       "   -71.0,\n",
       "   -73.0,\n",
       "   -81.0,\n",
       "   -67.0,\n",
       "   -73.0,\n",
       "   -73.0,\n",
       "   -72.0,\n",
       "   -65.0,\n",
       "   -81.0,\n",
       "   -61.0,\n",
       "   -75.0,\n",
       "   -73.0,\n",
       "   -73.0,\n",
       "   -69.0,\n",
       "   -67.0,\n",
       "   -105.0,\n",
       "   -85.0,\n",
       "   -72.0,\n",
       "   -69.0,\n",
       "   -75.0,\n",
       "   -69.0,\n",
       "   -71.0,\n",
       "   -75.0,\n",
       "   -63.0,\n",
       "   -75.0,\n",
       "   -73.0,\n",
       "   -81.0,\n",
       "   -73.0,\n",
       "   -63.0,\n",
       "   -83.0,\n",
       "   -77.0,\n",
       "   -75.0,\n",
       "   -84.0,\n",
       "   -83.0,\n",
       "   -79.0,\n",
       "   -77.0,\n",
       "   -77.0,\n",
       "   -85.0,\n",
       "   -65.0,\n",
       "   -67.0,\n",
       "   -65.0,\n",
       "   -85.0,\n",
       "   -75.0,\n",
       "   -75.0,\n",
       "   -67.0,\n",
       "   -69.0,\n",
       "   -69.0,\n",
       "   -55.0,\n",
       "   -61.0,\n",
       "   -73.0,\n",
       "   -77.0],\n",
       "  'episode_lengths': [10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10,\n",
       "   10]},\n",
       " 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5552402248782893,\n",
       "  'mean_inference_ms': 1.0480512246333493,\n",
       "  'mean_action_processing_ms': 0.09850113038643639,\n",
       "  'mean_env_wait_ms': 0.07877026139824651,\n",
       "  'mean_env_render_ms': 0.0},\n",
       " 'num_faulty_episodes': 0,\n",
       " 'num_healthy_workers': 3,\n",
       " 'num_in_flight_async_reqs': 0,\n",
       " 'num_remote_worker_restarts': 0,\n",
       " 'num_agent_steps_sampled': 80000,\n",
       " 'num_agent_steps_trained': 80000,\n",
       " 'num_env_steps_sampled': 80000,\n",
       " 'num_env_steps_trained': 80000,\n",
       " 'num_env_steps_sampled_this_iter': 4000,\n",
       " 'num_env_steps_trained_this_iter': 4000,\n",
       " 'timesteps_total': 80000,\n",
       " 'num_steps_trained_this_iter': 4000,\n",
       " 'agent_timesteps_total': 80000,\n",
       " 'timers': {'training_iteration_time_ms': 12906.208,\n",
       "  'load_time_ms': 6.325,\n",
       "  'load_throughput': 632367.512,\n",
       "  'learn_time_ms': 10454.123,\n",
       "  'learn_throughput': 382.624,\n",
       "  'synch_weights_time_ms': 4.901},\n",
       " 'counters': {'num_env_steps_sampled': 80000,\n",
       "  'num_env_steps_trained': 80000,\n",
       "  'num_agent_steps_sampled': 80000,\n",
       "  'num_agent_steps_trained': 80000},\n",
       " 'done': False,\n",
       " 'episodes_total': 8000,\n",
       " 'training_iteration': 20,\n",
       " 'trial_id': 'default',\n",
       " 'experiment_id': '16002e55dc654dff94860f37f09e20a4',\n",
       " 'date': '2023-01-07_17-40-17',\n",
       " 'timestamp': 1673131217,\n",
       " 'time_this_iter_s': 12.76124119758606,\n",
       " 'time_total_s': 256.07317662239075,\n",
       " 'pid': 21960,\n",
       " 'hostname': 'Teamy-Desktop',\n",
       " 'node_ip': '127.0.0.1',\n",
       " 'config': {'extra_python_environs_for_driver': {},\n",
       "  'extra_python_environs_for_worker': {},\n",
       "  'num_gpus': 1,\n",
       "  'num_cpus_per_worker': 1,\n",
       "  'num_gpus_per_worker': 0,\n",
       "  '_fake_gpus': False,\n",
       "  'custom_resources_per_worker': {},\n",
       "  'placement_strategy': 'PACK',\n",
       "  'eager_tracing': False,\n",
       "  'eager_max_retraces': 20,\n",
       "  'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "   'inter_op_parallelism_threads': 2,\n",
       "   'gpu_options': {'allow_growth': True},\n",
       "   'log_device_placement': False,\n",
       "   'device_count': {'CPU': 1},\n",
       "   'allow_soft_placement': True},\n",
       "  'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "   'inter_op_parallelism_threads': 8},\n",
       "  'env': 'Platoon-v1',\n",
       "  'env_config': {},\n",
       "  'observation_space': None,\n",
       "  'action_space': None,\n",
       "  'env_task_fn': None,\n",
       "  'render_env': False,\n",
       "  'clip_rewards': None,\n",
       "  'normalize_actions': True,\n",
       "  'clip_actions': False,\n",
       "  'disable_env_checking': False,\n",
       "  'is_atari': False,\n",
       "  'num_envs_per_worker': 1,\n",
       "  'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "  'sample_async': False,\n",
       "  'enable_connectors': False,\n",
       "  'rollout_fragment_length': 'auto',\n",
       "  'batch_mode': 'truncate_episodes',\n",
       "  'remote_worker_envs': False,\n",
       "  'remote_env_batch_wait_ms': 0,\n",
       "  'validate_workers_after_construction': True,\n",
       "  'ignore_worker_failures': False,\n",
       "  'recreate_failed_workers': False,\n",
       "  'restart_failed_sub_environments': False,\n",
       "  'num_consecutive_worker_failures_tolerance': 100,\n",
       "  'preprocessor_pref': 'deepmind',\n",
       "  'observation_filter': 'NoFilter',\n",
       "  'synchronize_filters': True,\n",
       "  'compress_observations': False,\n",
       "  'enable_tf1_exec_eagerly': False,\n",
       "  'sampler_perf_stats_ema_coef': None,\n",
       "  'gamma': 0.99,\n",
       "  'lr': 5e-05,\n",
       "  'train_batch_size': 4000,\n",
       "  'model': {'_disable_preprocessor_api': False,\n",
       "   '_disable_action_flattening': False,\n",
       "   'fcnet_hiddens': [256, 256],\n",
       "   'fcnet_activation': 'tanh',\n",
       "   'conv_filters': None,\n",
       "   'conv_activation': 'relu',\n",
       "   'post_fcnet_hiddens': [],\n",
       "   'post_fcnet_activation': 'relu',\n",
       "   'free_log_std': False,\n",
       "   'no_final_linear': False,\n",
       "   'vf_share_layers': False,\n",
       "   'use_lstm': False,\n",
       "   'max_seq_len': 20,\n",
       "   'lstm_cell_size': 256,\n",
       "   'lstm_use_prev_action': False,\n",
       "   'lstm_use_prev_reward': False,\n",
       "   '_time_major': False,\n",
       "   'use_attention': False,\n",
       "   'attention_num_transformer_units': 1,\n",
       "   'attention_dim': 64,\n",
       "   'attention_num_heads': 1,\n",
       "   'attention_head_dim': 32,\n",
       "   'attention_memory_inference': 50,\n",
       "   'attention_memory_training': 50,\n",
       "   'attention_position_wise_mlp_dim': 32,\n",
       "   'attention_init_gru_gate_bias': 2.0,\n",
       "   'attention_use_n_prev_actions': 0,\n",
       "   'attention_use_n_prev_rewards': 0,\n",
       "   'framestack': True,\n",
       "   'dim': 84,\n",
       "   'grayscale': False,\n",
       "   'zero_mean': True,\n",
       "   'custom_model': None,\n",
       "   'custom_model_config': {},\n",
       "   'custom_action_dist': None,\n",
       "   'custom_preprocessor': None,\n",
       "   'lstm_use_prev_action_reward': -1,\n",
       "   '_use_default_native_models': -1},\n",
       "  'optimizer': {},\n",
       "  'max_requests_in_flight_per_sampler_worker': 2,\n",
       "  'explore': True,\n",
       "  'exploration_config': {'type': 'StochasticSampling'},\n",
       "  'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec at 0x1d008e15940>},\n",
       "  'policy_states_are_swappable': False,\n",
       "  'input_config': {},\n",
       "  'actions_in_input_normalized': False,\n",
       "  'postprocess_inputs': False,\n",
       "  'shuffle_buffer_size': 0,\n",
       "  'output': None,\n",
       "  'output_config': {},\n",
       "  'output_compress_columns': ['obs', 'new_obs'],\n",
       "  'output_max_file_size': 67108864,\n",
       "  'offline_sampling': False,\n",
       "  'evaluation_interval': None,\n",
       "  'evaluation_duration': 10,\n",
       "  'evaluation_duration_unit': 'episodes',\n",
       "  'evaluation_sample_timeout_s': 180.0,\n",
       "  'evaluation_parallel_to_training': False,\n",
       "  'evaluation_config': None,\n",
       "  'off_policy_estimation_methods': {},\n",
       "  'ope_split_batch_by_episode': True,\n",
       "  'evaluation_num_workers': 0,\n",
       "  'always_attach_evaluation_results': False,\n",
       "  'enable_async_evaluation': False,\n",
       "  'in_evaluation': False,\n",
       "  'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
       "  'keep_per_episode_custom_metrics': False,\n",
       "  'metrics_episode_collection_timeout_s': 60.0,\n",
       "  'metrics_num_episodes_for_smoothing': 100,\n",
       "  'min_time_s_per_iteration': None,\n",
       "  'min_train_timesteps_per_iteration': 0,\n",
       "  'min_sample_timesteps_per_iteration': 0,\n",
       "  'export_native_model_files': False,\n",
       "  'checkpoint_trainable_policies_only': False,\n",
       "  'logger_creator': None,\n",
       "  'logger_config': None,\n",
       "  'log_level': -1,\n",
       "  'log_sys_usage': True,\n",
       "  'fake_sampler': False,\n",
       "  'seed': None,\n",
       "  'worker_cls': None,\n",
       "  'rl_module_class': None,\n",
       "  '_enable_rl_module_api': False,\n",
       "  '_tf_policy_handles_more_than_one_loss': False,\n",
       "  '_disable_preprocessor_api': False,\n",
       "  '_disable_action_flattening': False,\n",
       "  '_disable_execution_plan_api': True,\n",
       "  'simple_optimizer': False,\n",
       "  'replay_sequence_length': None,\n",
       "  'horizon': -1,\n",
       "  'soft_horizon': -1,\n",
       "  'no_done_at_end': -1,\n",
       "  'lr_schedule': None,\n",
       "  'use_critic': True,\n",
       "  'use_gae': True,\n",
       "  'kl_coeff': 0.2,\n",
       "  'sgd_minibatch_size': 128,\n",
       "  'num_sgd_iter': 30,\n",
       "  'shuffle_sequences': True,\n",
       "  'vf_loss_coeff': 1.0,\n",
       "  'entropy_coeff': 0.0,\n",
       "  'entropy_coeff_schedule': None,\n",
       "  'clip_param': 0.3,\n",
       "  'vf_clip_param': 10.0,\n",
       "  'grad_clip': None,\n",
       "  'kl_target': 0.01,\n",
       "  'vf_share_layers': -1,\n",
       "  'lambda': 1.0,\n",
       "  'input': 'sampler',\n",
       "  'multiagent': {'policies': {'default_policy': (None, None, None, None)},\n",
       "   'policy_mapping_fn': <function ray.rllib.algorithms.algorithm_config.AlgorithmConfig.__init__.<locals>.<lambda>(aid, episode, worker, **kwargs)>,\n",
       "   'policies_to_train': None,\n",
       "   'policy_map_capacity': 100,\n",
       "   'policy_map_cache': -1,\n",
       "   'count_steps_by': 'env_steps',\n",
       "   'observation_fn': None},\n",
       "  'callbacks': ray.rllib.algorithms.callbacks.DefaultCallbacks,\n",
       "  'create_env_on_driver': False,\n",
       "  'custom_eval_function': None,\n",
       "  'framework': 'torch',\n",
       "  'num_cpus_for_driver': 1,\n",
       "  'num_workers': 3},\n",
       " 'time_since_restore': 256.07317662239075,\n",
       " 'timesteps_since_restore': 0,\n",
       " 'iterations_since_restore': 20,\n",
       " 'warmup_time': 10.99787950515747,\n",
       " 'perf': {'cpu_util_percent': 30.213333333333335,\n",
       "  'ram_util_percent': 53.66666666666668,\n",
       "  'gpu_util_percent0': 0.2946666666666667,\n",
       "  'vram_util_percent0': 0.11371383596591217}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameNotFound",
     "evalue": "Environment Platoon doesn't exist. Did you mean: `Pooyan`?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameNotFound\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Perform inference (action computations) based on given env observations.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# Note that we are using a slightly different env here (len 10 instead of 20),\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# however, this should still work as the agent has (hopefully) learned\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m# to \"just always walk right!\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m# env = SimpleCorridor({\"corridor_length\": 10})\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m env \u001b[39m=\u001b[39m gym\u001b[39m.\u001b[39;49mmake(env_name)\n\u001b[0;32m      7\u001b[0m \u001b[39m# Get the initial observation (should be: [0.0] for the starting position).\u001b[39;00m\n\u001b[0;32m      8\u001b[0m obs, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mreset()\n",
      "File \u001b[1;32mc:\\Users\\TeamD\\.conda\\envs\\rllib\\lib\\site-packages\\gymnasium\\envs\\registration.py:591\u001b[0m, in \u001b[0;36mmake\u001b[1;34m(id, max_episode_steps, autoreset, apply_api_compatibility, disable_env_checker, **kwargs)\u001b[0m\n\u001b[0;32m    585\u001b[0m         logger\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    586\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUsing the latest versioned environment `\u001b[39m\u001b[39m{\u001b[39;00mnew_env_id\u001b[39m}\u001b[39;00m\u001b[39m` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    587\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minstead of the unversioned environment `\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mid\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    588\u001b[0m         )\n\u001b[0;32m    590\u001b[0m     \u001b[39mif\u001b[39;00m spec_ \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m         _check_version_exists(ns, name, version)\n\u001b[0;32m    592\u001b[0m         \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo registered env with id: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mid\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    594\u001b[0m _kwargs \u001b[39m=\u001b[39m spec_\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[1;32mc:\\Users\\TeamD\\.conda\\envs\\rllib\\lib\\site-packages\\gymnasium\\envs\\registration.py:217\u001b[0m, in \u001b[0;36m_check_version_exists\u001b[1;34m(ns, name, version)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[39mif\u001b[39;00m get_env_id(ns, name, version) \u001b[39min\u001b[39;00m registry:\n\u001b[0;32m    215\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m _check_name_exists(ns, name)\n\u001b[0;32m    218\u001b[0m \u001b[39mif\u001b[39;00m version \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    219\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\TeamD\\.conda\\envs\\rllib\\lib\\site-packages\\gymnasium\\envs\\registration.py:194\u001b[0m, in \u001b[0;36m_check_name_exists\u001b[1;34m(ns, name)\u001b[0m\n\u001b[0;32m    191\u001b[0m namespace_msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m in namespace \u001b[39m\u001b[39m{\u001b[39;00mns\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m ns \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    192\u001b[0m suggestion_msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDid you mean: `\u001b[39m\u001b[39m{\u001b[39;00msuggestion[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m`?\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m suggestion \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 194\u001b[0m \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mNameNotFound(\n\u001b[0;32m    195\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEnvironment \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt exist\u001b[39m\u001b[39m{\u001b[39;00mnamespace_msg\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m{\u001b[39;00msuggestion_msg\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    196\u001b[0m )\n",
      "\u001b[1;31mNameNotFound\u001b[0m: Environment Platoon doesn't exist. Did you mean: `Pooyan`?"
     ]
    }
   ],
   "source": [
    "\n",
    "# Perform inference (action computations) based on given env observations.\n",
    "# Note that we are using a slightly different env here (len 10 instead of 20),\n",
    "# however, this should still work as the agent has (hopefully) learned\n",
    "# to \"just always walk right!\"\n",
    "# env = SimpleCorridor({\"corridor_length\": 10})\n",
    "env = gym.make(env_name)\n",
    "# Get the initial observation (should be: [0.0] for the starting position).\n",
    "obs, info = env.reset()\n",
    "terminated = truncated = False\n",
    "total_reward = 0.0\n",
    "# Play one episode.\n",
    "while not terminated and not truncated:\n",
    "    # Compute a single action, given the current observation\n",
    "    # from the environment.\n",
    "    action = algo.compute_single_action(obs)\n",
    "    # Apply the computed action in the environment.\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    # Sum up rewards for reporting purposes.\n",
    "    total_reward += reward\n",
    "    # env.render()\n",
    "# Report results.\n",
    "print(f\"Played 1 episode; total-reward={total_reward}\")\n",
    "# __quick_start_end__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rllib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "524f818cd743d7abf57cb48d668c781df3b45c3f425c53d80f3bb0fcd0df7a52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
